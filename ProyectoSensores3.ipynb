{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "953ef117",
   "metadata": {},
   "source": [
    "# Brahyan Avendaño Morales\n",
    "Trabajo de sensores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a60066",
   "metadata": {},
   "source": [
    "# Análisis de expresión génica en monocitos de pacientes con cáncer de mama metastásico y sepsis. \n",
    "#Base de datos: (Cáncer de mama metastásico y sepsis: monocitos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80796972",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gzip\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "from sklearn import tree\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6fb983ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>B.1</th>\n",
       "      <th>B.2</th>\n",
       "      <th>B.3</th>\n",
       "      <th>B.4</th>\n",
       "      <th>HC.1</th>\n",
       "      <th>HC.2</th>\n",
       "      <th>HC.3</th>\n",
       "      <th>S.1</th>\n",
       "      <th>S.2</th>\n",
       "      <th>S.3</th>\n",
       "      <th>T.1</th>\n",
       "      <th>T.2</th>\n",
       "      <th>T.3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID_REF</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ILMN_1725881</th>\n",
       "      <td>10.479167</td>\n",
       "      <td>4.937500</td>\n",
       "      <td>16.8125</td>\n",
       "      <td>9.062500</td>\n",
       "      <td>1.854167</td>\n",
       "      <td>9.104167</td>\n",
       "      <td>15.104167</td>\n",
       "      <td>3.4375</td>\n",
       "      <td>8.270833</td>\n",
       "      <td>-3.145833</td>\n",
       "      <td>11.437500</td>\n",
       "      <td>14.020833</td>\n",
       "      <td>11.187500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ILMN_1910180</th>\n",
       "      <td>-0.687500</td>\n",
       "      <td>2.229167</td>\n",
       "      <td>-1.4375</td>\n",
       "      <td>23.270834</td>\n",
       "      <td>4.312500</td>\n",
       "      <td>3.270833</td>\n",
       "      <td>3.479167</td>\n",
       "      <td>-8.4375</td>\n",
       "      <td>-5.354166</td>\n",
       "      <td>-1.187500</td>\n",
       "      <td>2.895833</td>\n",
       "      <td>-3.687500</td>\n",
       "      <td>-3.354167</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    B.1       B.2      B.3        B.4      HC.1      HC.2  \\\n",
       "ID_REF                                                                      \n",
       "ILMN_1725881  10.479167  4.937500  16.8125   9.062500  1.854167  9.104167   \n",
       "ILMN_1910180  -0.687500  2.229167  -1.4375  23.270834  4.312500  3.270833   \n",
       "\n",
       "                   HC.3     S.1       S.2       S.3        T.1        T.2  \\\n",
       "ID_REF                                                                      \n",
       "ILMN_1725881  15.104167  3.4375  8.270833 -3.145833  11.437500  14.020833   \n",
       "ILMN_1910180   3.479167 -8.4375 -5.354166 -1.187500   2.895833  -3.687500   \n",
       "\n",
       "                    T.3  \n",
       "ID_REF                   \n",
       "ILMN_1725881  11.187500  \n",
       "ILMN_1910180  -3.354167  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath = \"GSE65517_normalized.txt.gz\"\n",
    "df = pd.read_csv(filepath, sep=\"\\t\", compression=\"gzip\" , skiprows=4, index_col=0, header=1 )\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "830964b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47332, 13)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5fbd83ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>ID_REF</th>\n",
       "      <th>ILMN_1725881</th>\n",
       "      <th>ILMN_1910180</th>\n",
       "      <th>ILMN_1804174</th>\n",
       "      <th>ILMN_1796063</th>\n",
       "      <th>ILMN_3284771</th>\n",
       "      <th>ILMN_3208259</th>\n",
       "      <th>ILMN_1811966</th>\n",
       "      <th>ILMN_1668162</th>\n",
       "      <th>ILMN_1715600</th>\n",
       "      <th>ILMN_1912287</th>\n",
       "      <th>...</th>\n",
       "      <th>ILMN_3166640</th>\n",
       "      <th>ILMN_3166655</th>\n",
       "      <th>ILMN_3166673</th>\n",
       "      <th>ILMN_3166687</th>\n",
       "      <th>ILMN_3166703</th>\n",
       "      <th>ILMN_3166721</th>\n",
       "      <th>ILMN_3166728</th>\n",
       "      <th>ILMN_3166775</th>\n",
       "      <th>ILMN_3166789</th>\n",
       "      <th>ILMN_3166804</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>B.1</th>\n",
       "      <td>10.479167</td>\n",
       "      <td>-0.687500</td>\n",
       "      <td>16.854166</td>\n",
       "      <td>401.56250</td>\n",
       "      <td>0.354167</td>\n",
       "      <td>2.354167</td>\n",
       "      <td>9.562500</td>\n",
       "      <td>-7.645834</td>\n",
       "      <td>-7.645834</td>\n",
       "      <td>13.645833</td>\n",
       "      <td>...</td>\n",
       "      <td>3.187500</td>\n",
       "      <td>-3.604167</td>\n",
       "      <td>-5.645834</td>\n",
       "      <td>-4.562500</td>\n",
       "      <td>7.770834</td>\n",
       "      <td>-1.729167</td>\n",
       "      <td>-8.687500</td>\n",
       "      <td>-0.729167</td>\n",
       "      <td>-0.729167</td>\n",
       "      <td>1.312500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B.2</th>\n",
       "      <td>4.937500</td>\n",
       "      <td>2.229167</td>\n",
       "      <td>7.562500</td>\n",
       "      <td>416.60416</td>\n",
       "      <td>-2.895833</td>\n",
       "      <td>-0.354167</td>\n",
       "      <td>2.229167</td>\n",
       "      <td>-7.770834</td>\n",
       "      <td>-4.020834</td>\n",
       "      <td>15.687500</td>\n",
       "      <td>...</td>\n",
       "      <td>12.979167</td>\n",
       "      <td>0.854167</td>\n",
       "      <td>-6.604166</td>\n",
       "      <td>-4.104166</td>\n",
       "      <td>3.562500</td>\n",
       "      <td>-0.395833</td>\n",
       "      <td>-6.604166</td>\n",
       "      <td>-0.395833</td>\n",
       "      <td>-7.812500</td>\n",
       "      <td>3.562500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B.3</th>\n",
       "      <td>16.812500</td>\n",
       "      <td>-1.437500</td>\n",
       "      <td>1.145833</td>\n",
       "      <td>229.02083</td>\n",
       "      <td>-7.729166</td>\n",
       "      <td>3.770833</td>\n",
       "      <td>3.770833</td>\n",
       "      <td>5.104166</td>\n",
       "      <td>-9.979167</td>\n",
       "      <td>61.520832</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.437500</td>\n",
       "      <td>-2.854167</td>\n",
       "      <td>-2.854167</td>\n",
       "      <td>1.104167</td>\n",
       "      <td>-0.312500</td>\n",
       "      <td>6.562500</td>\n",
       "      <td>1.104167</td>\n",
       "      <td>-11.187500</td>\n",
       "      <td>-0.312500</td>\n",
       "      <td>-1.479167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B.4</th>\n",
       "      <td>9.062500</td>\n",
       "      <td>23.270834</td>\n",
       "      <td>31.895834</td>\n",
       "      <td>466.81250</td>\n",
       "      <td>-7.520834</td>\n",
       "      <td>-4.229166</td>\n",
       "      <td>16.979166</td>\n",
       "      <td>-11.187500</td>\n",
       "      <td>10.187500</td>\n",
       "      <td>27.229166</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.604167</td>\n",
       "      <td>5.395834</td>\n",
       "      <td>-9.812500</td>\n",
       "      <td>-1.854167</td>\n",
       "      <td>5.395834</td>\n",
       "      <td>-1.854167</td>\n",
       "      <td>-7.562500</td>\n",
       "      <td>-3.020833</td>\n",
       "      <td>-3.020833</td>\n",
       "      <td>-0.604167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HC.1</th>\n",
       "      <td>1.854167</td>\n",
       "      <td>4.312500</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>473.22916</td>\n",
       "      <td>-5.937500</td>\n",
       "      <td>-3.229167</td>\n",
       "      <td>30.229166</td>\n",
       "      <td>-0.812500</td>\n",
       "      <td>13.729167</td>\n",
       "      <td>5.187500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.979167</td>\n",
       "      <td>-2.395833</td>\n",
       "      <td>-2.395833</td>\n",
       "      <td>-2.395833</td>\n",
       "      <td>-6.812500</td>\n",
       "      <td>6.770834</td>\n",
       "      <td>-2.395833</td>\n",
       "      <td>-6.812500</td>\n",
       "      <td>6.770834</td>\n",
       "      <td>-6.812500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HC.2</th>\n",
       "      <td>9.104167</td>\n",
       "      <td>3.270833</td>\n",
       "      <td>40.145832</td>\n",
       "      <td>309.27084</td>\n",
       "      <td>-4.895834</td>\n",
       "      <td>0.395833</td>\n",
       "      <td>16.354166</td>\n",
       "      <td>-10.187500</td>\n",
       "      <td>-3.270833</td>\n",
       "      <td>10.645833</td>\n",
       "      <td>...</td>\n",
       "      <td>9.770833</td>\n",
       "      <td>-8.437500</td>\n",
       "      <td>-10.229167</td>\n",
       "      <td>2.729167</td>\n",
       "      <td>-2.604167</td>\n",
       "      <td>1.229167</td>\n",
       "      <td>-4.937500</td>\n",
       "      <td>-1.062500</td>\n",
       "      <td>-3.312500</td>\n",
       "      <td>1.979167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HC.3</th>\n",
       "      <td>15.104167</td>\n",
       "      <td>3.479167</td>\n",
       "      <td>29.187500</td>\n",
       "      <td>536.47920</td>\n",
       "      <td>-0.979167</td>\n",
       "      <td>-6.479166</td>\n",
       "      <td>7.895834</td>\n",
       "      <td>-0.145833</td>\n",
       "      <td>-3.312500</td>\n",
       "      <td>-0.145833</td>\n",
       "      <td>...</td>\n",
       "      <td>7.854166</td>\n",
       "      <td>-4.312500</td>\n",
       "      <td>-1.020833</td>\n",
       "      <td>1.270833</td>\n",
       "      <td>1.270833</td>\n",
       "      <td>9.312500</td>\n",
       "      <td>-7.479166</td>\n",
       "      <td>-3.354167</td>\n",
       "      <td>-3.354167</td>\n",
       "      <td>-0.187500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S.1</th>\n",
       "      <td>3.437500</td>\n",
       "      <td>-8.437500</td>\n",
       "      <td>13.187500</td>\n",
       "      <td>212.52083</td>\n",
       "      <td>-2.770833</td>\n",
       "      <td>-9.520833</td>\n",
       "      <td>22.604166</td>\n",
       "      <td>-7.270834</td>\n",
       "      <td>-1.354167</td>\n",
       "      <td>38.729168</td>\n",
       "      <td>...</td>\n",
       "      <td>17.562500</td>\n",
       "      <td>-3.895833</td>\n",
       "      <td>-3.895833</td>\n",
       "      <td>2.145833</td>\n",
       "      <td>3.395833</td>\n",
       "      <td>-6.145834</td>\n",
       "      <td>-0.229167</td>\n",
       "      <td>-2.812500</td>\n",
       "      <td>-3.895833</td>\n",
       "      <td>8.812500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S.2</th>\n",
       "      <td>8.270833</td>\n",
       "      <td>-5.354166</td>\n",
       "      <td>9.145833</td>\n",
       "      <td>530.93750</td>\n",
       "      <td>-2.604167</td>\n",
       "      <td>-4.395834</td>\n",
       "      <td>8.270833</td>\n",
       "      <td>-3.395833</td>\n",
       "      <td>-4.395834</td>\n",
       "      <td>61.770832</td>\n",
       "      <td>...</td>\n",
       "      <td>4.937500</td>\n",
       "      <td>-7.187500</td>\n",
       "      <td>-5.395834</td>\n",
       "      <td>-3.437500</td>\n",
       "      <td>-2.645833</td>\n",
       "      <td>-3.437500</td>\n",
       "      <td>-9.312500</td>\n",
       "      <td>-5.395834</td>\n",
       "      <td>-1.770833</td>\n",
       "      <td>5.770834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S.3</th>\n",
       "      <td>-3.145833</td>\n",
       "      <td>-1.187500</td>\n",
       "      <td>18.645834</td>\n",
       "      <td>388.18750</td>\n",
       "      <td>-1.187500</td>\n",
       "      <td>-1.187500</td>\n",
       "      <td>2.604167</td>\n",
       "      <td>-9.812500</td>\n",
       "      <td>8.354167</td>\n",
       "      <td>37.854168</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.437500</td>\n",
       "      <td>-9.854167</td>\n",
       "      <td>-6.104166</td>\n",
       "      <td>-7.062500</td>\n",
       "      <td>-1.229167</td>\n",
       "      <td>-3.187500</td>\n",
       "      <td>-0.437500</td>\n",
       "      <td>3.604167</td>\n",
       "      <td>-5.145834</td>\n",
       "      <td>-5.145834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T.1</th>\n",
       "      <td>11.437500</td>\n",
       "      <td>2.895833</td>\n",
       "      <td>43.479168</td>\n",
       "      <td>475.18750</td>\n",
       "      <td>-6.270834</td>\n",
       "      <td>-3.437500</td>\n",
       "      <td>14.562500</td>\n",
       "      <td>-9.312500</td>\n",
       "      <td>-1.770833</td>\n",
       "      <td>22.354166</td>\n",
       "      <td>...</td>\n",
       "      <td>1.937500</td>\n",
       "      <td>-6.312500</td>\n",
       "      <td>-10.312500</td>\n",
       "      <td>-8.354167</td>\n",
       "      <td>5.354166</td>\n",
       "      <td>-2.770833</td>\n",
       "      <td>-1.812500</td>\n",
       "      <td>-0.937500</td>\n",
       "      <td>-1.812500</td>\n",
       "      <td>3.687500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T.2</th>\n",
       "      <td>14.020833</td>\n",
       "      <td>-3.687500</td>\n",
       "      <td>10.979167</td>\n",
       "      <td>490.60416</td>\n",
       "      <td>-4.479166</td>\n",
       "      <td>-1.937500</td>\n",
       "      <td>17.437500</td>\n",
       "      <td>-7.312500</td>\n",
       "      <td>-0.937500</td>\n",
       "      <td>14.020833</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.979167</td>\n",
       "      <td>-0.979167</td>\n",
       "      <td>-7.354166</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>-0.979167</td>\n",
       "      <td>9.437500</td>\n",
       "      <td>-4.520834</td>\n",
       "      <td>-6.354166</td>\n",
       "      <td>-1.979167</td>\n",
       "      <td>-1.979167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T.3</th>\n",
       "      <td>11.187500</td>\n",
       "      <td>-3.354167</td>\n",
       "      <td>17.062500</td>\n",
       "      <td>600.18750</td>\n",
       "      <td>-8.229167</td>\n",
       "      <td>-1.270833</td>\n",
       "      <td>8.062500</td>\n",
       "      <td>-7.229166</td>\n",
       "      <td>9.604167</td>\n",
       "      <td>18.354166</td>\n",
       "      <td>...</td>\n",
       "      <td>1.479167</td>\n",
       "      <td>-5.354166</td>\n",
       "      <td>-3.395833</td>\n",
       "      <td>-2.354167</td>\n",
       "      <td>-0.479167</td>\n",
       "      <td>-2.354167</td>\n",
       "      <td>-3.395833</td>\n",
       "      <td>-7.270834</td>\n",
       "      <td>1.479167</td>\n",
       "      <td>6.187500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13 rows × 47332 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "ID_REF  ILMN_1725881  ILMN_1910180  ILMN_1804174  ILMN_1796063  ILMN_3284771  \\\n",
       "B.1        10.479167     -0.687500     16.854166     401.56250      0.354167   \n",
       "B.2         4.937500      2.229167      7.562500     416.60416     -2.895833   \n",
       "B.3        16.812500     -1.437500      1.145833     229.02083     -7.729166   \n",
       "B.4         9.062500     23.270834     31.895834     466.81250     -7.520834   \n",
       "HC.1        1.854167      4.312500      0.187500     473.22916     -5.937500   \n",
       "HC.2        9.104167      3.270833     40.145832     309.27084     -4.895834   \n",
       "HC.3       15.104167      3.479167     29.187500     536.47920     -0.979167   \n",
       "S.1         3.437500     -8.437500     13.187500     212.52083     -2.770833   \n",
       "S.2         8.270833     -5.354166      9.145833     530.93750     -2.604167   \n",
       "S.3        -3.145833     -1.187500     18.645834     388.18750     -1.187500   \n",
       "T.1        11.437500      2.895833     43.479168     475.18750     -6.270834   \n",
       "T.2        14.020833     -3.687500     10.979167     490.60416     -4.479166   \n",
       "T.3        11.187500     -3.354167     17.062500     600.18750     -8.229167   \n",
       "\n",
       "ID_REF  ILMN_3208259  ILMN_1811966  ILMN_1668162  ILMN_1715600  ILMN_1912287  \\\n",
       "B.1         2.354167      9.562500     -7.645834     -7.645834     13.645833   \n",
       "B.2        -0.354167      2.229167     -7.770834     -4.020834     15.687500   \n",
       "B.3         3.770833      3.770833      5.104166     -9.979167     61.520832   \n",
       "B.4        -4.229166     16.979166    -11.187500     10.187500     27.229166   \n",
       "HC.1       -3.229167     30.229166     -0.812500     13.729167      5.187500   \n",
       "HC.2        0.395833     16.354166    -10.187500     -3.270833     10.645833   \n",
       "HC.3       -6.479166      7.895834     -0.145833     -3.312500     -0.145833   \n",
       "S.1        -9.520833     22.604166     -7.270834     -1.354167     38.729168   \n",
       "S.2        -4.395834      8.270833     -3.395833     -4.395834     61.770832   \n",
       "S.3        -1.187500      2.604167     -9.812500      8.354167     37.854168   \n",
       "T.1        -3.437500     14.562500     -9.312500     -1.770833     22.354166   \n",
       "T.2        -1.937500     17.437500     -7.312500     -0.937500     14.020833   \n",
       "T.3        -1.270833      8.062500     -7.229166      9.604167     18.354166   \n",
       "\n",
       "ID_REF  ...  ILMN_3166640  ILMN_3166655  ILMN_3166673  ILMN_3166687  \\\n",
       "B.1     ...      3.187500     -3.604167     -5.645834     -4.562500   \n",
       "B.2     ...     12.979167      0.854167     -6.604166     -4.104166   \n",
       "B.3     ...     -6.437500     -2.854167     -2.854167      1.104167   \n",
       "B.4     ...     -0.604167      5.395834     -9.812500     -1.854167   \n",
       "HC.1    ...      0.979167     -2.395833     -2.395833     -2.395833   \n",
       "HC.2    ...      9.770833     -8.437500    -10.229167      2.729167   \n",
       "HC.3    ...      7.854166     -4.312500     -1.020833      1.270833   \n",
       "S.1     ...     17.562500     -3.895833     -3.895833      2.145833   \n",
       "S.2     ...      4.937500     -7.187500     -5.395834     -3.437500   \n",
       "S.3     ...     -0.437500     -9.854167     -6.104166     -7.062500   \n",
       "T.1     ...      1.937500     -6.312500    -10.312500     -8.354167   \n",
       "T.2     ...     -0.979167     -0.979167     -7.354166      0.020833   \n",
       "T.3     ...      1.479167     -5.354166     -3.395833     -2.354167   \n",
       "\n",
       "ID_REF  ILMN_3166703  ILMN_3166721  ILMN_3166728  ILMN_3166775  ILMN_3166789  \\\n",
       "B.1         7.770834     -1.729167     -8.687500     -0.729167     -0.729167   \n",
       "B.2         3.562500     -0.395833     -6.604166     -0.395833     -7.812500   \n",
       "B.3        -0.312500      6.562500      1.104167    -11.187500     -0.312500   \n",
       "B.4         5.395834     -1.854167     -7.562500     -3.020833     -3.020833   \n",
       "HC.1       -6.812500      6.770834     -2.395833     -6.812500      6.770834   \n",
       "HC.2       -2.604167      1.229167     -4.937500     -1.062500     -3.312500   \n",
       "HC.3        1.270833      9.312500     -7.479166     -3.354167     -3.354167   \n",
       "S.1         3.395833     -6.145834     -0.229167     -2.812500     -3.895833   \n",
       "S.2        -2.645833     -3.437500     -9.312500     -5.395834     -1.770833   \n",
       "S.3        -1.229167     -3.187500     -0.437500      3.604167     -5.145834   \n",
       "T.1         5.354166     -2.770833     -1.812500     -0.937500     -1.812500   \n",
       "T.2        -0.979167      9.437500     -4.520834     -6.354166     -1.979167   \n",
       "T.3        -0.479167     -2.354167     -3.395833     -7.270834      1.479167   \n",
       "\n",
       "ID_REF  ILMN_3166804  \n",
       "B.1         1.312500  \n",
       "B.2         3.562500  \n",
       "B.3        -1.479167  \n",
       "B.4        -0.604167  \n",
       "HC.1       -6.812500  \n",
       "HC.2        1.979167  \n",
       "HC.3       -0.187500  \n",
       "S.1         8.812500  \n",
       "S.2         5.770834  \n",
       "S.3        -5.145834  \n",
       "T.1         3.687500  \n",
       "T.2        -1.979167  \n",
       "T.3         6.187500  \n",
       "\n",
       "[13 rows x 47332 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transponer la base de datos\n",
    "df_T = df.transpose()\n",
    "\n",
    "# guardar la base de datos transpuesta en un archivo csv\n",
    "df_T.to_csv('archivo_transpuesto.csv', index=False)\n",
    "df_T.head(13)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bbe412f",
   "metadata": {},
   "source": [
    "# Nuevo Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee908dff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>ID_REF</th>\n",
       "      <th>ILMN_1725881</th>\n",
       "      <th>ILMN_1910180</th>\n",
       "      <th>ILMN_1804174</th>\n",
       "      <th>ILMN_1796063</th>\n",
       "      <th>ILMN_3284771</th>\n",
       "      <th>ILMN_3208259</th>\n",
       "      <th>ILMN_1811966</th>\n",
       "      <th>ILMN_1668162</th>\n",
       "      <th>ILMN_1715600</th>\n",
       "      <th>ILMN_1912287</th>\n",
       "      <th>...</th>\n",
       "      <th>ILMN_3166655</th>\n",
       "      <th>ILMN_3166673</th>\n",
       "      <th>ILMN_3166687</th>\n",
       "      <th>ILMN_3166703</th>\n",
       "      <th>ILMN_3166721</th>\n",
       "      <th>ILMN_3166728</th>\n",
       "      <th>ILMN_3166775</th>\n",
       "      <th>ILMN_3166789</th>\n",
       "      <th>ILMN_3166804</th>\n",
       "      <th>ESTADO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>B.1</th>\n",
       "      <td>10.479167</td>\n",
       "      <td>-0.687500</td>\n",
       "      <td>16.854166</td>\n",
       "      <td>401.56250</td>\n",
       "      <td>0.354167</td>\n",
       "      <td>2.354167</td>\n",
       "      <td>9.562500</td>\n",
       "      <td>-7.645834</td>\n",
       "      <td>-7.645834</td>\n",
       "      <td>13.645833</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.604167</td>\n",
       "      <td>-5.645834</td>\n",
       "      <td>-4.562500</td>\n",
       "      <td>7.770834</td>\n",
       "      <td>-1.729167</td>\n",
       "      <td>-8.687500</td>\n",
       "      <td>-0.729167</td>\n",
       "      <td>-0.729167</td>\n",
       "      <td>1.312500</td>\n",
       "      <td>metastatic_breast_cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B.2</th>\n",
       "      <td>4.937500</td>\n",
       "      <td>2.229167</td>\n",
       "      <td>7.562500</td>\n",
       "      <td>416.60416</td>\n",
       "      <td>-2.895833</td>\n",
       "      <td>-0.354167</td>\n",
       "      <td>2.229167</td>\n",
       "      <td>-7.770834</td>\n",
       "      <td>-4.020834</td>\n",
       "      <td>15.687500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854167</td>\n",
       "      <td>-6.604166</td>\n",
       "      <td>-4.104166</td>\n",
       "      <td>3.562500</td>\n",
       "      <td>-0.395833</td>\n",
       "      <td>-6.604166</td>\n",
       "      <td>-0.395833</td>\n",
       "      <td>-7.812500</td>\n",
       "      <td>3.562500</td>\n",
       "      <td>metastatic_breast_cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B.3</th>\n",
       "      <td>16.812500</td>\n",
       "      <td>-1.437500</td>\n",
       "      <td>1.145833</td>\n",
       "      <td>229.02083</td>\n",
       "      <td>-7.729166</td>\n",
       "      <td>3.770833</td>\n",
       "      <td>3.770833</td>\n",
       "      <td>5.104166</td>\n",
       "      <td>-9.979167</td>\n",
       "      <td>61.520832</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.854167</td>\n",
       "      <td>-2.854167</td>\n",
       "      <td>1.104167</td>\n",
       "      <td>-0.312500</td>\n",
       "      <td>6.562500</td>\n",
       "      <td>1.104167</td>\n",
       "      <td>-11.187500</td>\n",
       "      <td>-0.312500</td>\n",
       "      <td>-1.479167</td>\n",
       "      <td>metastatic_breast_cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B.4</th>\n",
       "      <td>9.062500</td>\n",
       "      <td>23.270834</td>\n",
       "      <td>31.895834</td>\n",
       "      <td>466.81250</td>\n",
       "      <td>-7.520834</td>\n",
       "      <td>-4.229166</td>\n",
       "      <td>16.979166</td>\n",
       "      <td>-11.187500</td>\n",
       "      <td>10.187500</td>\n",
       "      <td>27.229166</td>\n",
       "      <td>...</td>\n",
       "      <td>5.395834</td>\n",
       "      <td>-9.812500</td>\n",
       "      <td>-1.854167</td>\n",
       "      <td>5.395834</td>\n",
       "      <td>-1.854167</td>\n",
       "      <td>-7.562500</td>\n",
       "      <td>-3.020833</td>\n",
       "      <td>-3.020833</td>\n",
       "      <td>-0.604167</td>\n",
       "      <td>metastatic_breast_cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HC.1</th>\n",
       "      <td>1.854167</td>\n",
       "      <td>4.312500</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>473.22916</td>\n",
       "      <td>-5.937500</td>\n",
       "      <td>-3.229167</td>\n",
       "      <td>30.229166</td>\n",
       "      <td>-0.812500</td>\n",
       "      <td>13.729167</td>\n",
       "      <td>5.187500</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.395833</td>\n",
       "      <td>-2.395833</td>\n",
       "      <td>-2.395833</td>\n",
       "      <td>-6.812500</td>\n",
       "      <td>6.770834</td>\n",
       "      <td>-2.395833</td>\n",
       "      <td>-6.812500</td>\n",
       "      <td>6.770834</td>\n",
       "      <td>-6.812500</td>\n",
       "      <td>healthy_control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HC.2</th>\n",
       "      <td>9.104167</td>\n",
       "      <td>3.270833</td>\n",
       "      <td>40.145832</td>\n",
       "      <td>309.27084</td>\n",
       "      <td>-4.895834</td>\n",
       "      <td>0.395833</td>\n",
       "      <td>16.354166</td>\n",
       "      <td>-10.187500</td>\n",
       "      <td>-3.270833</td>\n",
       "      <td>10.645833</td>\n",
       "      <td>...</td>\n",
       "      <td>-8.437500</td>\n",
       "      <td>-10.229167</td>\n",
       "      <td>2.729167</td>\n",
       "      <td>-2.604167</td>\n",
       "      <td>1.229167</td>\n",
       "      <td>-4.937500</td>\n",
       "      <td>-1.062500</td>\n",
       "      <td>-3.312500</td>\n",
       "      <td>1.979167</td>\n",
       "      <td>healthy_control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HC.3</th>\n",
       "      <td>15.104167</td>\n",
       "      <td>3.479167</td>\n",
       "      <td>29.187500</td>\n",
       "      <td>536.47920</td>\n",
       "      <td>-0.979167</td>\n",
       "      <td>-6.479166</td>\n",
       "      <td>7.895834</td>\n",
       "      <td>-0.145833</td>\n",
       "      <td>-3.312500</td>\n",
       "      <td>-0.145833</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.312500</td>\n",
       "      <td>-1.020833</td>\n",
       "      <td>1.270833</td>\n",
       "      <td>1.270833</td>\n",
       "      <td>9.312500</td>\n",
       "      <td>-7.479166</td>\n",
       "      <td>-3.354167</td>\n",
       "      <td>-3.354167</td>\n",
       "      <td>-0.187500</td>\n",
       "      <td>healthy_control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S.1</th>\n",
       "      <td>3.437500</td>\n",
       "      <td>-8.437500</td>\n",
       "      <td>13.187500</td>\n",
       "      <td>212.52083</td>\n",
       "      <td>-2.770833</td>\n",
       "      <td>-9.520833</td>\n",
       "      <td>22.604166</td>\n",
       "      <td>-7.270834</td>\n",
       "      <td>-1.354167</td>\n",
       "      <td>38.729168</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.895833</td>\n",
       "      <td>-3.895833</td>\n",
       "      <td>2.145833</td>\n",
       "      <td>3.395833</td>\n",
       "      <td>-6.145834</td>\n",
       "      <td>-0.229167</td>\n",
       "      <td>-2.812500</td>\n",
       "      <td>-3.895833</td>\n",
       "      <td>8.812500</td>\n",
       "      <td>gram_negative_sepsis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S.2</th>\n",
       "      <td>8.270833</td>\n",
       "      <td>-5.354166</td>\n",
       "      <td>9.145833</td>\n",
       "      <td>530.93750</td>\n",
       "      <td>-2.604167</td>\n",
       "      <td>-4.395834</td>\n",
       "      <td>8.270833</td>\n",
       "      <td>-3.395833</td>\n",
       "      <td>-4.395834</td>\n",
       "      <td>61.770832</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.187500</td>\n",
       "      <td>-5.395834</td>\n",
       "      <td>-3.437500</td>\n",
       "      <td>-2.645833</td>\n",
       "      <td>-3.437500</td>\n",
       "      <td>-9.312500</td>\n",
       "      <td>-5.395834</td>\n",
       "      <td>-1.770833</td>\n",
       "      <td>5.770834</td>\n",
       "      <td>gram_negative_sepsis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S.3</th>\n",
       "      <td>-3.145833</td>\n",
       "      <td>-1.187500</td>\n",
       "      <td>18.645834</td>\n",
       "      <td>388.18750</td>\n",
       "      <td>-1.187500</td>\n",
       "      <td>-1.187500</td>\n",
       "      <td>2.604167</td>\n",
       "      <td>-9.812500</td>\n",
       "      <td>8.354167</td>\n",
       "      <td>37.854168</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.854167</td>\n",
       "      <td>-6.104166</td>\n",
       "      <td>-7.062500</td>\n",
       "      <td>-1.229167</td>\n",
       "      <td>-3.187500</td>\n",
       "      <td>-0.437500</td>\n",
       "      <td>3.604167</td>\n",
       "      <td>-5.145834</td>\n",
       "      <td>-5.145834</td>\n",
       "      <td>gram_negative_sepsis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T.1</th>\n",
       "      <td>11.437500</td>\n",
       "      <td>2.895833</td>\n",
       "      <td>43.479168</td>\n",
       "      <td>475.18750</td>\n",
       "      <td>-6.270834</td>\n",
       "      <td>-3.437500</td>\n",
       "      <td>14.562500</td>\n",
       "      <td>-9.312500</td>\n",
       "      <td>-1.770833</td>\n",
       "      <td>22.354166</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.312500</td>\n",
       "      <td>-10.312500</td>\n",
       "      <td>-8.354167</td>\n",
       "      <td>5.354166</td>\n",
       "      <td>-2.770833</td>\n",
       "      <td>-1.812500</td>\n",
       "      <td>-0.937500</td>\n",
       "      <td>-1.812500</td>\n",
       "      <td>3.687500</td>\n",
       "      <td>tuberculosis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T.2</th>\n",
       "      <td>14.020833</td>\n",
       "      <td>-3.687500</td>\n",
       "      <td>10.979167</td>\n",
       "      <td>490.60416</td>\n",
       "      <td>-4.479166</td>\n",
       "      <td>-1.937500</td>\n",
       "      <td>17.437500</td>\n",
       "      <td>-7.312500</td>\n",
       "      <td>-0.937500</td>\n",
       "      <td>14.020833</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.979167</td>\n",
       "      <td>-7.354166</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>-0.979167</td>\n",
       "      <td>9.437500</td>\n",
       "      <td>-4.520834</td>\n",
       "      <td>-6.354166</td>\n",
       "      <td>-1.979167</td>\n",
       "      <td>-1.979167</td>\n",
       "      <td>tuberculosis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T.3</th>\n",
       "      <td>11.187500</td>\n",
       "      <td>-3.354167</td>\n",
       "      <td>17.062500</td>\n",
       "      <td>600.18750</td>\n",
       "      <td>-8.229167</td>\n",
       "      <td>-1.270833</td>\n",
       "      <td>8.062500</td>\n",
       "      <td>-7.229166</td>\n",
       "      <td>9.604167</td>\n",
       "      <td>18.354166</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.354166</td>\n",
       "      <td>-3.395833</td>\n",
       "      <td>-2.354167</td>\n",
       "      <td>-0.479167</td>\n",
       "      <td>-2.354167</td>\n",
       "      <td>-3.395833</td>\n",
       "      <td>-7.270834</td>\n",
       "      <td>1.479167</td>\n",
       "      <td>6.187500</td>\n",
       "      <td>tuberculosis</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13 rows × 47333 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "ID_REF  ILMN_1725881  ILMN_1910180  ILMN_1804174  ILMN_1796063  ILMN_3284771  \\\n",
       "B.1        10.479167     -0.687500     16.854166     401.56250      0.354167   \n",
       "B.2         4.937500      2.229167      7.562500     416.60416     -2.895833   \n",
       "B.3        16.812500     -1.437500      1.145833     229.02083     -7.729166   \n",
       "B.4         9.062500     23.270834     31.895834     466.81250     -7.520834   \n",
       "HC.1        1.854167      4.312500      0.187500     473.22916     -5.937500   \n",
       "HC.2        9.104167      3.270833     40.145832     309.27084     -4.895834   \n",
       "HC.3       15.104167      3.479167     29.187500     536.47920     -0.979167   \n",
       "S.1         3.437500     -8.437500     13.187500     212.52083     -2.770833   \n",
       "S.2         8.270833     -5.354166      9.145833     530.93750     -2.604167   \n",
       "S.3        -3.145833     -1.187500     18.645834     388.18750     -1.187500   \n",
       "T.1        11.437500      2.895833     43.479168     475.18750     -6.270834   \n",
       "T.2        14.020833     -3.687500     10.979167     490.60416     -4.479166   \n",
       "T.3        11.187500     -3.354167     17.062500     600.18750     -8.229167   \n",
       "\n",
       "ID_REF  ILMN_3208259  ILMN_1811966  ILMN_1668162  ILMN_1715600  ILMN_1912287  \\\n",
       "B.1         2.354167      9.562500     -7.645834     -7.645834     13.645833   \n",
       "B.2        -0.354167      2.229167     -7.770834     -4.020834     15.687500   \n",
       "B.3         3.770833      3.770833      5.104166     -9.979167     61.520832   \n",
       "B.4        -4.229166     16.979166    -11.187500     10.187500     27.229166   \n",
       "HC.1       -3.229167     30.229166     -0.812500     13.729167      5.187500   \n",
       "HC.2        0.395833     16.354166    -10.187500     -3.270833     10.645833   \n",
       "HC.3       -6.479166      7.895834     -0.145833     -3.312500     -0.145833   \n",
       "S.1        -9.520833     22.604166     -7.270834     -1.354167     38.729168   \n",
       "S.2        -4.395834      8.270833     -3.395833     -4.395834     61.770832   \n",
       "S.3        -1.187500      2.604167     -9.812500      8.354167     37.854168   \n",
       "T.1        -3.437500     14.562500     -9.312500     -1.770833     22.354166   \n",
       "T.2        -1.937500     17.437500     -7.312500     -0.937500     14.020833   \n",
       "T.3        -1.270833      8.062500     -7.229166      9.604167     18.354166   \n",
       "\n",
       "ID_REF  ...  ILMN_3166655  ILMN_3166673  ILMN_3166687  ILMN_3166703  \\\n",
       "B.1     ...     -3.604167     -5.645834     -4.562500      7.770834   \n",
       "B.2     ...      0.854167     -6.604166     -4.104166      3.562500   \n",
       "B.3     ...     -2.854167     -2.854167      1.104167     -0.312500   \n",
       "B.4     ...      5.395834     -9.812500     -1.854167      5.395834   \n",
       "HC.1    ...     -2.395833     -2.395833     -2.395833     -6.812500   \n",
       "HC.2    ...     -8.437500    -10.229167      2.729167     -2.604167   \n",
       "HC.3    ...     -4.312500     -1.020833      1.270833      1.270833   \n",
       "S.1     ...     -3.895833     -3.895833      2.145833      3.395833   \n",
       "S.2     ...     -7.187500     -5.395834     -3.437500     -2.645833   \n",
       "S.3     ...     -9.854167     -6.104166     -7.062500     -1.229167   \n",
       "T.1     ...     -6.312500    -10.312500     -8.354167      5.354166   \n",
       "T.2     ...     -0.979167     -7.354166      0.020833     -0.979167   \n",
       "T.3     ...     -5.354166     -3.395833     -2.354167     -0.479167   \n",
       "\n",
       "ID_REF  ILMN_3166721  ILMN_3166728  ILMN_3166775  ILMN_3166789  ILMN_3166804  \\\n",
       "B.1        -1.729167     -8.687500     -0.729167     -0.729167      1.312500   \n",
       "B.2        -0.395833     -6.604166     -0.395833     -7.812500      3.562500   \n",
       "B.3         6.562500      1.104167    -11.187500     -0.312500     -1.479167   \n",
       "B.4        -1.854167     -7.562500     -3.020833     -3.020833     -0.604167   \n",
       "HC.1        6.770834     -2.395833     -6.812500      6.770834     -6.812500   \n",
       "HC.2        1.229167     -4.937500     -1.062500     -3.312500      1.979167   \n",
       "HC.3        9.312500     -7.479166     -3.354167     -3.354167     -0.187500   \n",
       "S.1        -6.145834     -0.229167     -2.812500     -3.895833      8.812500   \n",
       "S.2        -3.437500     -9.312500     -5.395834     -1.770833      5.770834   \n",
       "S.3        -3.187500     -0.437500      3.604167     -5.145834     -5.145834   \n",
       "T.1        -2.770833     -1.812500     -0.937500     -1.812500      3.687500   \n",
       "T.2         9.437500     -4.520834     -6.354166     -1.979167     -1.979167   \n",
       "T.3        -2.354167     -3.395833     -7.270834      1.479167      6.187500   \n",
       "\n",
       "ID_REF                    ESTADO  \n",
       "B.1     metastatic_breast_cancer  \n",
       "B.2     metastatic_breast_cancer  \n",
       "B.3     metastatic_breast_cancer  \n",
       "B.4     metastatic_breast_cancer  \n",
       "HC.1             healthy_control  \n",
       "HC.2             healthy_control  \n",
       "HC.3             healthy_control  \n",
       "S.1         gram_negative_sepsis  \n",
       "S.2         gram_negative_sepsis  \n",
       "S.3         gram_negative_sepsis  \n",
       "T.1                 tuberculosis  \n",
       "T.2                 tuberculosis  \n",
       "T.3                 tuberculosis  \n",
       "\n",
       "[13 rows x 47333 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_T['ESTADO'] = ['metastatic_breast_cancer', 'metastatic_breast_cancer', 'metastatic_breast_cancer', \n",
    "          'metastatic_breast_cancer', 'healthy_control', 'healthy_control', 'healthy_control', \n",
    "          'gram_negative_sepsis', 'gram_negative_sepsis', 'gram_negative_sepsis', 'tuberculosis', \n",
    "          'tuberculosis', 'tuberculosis']\n",
    "\n",
    "#df_T['ESTADO'] = estado\n",
    "# Primary human monocytes from patient with metastatic breast cancer:B1, B2, B3, B4\n",
    "# Primary human monocytes from healthy control: H1,H2, H3\n",
    "# Primary human monocytes from patient with gram-negative sepsis: S1,S2, S3\n",
    "# Primary human monocytes from patient with tuberculosis:T1, T2, T3\n",
    "df_T.head(13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "64efe7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primero tenemos que generar el objeto\n",
    "codificacion = LabelEncoder()\n",
    "# Ahora se ajusta a los datos\n",
    "df_T['ESTADO']=codificacion.fit_transform(df_T['ESTADO'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97b18be3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>ID_REF</th>\n",
       "      <th>ILMN_1725881</th>\n",
       "      <th>ILMN_1910180</th>\n",
       "      <th>ILMN_1804174</th>\n",
       "      <th>ILMN_1796063</th>\n",
       "      <th>ILMN_3284771</th>\n",
       "      <th>ILMN_3208259</th>\n",
       "      <th>ILMN_1811966</th>\n",
       "      <th>ILMN_1668162</th>\n",
       "      <th>ILMN_1715600</th>\n",
       "      <th>ILMN_1912287</th>\n",
       "      <th>...</th>\n",
       "      <th>ILMN_3166655</th>\n",
       "      <th>ILMN_3166673</th>\n",
       "      <th>ILMN_3166687</th>\n",
       "      <th>ILMN_3166703</th>\n",
       "      <th>ILMN_3166721</th>\n",
       "      <th>ILMN_3166728</th>\n",
       "      <th>ILMN_3166775</th>\n",
       "      <th>ILMN_3166789</th>\n",
       "      <th>ILMN_3166804</th>\n",
       "      <th>ESTADO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>B.1</th>\n",
       "      <td>10.479167</td>\n",
       "      <td>-0.687500</td>\n",
       "      <td>16.854166</td>\n",
       "      <td>401.56250</td>\n",
       "      <td>0.354167</td>\n",
       "      <td>2.354167</td>\n",
       "      <td>9.562500</td>\n",
       "      <td>-7.645834</td>\n",
       "      <td>-7.645834</td>\n",
       "      <td>13.645833</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.604167</td>\n",
       "      <td>-5.645834</td>\n",
       "      <td>-4.562500</td>\n",
       "      <td>7.770834</td>\n",
       "      <td>-1.729167</td>\n",
       "      <td>-8.687500</td>\n",
       "      <td>-0.729167</td>\n",
       "      <td>-0.729167</td>\n",
       "      <td>1.312500</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B.2</th>\n",
       "      <td>4.937500</td>\n",
       "      <td>2.229167</td>\n",
       "      <td>7.562500</td>\n",
       "      <td>416.60416</td>\n",
       "      <td>-2.895833</td>\n",
       "      <td>-0.354167</td>\n",
       "      <td>2.229167</td>\n",
       "      <td>-7.770834</td>\n",
       "      <td>-4.020834</td>\n",
       "      <td>15.687500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854167</td>\n",
       "      <td>-6.604166</td>\n",
       "      <td>-4.104166</td>\n",
       "      <td>3.562500</td>\n",
       "      <td>-0.395833</td>\n",
       "      <td>-6.604166</td>\n",
       "      <td>-0.395833</td>\n",
       "      <td>-7.812500</td>\n",
       "      <td>3.562500</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B.3</th>\n",
       "      <td>16.812500</td>\n",
       "      <td>-1.437500</td>\n",
       "      <td>1.145833</td>\n",
       "      <td>229.02083</td>\n",
       "      <td>-7.729166</td>\n",
       "      <td>3.770833</td>\n",
       "      <td>3.770833</td>\n",
       "      <td>5.104166</td>\n",
       "      <td>-9.979167</td>\n",
       "      <td>61.520832</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.854167</td>\n",
       "      <td>-2.854167</td>\n",
       "      <td>1.104167</td>\n",
       "      <td>-0.312500</td>\n",
       "      <td>6.562500</td>\n",
       "      <td>1.104167</td>\n",
       "      <td>-11.187500</td>\n",
       "      <td>-0.312500</td>\n",
       "      <td>-1.479167</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B.4</th>\n",
       "      <td>9.062500</td>\n",
       "      <td>23.270834</td>\n",
       "      <td>31.895834</td>\n",
       "      <td>466.81250</td>\n",
       "      <td>-7.520834</td>\n",
       "      <td>-4.229166</td>\n",
       "      <td>16.979166</td>\n",
       "      <td>-11.187500</td>\n",
       "      <td>10.187500</td>\n",
       "      <td>27.229166</td>\n",
       "      <td>...</td>\n",
       "      <td>5.395834</td>\n",
       "      <td>-9.812500</td>\n",
       "      <td>-1.854167</td>\n",
       "      <td>5.395834</td>\n",
       "      <td>-1.854167</td>\n",
       "      <td>-7.562500</td>\n",
       "      <td>-3.020833</td>\n",
       "      <td>-3.020833</td>\n",
       "      <td>-0.604167</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HC.1</th>\n",
       "      <td>1.854167</td>\n",
       "      <td>4.312500</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>473.22916</td>\n",
       "      <td>-5.937500</td>\n",
       "      <td>-3.229167</td>\n",
       "      <td>30.229166</td>\n",
       "      <td>-0.812500</td>\n",
       "      <td>13.729167</td>\n",
       "      <td>5.187500</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.395833</td>\n",
       "      <td>-2.395833</td>\n",
       "      <td>-2.395833</td>\n",
       "      <td>-6.812500</td>\n",
       "      <td>6.770834</td>\n",
       "      <td>-2.395833</td>\n",
       "      <td>-6.812500</td>\n",
       "      <td>6.770834</td>\n",
       "      <td>-6.812500</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HC.2</th>\n",
       "      <td>9.104167</td>\n",
       "      <td>3.270833</td>\n",
       "      <td>40.145832</td>\n",
       "      <td>309.27084</td>\n",
       "      <td>-4.895834</td>\n",
       "      <td>0.395833</td>\n",
       "      <td>16.354166</td>\n",
       "      <td>-10.187500</td>\n",
       "      <td>-3.270833</td>\n",
       "      <td>10.645833</td>\n",
       "      <td>...</td>\n",
       "      <td>-8.437500</td>\n",
       "      <td>-10.229167</td>\n",
       "      <td>2.729167</td>\n",
       "      <td>-2.604167</td>\n",
       "      <td>1.229167</td>\n",
       "      <td>-4.937500</td>\n",
       "      <td>-1.062500</td>\n",
       "      <td>-3.312500</td>\n",
       "      <td>1.979167</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HC.3</th>\n",
       "      <td>15.104167</td>\n",
       "      <td>3.479167</td>\n",
       "      <td>29.187500</td>\n",
       "      <td>536.47920</td>\n",
       "      <td>-0.979167</td>\n",
       "      <td>-6.479166</td>\n",
       "      <td>7.895834</td>\n",
       "      <td>-0.145833</td>\n",
       "      <td>-3.312500</td>\n",
       "      <td>-0.145833</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.312500</td>\n",
       "      <td>-1.020833</td>\n",
       "      <td>1.270833</td>\n",
       "      <td>1.270833</td>\n",
       "      <td>9.312500</td>\n",
       "      <td>-7.479166</td>\n",
       "      <td>-3.354167</td>\n",
       "      <td>-3.354167</td>\n",
       "      <td>-0.187500</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S.1</th>\n",
       "      <td>3.437500</td>\n",
       "      <td>-8.437500</td>\n",
       "      <td>13.187500</td>\n",
       "      <td>212.52083</td>\n",
       "      <td>-2.770833</td>\n",
       "      <td>-9.520833</td>\n",
       "      <td>22.604166</td>\n",
       "      <td>-7.270834</td>\n",
       "      <td>-1.354167</td>\n",
       "      <td>38.729168</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.895833</td>\n",
       "      <td>-3.895833</td>\n",
       "      <td>2.145833</td>\n",
       "      <td>3.395833</td>\n",
       "      <td>-6.145834</td>\n",
       "      <td>-0.229167</td>\n",
       "      <td>-2.812500</td>\n",
       "      <td>-3.895833</td>\n",
       "      <td>8.812500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S.2</th>\n",
       "      <td>8.270833</td>\n",
       "      <td>-5.354166</td>\n",
       "      <td>9.145833</td>\n",
       "      <td>530.93750</td>\n",
       "      <td>-2.604167</td>\n",
       "      <td>-4.395834</td>\n",
       "      <td>8.270833</td>\n",
       "      <td>-3.395833</td>\n",
       "      <td>-4.395834</td>\n",
       "      <td>61.770832</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.187500</td>\n",
       "      <td>-5.395834</td>\n",
       "      <td>-3.437500</td>\n",
       "      <td>-2.645833</td>\n",
       "      <td>-3.437500</td>\n",
       "      <td>-9.312500</td>\n",
       "      <td>-5.395834</td>\n",
       "      <td>-1.770833</td>\n",
       "      <td>5.770834</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S.3</th>\n",
       "      <td>-3.145833</td>\n",
       "      <td>-1.187500</td>\n",
       "      <td>18.645834</td>\n",
       "      <td>388.18750</td>\n",
       "      <td>-1.187500</td>\n",
       "      <td>-1.187500</td>\n",
       "      <td>2.604167</td>\n",
       "      <td>-9.812500</td>\n",
       "      <td>8.354167</td>\n",
       "      <td>37.854168</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.854167</td>\n",
       "      <td>-6.104166</td>\n",
       "      <td>-7.062500</td>\n",
       "      <td>-1.229167</td>\n",
       "      <td>-3.187500</td>\n",
       "      <td>-0.437500</td>\n",
       "      <td>3.604167</td>\n",
       "      <td>-5.145834</td>\n",
       "      <td>-5.145834</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T.1</th>\n",
       "      <td>11.437500</td>\n",
       "      <td>2.895833</td>\n",
       "      <td>43.479168</td>\n",
       "      <td>475.18750</td>\n",
       "      <td>-6.270834</td>\n",
       "      <td>-3.437500</td>\n",
       "      <td>14.562500</td>\n",
       "      <td>-9.312500</td>\n",
       "      <td>-1.770833</td>\n",
       "      <td>22.354166</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.312500</td>\n",
       "      <td>-10.312500</td>\n",
       "      <td>-8.354167</td>\n",
       "      <td>5.354166</td>\n",
       "      <td>-2.770833</td>\n",
       "      <td>-1.812500</td>\n",
       "      <td>-0.937500</td>\n",
       "      <td>-1.812500</td>\n",
       "      <td>3.687500</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T.2</th>\n",
       "      <td>14.020833</td>\n",
       "      <td>-3.687500</td>\n",
       "      <td>10.979167</td>\n",
       "      <td>490.60416</td>\n",
       "      <td>-4.479166</td>\n",
       "      <td>-1.937500</td>\n",
       "      <td>17.437500</td>\n",
       "      <td>-7.312500</td>\n",
       "      <td>-0.937500</td>\n",
       "      <td>14.020833</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.979167</td>\n",
       "      <td>-7.354166</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>-0.979167</td>\n",
       "      <td>9.437500</td>\n",
       "      <td>-4.520834</td>\n",
       "      <td>-6.354166</td>\n",
       "      <td>-1.979167</td>\n",
       "      <td>-1.979167</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T.3</th>\n",
       "      <td>11.187500</td>\n",
       "      <td>-3.354167</td>\n",
       "      <td>17.062500</td>\n",
       "      <td>600.18750</td>\n",
       "      <td>-8.229167</td>\n",
       "      <td>-1.270833</td>\n",
       "      <td>8.062500</td>\n",
       "      <td>-7.229166</td>\n",
       "      <td>9.604167</td>\n",
       "      <td>18.354166</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.354166</td>\n",
       "      <td>-3.395833</td>\n",
       "      <td>-2.354167</td>\n",
       "      <td>-0.479167</td>\n",
       "      <td>-2.354167</td>\n",
       "      <td>-3.395833</td>\n",
       "      <td>-7.270834</td>\n",
       "      <td>1.479167</td>\n",
       "      <td>6.187500</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13 rows × 47333 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "ID_REF  ILMN_1725881  ILMN_1910180  ILMN_1804174  ILMN_1796063  ILMN_3284771  \\\n",
       "B.1        10.479167     -0.687500     16.854166     401.56250      0.354167   \n",
       "B.2         4.937500      2.229167      7.562500     416.60416     -2.895833   \n",
       "B.3        16.812500     -1.437500      1.145833     229.02083     -7.729166   \n",
       "B.4         9.062500     23.270834     31.895834     466.81250     -7.520834   \n",
       "HC.1        1.854167      4.312500      0.187500     473.22916     -5.937500   \n",
       "HC.2        9.104167      3.270833     40.145832     309.27084     -4.895834   \n",
       "HC.3       15.104167      3.479167     29.187500     536.47920     -0.979167   \n",
       "S.1         3.437500     -8.437500     13.187500     212.52083     -2.770833   \n",
       "S.2         8.270833     -5.354166      9.145833     530.93750     -2.604167   \n",
       "S.3        -3.145833     -1.187500     18.645834     388.18750     -1.187500   \n",
       "T.1        11.437500      2.895833     43.479168     475.18750     -6.270834   \n",
       "T.2        14.020833     -3.687500     10.979167     490.60416     -4.479166   \n",
       "T.3        11.187500     -3.354167     17.062500     600.18750     -8.229167   \n",
       "\n",
       "ID_REF  ILMN_3208259  ILMN_1811966  ILMN_1668162  ILMN_1715600  ILMN_1912287  \\\n",
       "B.1         2.354167      9.562500     -7.645834     -7.645834     13.645833   \n",
       "B.2        -0.354167      2.229167     -7.770834     -4.020834     15.687500   \n",
       "B.3         3.770833      3.770833      5.104166     -9.979167     61.520832   \n",
       "B.4        -4.229166     16.979166    -11.187500     10.187500     27.229166   \n",
       "HC.1       -3.229167     30.229166     -0.812500     13.729167      5.187500   \n",
       "HC.2        0.395833     16.354166    -10.187500     -3.270833     10.645833   \n",
       "HC.3       -6.479166      7.895834     -0.145833     -3.312500     -0.145833   \n",
       "S.1        -9.520833     22.604166     -7.270834     -1.354167     38.729168   \n",
       "S.2        -4.395834      8.270833     -3.395833     -4.395834     61.770832   \n",
       "S.3        -1.187500      2.604167     -9.812500      8.354167     37.854168   \n",
       "T.1        -3.437500     14.562500     -9.312500     -1.770833     22.354166   \n",
       "T.2        -1.937500     17.437500     -7.312500     -0.937500     14.020833   \n",
       "T.3        -1.270833      8.062500     -7.229166      9.604167     18.354166   \n",
       "\n",
       "ID_REF  ...  ILMN_3166655  ILMN_3166673  ILMN_3166687  ILMN_3166703  \\\n",
       "B.1     ...     -3.604167     -5.645834     -4.562500      7.770834   \n",
       "B.2     ...      0.854167     -6.604166     -4.104166      3.562500   \n",
       "B.3     ...     -2.854167     -2.854167      1.104167     -0.312500   \n",
       "B.4     ...      5.395834     -9.812500     -1.854167      5.395834   \n",
       "HC.1    ...     -2.395833     -2.395833     -2.395833     -6.812500   \n",
       "HC.2    ...     -8.437500    -10.229167      2.729167     -2.604167   \n",
       "HC.3    ...     -4.312500     -1.020833      1.270833      1.270833   \n",
       "S.1     ...     -3.895833     -3.895833      2.145833      3.395833   \n",
       "S.2     ...     -7.187500     -5.395834     -3.437500     -2.645833   \n",
       "S.3     ...     -9.854167     -6.104166     -7.062500     -1.229167   \n",
       "T.1     ...     -6.312500    -10.312500     -8.354167      5.354166   \n",
       "T.2     ...     -0.979167     -7.354166      0.020833     -0.979167   \n",
       "T.3     ...     -5.354166     -3.395833     -2.354167     -0.479167   \n",
       "\n",
       "ID_REF  ILMN_3166721  ILMN_3166728  ILMN_3166775  ILMN_3166789  ILMN_3166804  \\\n",
       "B.1        -1.729167     -8.687500     -0.729167     -0.729167      1.312500   \n",
       "B.2        -0.395833     -6.604166     -0.395833     -7.812500      3.562500   \n",
       "B.3         6.562500      1.104167    -11.187500     -0.312500     -1.479167   \n",
       "B.4        -1.854167     -7.562500     -3.020833     -3.020833     -0.604167   \n",
       "HC.1        6.770834     -2.395833     -6.812500      6.770834     -6.812500   \n",
       "HC.2        1.229167     -4.937500     -1.062500     -3.312500      1.979167   \n",
       "HC.3        9.312500     -7.479166     -3.354167     -3.354167     -0.187500   \n",
       "S.1        -6.145834     -0.229167     -2.812500     -3.895833      8.812500   \n",
       "S.2        -3.437500     -9.312500     -5.395834     -1.770833      5.770834   \n",
       "S.3        -3.187500     -0.437500      3.604167     -5.145834     -5.145834   \n",
       "T.1        -2.770833     -1.812500     -0.937500     -1.812500      3.687500   \n",
       "T.2         9.437500     -4.520834     -6.354166     -1.979167     -1.979167   \n",
       "T.3        -2.354167     -3.395833     -7.270834      1.479167      6.187500   \n",
       "\n",
       "ID_REF  ESTADO  \n",
       "B.1          2  \n",
       "B.2          2  \n",
       "B.3          2  \n",
       "B.4          2  \n",
       "HC.1         1  \n",
       "HC.2         1  \n",
       "HC.3         1  \n",
       "S.1          0  \n",
       "S.2          0  \n",
       "S.3          0  \n",
       "T.1          3  \n",
       "T.2          3  \n",
       "T.3          3  \n",
       "\n",
       "[13 rows x 47333 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_T.head(13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bdc83283",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se selecciona la variable objetivo, en este caso \"ESTADO\".\n",
    "\n",
    "target=df_T['ESTADO']\n",
    "# guardar la base de datos transpuesta en un archivo csv\n",
    "target.to_csv('target.csv', index=False)\n",
    "# Del conjunto de datos se elimina la variable \"ESTADO\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1fb44f94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>ID_REF</th>\n",
       "      <th>ILMN_1725881</th>\n",
       "      <th>ILMN_1910180</th>\n",
       "      <th>ILMN_1804174</th>\n",
       "      <th>ILMN_1796063</th>\n",
       "      <th>ILMN_3284771</th>\n",
       "      <th>ILMN_3208259</th>\n",
       "      <th>ILMN_1811966</th>\n",
       "      <th>ILMN_1668162</th>\n",
       "      <th>ILMN_1715600</th>\n",
       "      <th>ILMN_1912287</th>\n",
       "      <th>...</th>\n",
       "      <th>ILMN_3166640</th>\n",
       "      <th>ILMN_3166655</th>\n",
       "      <th>ILMN_3166673</th>\n",
       "      <th>ILMN_3166687</th>\n",
       "      <th>ILMN_3166703</th>\n",
       "      <th>ILMN_3166721</th>\n",
       "      <th>ILMN_3166728</th>\n",
       "      <th>ILMN_3166775</th>\n",
       "      <th>ILMN_3166789</th>\n",
       "      <th>ILMN_3166804</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>B.1</th>\n",
       "      <td>10.479167</td>\n",
       "      <td>-0.687500</td>\n",
       "      <td>16.854166</td>\n",
       "      <td>401.56250</td>\n",
       "      <td>0.354167</td>\n",
       "      <td>2.354167</td>\n",
       "      <td>9.562500</td>\n",
       "      <td>-7.645834</td>\n",
       "      <td>-7.645834</td>\n",
       "      <td>13.645833</td>\n",
       "      <td>...</td>\n",
       "      <td>3.187500</td>\n",
       "      <td>-3.604167</td>\n",
       "      <td>-5.645834</td>\n",
       "      <td>-4.562500</td>\n",
       "      <td>7.770834</td>\n",
       "      <td>-1.729167</td>\n",
       "      <td>-8.687500</td>\n",
       "      <td>-0.729167</td>\n",
       "      <td>-0.729167</td>\n",
       "      <td>1.312500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B.2</th>\n",
       "      <td>4.937500</td>\n",
       "      <td>2.229167</td>\n",
       "      <td>7.562500</td>\n",
       "      <td>416.60416</td>\n",
       "      <td>-2.895833</td>\n",
       "      <td>-0.354167</td>\n",
       "      <td>2.229167</td>\n",
       "      <td>-7.770834</td>\n",
       "      <td>-4.020834</td>\n",
       "      <td>15.687500</td>\n",
       "      <td>...</td>\n",
       "      <td>12.979167</td>\n",
       "      <td>0.854167</td>\n",
       "      <td>-6.604166</td>\n",
       "      <td>-4.104166</td>\n",
       "      <td>3.562500</td>\n",
       "      <td>-0.395833</td>\n",
       "      <td>-6.604166</td>\n",
       "      <td>-0.395833</td>\n",
       "      <td>-7.812500</td>\n",
       "      <td>3.562500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B.3</th>\n",
       "      <td>16.812500</td>\n",
       "      <td>-1.437500</td>\n",
       "      <td>1.145833</td>\n",
       "      <td>229.02083</td>\n",
       "      <td>-7.729166</td>\n",
       "      <td>3.770833</td>\n",
       "      <td>3.770833</td>\n",
       "      <td>5.104166</td>\n",
       "      <td>-9.979167</td>\n",
       "      <td>61.520832</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.437500</td>\n",
       "      <td>-2.854167</td>\n",
       "      <td>-2.854167</td>\n",
       "      <td>1.104167</td>\n",
       "      <td>-0.312500</td>\n",
       "      <td>6.562500</td>\n",
       "      <td>1.104167</td>\n",
       "      <td>-11.187500</td>\n",
       "      <td>-0.312500</td>\n",
       "      <td>-1.479167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B.4</th>\n",
       "      <td>9.062500</td>\n",
       "      <td>23.270834</td>\n",
       "      <td>31.895834</td>\n",
       "      <td>466.81250</td>\n",
       "      <td>-7.520834</td>\n",
       "      <td>-4.229166</td>\n",
       "      <td>16.979166</td>\n",
       "      <td>-11.187500</td>\n",
       "      <td>10.187500</td>\n",
       "      <td>27.229166</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.604167</td>\n",
       "      <td>5.395834</td>\n",
       "      <td>-9.812500</td>\n",
       "      <td>-1.854167</td>\n",
       "      <td>5.395834</td>\n",
       "      <td>-1.854167</td>\n",
       "      <td>-7.562500</td>\n",
       "      <td>-3.020833</td>\n",
       "      <td>-3.020833</td>\n",
       "      <td>-0.604167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HC.1</th>\n",
       "      <td>1.854167</td>\n",
       "      <td>4.312500</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>473.22916</td>\n",
       "      <td>-5.937500</td>\n",
       "      <td>-3.229167</td>\n",
       "      <td>30.229166</td>\n",
       "      <td>-0.812500</td>\n",
       "      <td>13.729167</td>\n",
       "      <td>5.187500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.979167</td>\n",
       "      <td>-2.395833</td>\n",
       "      <td>-2.395833</td>\n",
       "      <td>-2.395833</td>\n",
       "      <td>-6.812500</td>\n",
       "      <td>6.770834</td>\n",
       "      <td>-2.395833</td>\n",
       "      <td>-6.812500</td>\n",
       "      <td>6.770834</td>\n",
       "      <td>-6.812500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HC.2</th>\n",
       "      <td>9.104167</td>\n",
       "      <td>3.270833</td>\n",
       "      <td>40.145832</td>\n",
       "      <td>309.27084</td>\n",
       "      <td>-4.895834</td>\n",
       "      <td>0.395833</td>\n",
       "      <td>16.354166</td>\n",
       "      <td>-10.187500</td>\n",
       "      <td>-3.270833</td>\n",
       "      <td>10.645833</td>\n",
       "      <td>...</td>\n",
       "      <td>9.770833</td>\n",
       "      <td>-8.437500</td>\n",
       "      <td>-10.229167</td>\n",
       "      <td>2.729167</td>\n",
       "      <td>-2.604167</td>\n",
       "      <td>1.229167</td>\n",
       "      <td>-4.937500</td>\n",
       "      <td>-1.062500</td>\n",
       "      <td>-3.312500</td>\n",
       "      <td>1.979167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HC.3</th>\n",
       "      <td>15.104167</td>\n",
       "      <td>3.479167</td>\n",
       "      <td>29.187500</td>\n",
       "      <td>536.47920</td>\n",
       "      <td>-0.979167</td>\n",
       "      <td>-6.479166</td>\n",
       "      <td>7.895834</td>\n",
       "      <td>-0.145833</td>\n",
       "      <td>-3.312500</td>\n",
       "      <td>-0.145833</td>\n",
       "      <td>...</td>\n",
       "      <td>7.854166</td>\n",
       "      <td>-4.312500</td>\n",
       "      <td>-1.020833</td>\n",
       "      <td>1.270833</td>\n",
       "      <td>1.270833</td>\n",
       "      <td>9.312500</td>\n",
       "      <td>-7.479166</td>\n",
       "      <td>-3.354167</td>\n",
       "      <td>-3.354167</td>\n",
       "      <td>-0.187500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S.1</th>\n",
       "      <td>3.437500</td>\n",
       "      <td>-8.437500</td>\n",
       "      <td>13.187500</td>\n",
       "      <td>212.52083</td>\n",
       "      <td>-2.770833</td>\n",
       "      <td>-9.520833</td>\n",
       "      <td>22.604166</td>\n",
       "      <td>-7.270834</td>\n",
       "      <td>-1.354167</td>\n",
       "      <td>38.729168</td>\n",
       "      <td>...</td>\n",
       "      <td>17.562500</td>\n",
       "      <td>-3.895833</td>\n",
       "      <td>-3.895833</td>\n",
       "      <td>2.145833</td>\n",
       "      <td>3.395833</td>\n",
       "      <td>-6.145834</td>\n",
       "      <td>-0.229167</td>\n",
       "      <td>-2.812500</td>\n",
       "      <td>-3.895833</td>\n",
       "      <td>8.812500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S.2</th>\n",
       "      <td>8.270833</td>\n",
       "      <td>-5.354166</td>\n",
       "      <td>9.145833</td>\n",
       "      <td>530.93750</td>\n",
       "      <td>-2.604167</td>\n",
       "      <td>-4.395834</td>\n",
       "      <td>8.270833</td>\n",
       "      <td>-3.395833</td>\n",
       "      <td>-4.395834</td>\n",
       "      <td>61.770832</td>\n",
       "      <td>...</td>\n",
       "      <td>4.937500</td>\n",
       "      <td>-7.187500</td>\n",
       "      <td>-5.395834</td>\n",
       "      <td>-3.437500</td>\n",
       "      <td>-2.645833</td>\n",
       "      <td>-3.437500</td>\n",
       "      <td>-9.312500</td>\n",
       "      <td>-5.395834</td>\n",
       "      <td>-1.770833</td>\n",
       "      <td>5.770834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S.3</th>\n",
       "      <td>-3.145833</td>\n",
       "      <td>-1.187500</td>\n",
       "      <td>18.645834</td>\n",
       "      <td>388.18750</td>\n",
       "      <td>-1.187500</td>\n",
       "      <td>-1.187500</td>\n",
       "      <td>2.604167</td>\n",
       "      <td>-9.812500</td>\n",
       "      <td>8.354167</td>\n",
       "      <td>37.854168</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.437500</td>\n",
       "      <td>-9.854167</td>\n",
       "      <td>-6.104166</td>\n",
       "      <td>-7.062500</td>\n",
       "      <td>-1.229167</td>\n",
       "      <td>-3.187500</td>\n",
       "      <td>-0.437500</td>\n",
       "      <td>3.604167</td>\n",
       "      <td>-5.145834</td>\n",
       "      <td>-5.145834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T.1</th>\n",
       "      <td>11.437500</td>\n",
       "      <td>2.895833</td>\n",
       "      <td>43.479168</td>\n",
       "      <td>475.18750</td>\n",
       "      <td>-6.270834</td>\n",
       "      <td>-3.437500</td>\n",
       "      <td>14.562500</td>\n",
       "      <td>-9.312500</td>\n",
       "      <td>-1.770833</td>\n",
       "      <td>22.354166</td>\n",
       "      <td>...</td>\n",
       "      <td>1.937500</td>\n",
       "      <td>-6.312500</td>\n",
       "      <td>-10.312500</td>\n",
       "      <td>-8.354167</td>\n",
       "      <td>5.354166</td>\n",
       "      <td>-2.770833</td>\n",
       "      <td>-1.812500</td>\n",
       "      <td>-0.937500</td>\n",
       "      <td>-1.812500</td>\n",
       "      <td>3.687500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T.2</th>\n",
       "      <td>14.020833</td>\n",
       "      <td>-3.687500</td>\n",
       "      <td>10.979167</td>\n",
       "      <td>490.60416</td>\n",
       "      <td>-4.479166</td>\n",
       "      <td>-1.937500</td>\n",
       "      <td>17.437500</td>\n",
       "      <td>-7.312500</td>\n",
       "      <td>-0.937500</td>\n",
       "      <td>14.020833</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.979167</td>\n",
       "      <td>-0.979167</td>\n",
       "      <td>-7.354166</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>-0.979167</td>\n",
       "      <td>9.437500</td>\n",
       "      <td>-4.520834</td>\n",
       "      <td>-6.354166</td>\n",
       "      <td>-1.979167</td>\n",
       "      <td>-1.979167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T.3</th>\n",
       "      <td>11.187500</td>\n",
       "      <td>-3.354167</td>\n",
       "      <td>17.062500</td>\n",
       "      <td>600.18750</td>\n",
       "      <td>-8.229167</td>\n",
       "      <td>-1.270833</td>\n",
       "      <td>8.062500</td>\n",
       "      <td>-7.229166</td>\n",
       "      <td>9.604167</td>\n",
       "      <td>18.354166</td>\n",
       "      <td>...</td>\n",
       "      <td>1.479167</td>\n",
       "      <td>-5.354166</td>\n",
       "      <td>-3.395833</td>\n",
       "      <td>-2.354167</td>\n",
       "      <td>-0.479167</td>\n",
       "      <td>-2.354167</td>\n",
       "      <td>-3.395833</td>\n",
       "      <td>-7.270834</td>\n",
       "      <td>1.479167</td>\n",
       "      <td>6.187500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13 rows × 47332 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "ID_REF  ILMN_1725881  ILMN_1910180  ILMN_1804174  ILMN_1796063  ILMN_3284771  \\\n",
       "B.1        10.479167     -0.687500     16.854166     401.56250      0.354167   \n",
       "B.2         4.937500      2.229167      7.562500     416.60416     -2.895833   \n",
       "B.3        16.812500     -1.437500      1.145833     229.02083     -7.729166   \n",
       "B.4         9.062500     23.270834     31.895834     466.81250     -7.520834   \n",
       "HC.1        1.854167      4.312500      0.187500     473.22916     -5.937500   \n",
       "HC.2        9.104167      3.270833     40.145832     309.27084     -4.895834   \n",
       "HC.3       15.104167      3.479167     29.187500     536.47920     -0.979167   \n",
       "S.1         3.437500     -8.437500     13.187500     212.52083     -2.770833   \n",
       "S.2         8.270833     -5.354166      9.145833     530.93750     -2.604167   \n",
       "S.3        -3.145833     -1.187500     18.645834     388.18750     -1.187500   \n",
       "T.1        11.437500      2.895833     43.479168     475.18750     -6.270834   \n",
       "T.2        14.020833     -3.687500     10.979167     490.60416     -4.479166   \n",
       "T.3        11.187500     -3.354167     17.062500     600.18750     -8.229167   \n",
       "\n",
       "ID_REF  ILMN_3208259  ILMN_1811966  ILMN_1668162  ILMN_1715600  ILMN_1912287  \\\n",
       "B.1         2.354167      9.562500     -7.645834     -7.645834     13.645833   \n",
       "B.2        -0.354167      2.229167     -7.770834     -4.020834     15.687500   \n",
       "B.3         3.770833      3.770833      5.104166     -9.979167     61.520832   \n",
       "B.4        -4.229166     16.979166    -11.187500     10.187500     27.229166   \n",
       "HC.1       -3.229167     30.229166     -0.812500     13.729167      5.187500   \n",
       "HC.2        0.395833     16.354166    -10.187500     -3.270833     10.645833   \n",
       "HC.3       -6.479166      7.895834     -0.145833     -3.312500     -0.145833   \n",
       "S.1        -9.520833     22.604166     -7.270834     -1.354167     38.729168   \n",
       "S.2        -4.395834      8.270833     -3.395833     -4.395834     61.770832   \n",
       "S.3        -1.187500      2.604167     -9.812500      8.354167     37.854168   \n",
       "T.1        -3.437500     14.562500     -9.312500     -1.770833     22.354166   \n",
       "T.2        -1.937500     17.437500     -7.312500     -0.937500     14.020833   \n",
       "T.3        -1.270833      8.062500     -7.229166      9.604167     18.354166   \n",
       "\n",
       "ID_REF  ...  ILMN_3166640  ILMN_3166655  ILMN_3166673  ILMN_3166687  \\\n",
       "B.1     ...      3.187500     -3.604167     -5.645834     -4.562500   \n",
       "B.2     ...     12.979167      0.854167     -6.604166     -4.104166   \n",
       "B.3     ...     -6.437500     -2.854167     -2.854167      1.104167   \n",
       "B.4     ...     -0.604167      5.395834     -9.812500     -1.854167   \n",
       "HC.1    ...      0.979167     -2.395833     -2.395833     -2.395833   \n",
       "HC.2    ...      9.770833     -8.437500    -10.229167      2.729167   \n",
       "HC.3    ...      7.854166     -4.312500     -1.020833      1.270833   \n",
       "S.1     ...     17.562500     -3.895833     -3.895833      2.145833   \n",
       "S.2     ...      4.937500     -7.187500     -5.395834     -3.437500   \n",
       "S.3     ...     -0.437500     -9.854167     -6.104166     -7.062500   \n",
       "T.1     ...      1.937500     -6.312500    -10.312500     -8.354167   \n",
       "T.2     ...     -0.979167     -0.979167     -7.354166      0.020833   \n",
       "T.3     ...      1.479167     -5.354166     -3.395833     -2.354167   \n",
       "\n",
       "ID_REF  ILMN_3166703  ILMN_3166721  ILMN_3166728  ILMN_3166775  ILMN_3166789  \\\n",
       "B.1         7.770834     -1.729167     -8.687500     -0.729167     -0.729167   \n",
       "B.2         3.562500     -0.395833     -6.604166     -0.395833     -7.812500   \n",
       "B.3        -0.312500      6.562500      1.104167    -11.187500     -0.312500   \n",
       "B.4         5.395834     -1.854167     -7.562500     -3.020833     -3.020833   \n",
       "HC.1       -6.812500      6.770834     -2.395833     -6.812500      6.770834   \n",
       "HC.2       -2.604167      1.229167     -4.937500     -1.062500     -3.312500   \n",
       "HC.3        1.270833      9.312500     -7.479166     -3.354167     -3.354167   \n",
       "S.1         3.395833     -6.145834     -0.229167     -2.812500     -3.895833   \n",
       "S.2        -2.645833     -3.437500     -9.312500     -5.395834     -1.770833   \n",
       "S.3        -1.229167     -3.187500     -0.437500      3.604167     -5.145834   \n",
       "T.1         5.354166     -2.770833     -1.812500     -0.937500     -1.812500   \n",
       "T.2        -0.979167      9.437500     -4.520834     -6.354166     -1.979167   \n",
       "T.3        -0.479167     -2.354167     -3.395833     -7.270834      1.479167   \n",
       "\n",
       "ID_REF  ILMN_3166804  \n",
       "B.1         1.312500  \n",
       "B.2         3.562500  \n",
       "B.3        -1.479167  \n",
       "B.4        -0.604167  \n",
       "HC.1       -6.812500  \n",
       "HC.2        1.979167  \n",
       "HC.3       -0.187500  \n",
       "S.1         8.812500  \n",
       "S.2         5.770834  \n",
       "S.3        -5.145834  \n",
       "T.1         3.687500  \n",
       "T.2        -1.979167  \n",
       "T.3         6.187500  \n",
       "\n",
       "[13 rows x 47332 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_T=df_T.drop(['ESTADO'], axis=1)\n",
    "df_T.head(13)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e461ec95",
   "metadata": {},
   "source": [
    "# Varianza\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "86a59246",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular la varianza de cada columna\n",
    "varianza = df_T.var(numeric_only=True)\n",
    "# Establecer un umbral para la varianza mínima\n",
    "umbral = 1000\n",
    "\n",
    "# Filtrar las columnas que tienen una varianza mayor o igual al umbral establecido\n",
    "cols_filtradas = varianza[varianza >= umbral].index\n",
    "\n",
    "# Actualizar el dataframe solo con las columnas filtradas\n",
    "df_T = df_T.loc[:,cols_filtradas]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "65115da9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>ID_REF</th>\n",
       "      <th>ILMN_1796063</th>\n",
       "      <th>ILMN_1793729</th>\n",
       "      <th>ILMN_1655444</th>\n",
       "      <th>ILMN_1711453</th>\n",
       "      <th>ILMN_1660232</th>\n",
       "      <th>ILMN_1763663</th>\n",
       "      <th>ILMN_1775074</th>\n",
       "      <th>ILMN_1809344</th>\n",
       "      <th>ILMN_1762281</th>\n",
       "      <th>ILMN_1734742</th>\n",
       "      <th>...</th>\n",
       "      <th>ILMN_1761281</th>\n",
       "      <th>ILMN_2051684</th>\n",
       "      <th>ILMN_2387952</th>\n",
       "      <th>ILMN_1742577</th>\n",
       "      <th>ILMN_3243700</th>\n",
       "      <th>ILMN_1678522</th>\n",
       "      <th>ILMN_1738523</th>\n",
       "      <th>ILMN_2149766</th>\n",
       "      <th>ILMN_1720233</th>\n",
       "      <th>ILMN_1791388</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>B.1</th>\n",
       "      <td>401.56250</td>\n",
       "      <td>544.81250</td>\n",
       "      <td>103.229164</td>\n",
       "      <td>57.312500</td>\n",
       "      <td>286.64584</td>\n",
       "      <td>146.604170</td>\n",
       "      <td>153.10417</td>\n",
       "      <td>140.770830</td>\n",
       "      <td>472.89584</td>\n",
       "      <td>647.47920</td>\n",
       "      <td>...</td>\n",
       "      <td>50.145832</td>\n",
       "      <td>362.60416</td>\n",
       "      <td>81.145836</td>\n",
       "      <td>484.437500</td>\n",
       "      <td>4329.9375</td>\n",
       "      <td>1689.47910</td>\n",
       "      <td>871.97920</td>\n",
       "      <td>174.395830</td>\n",
       "      <td>201.812500</td>\n",
       "      <td>377.39584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B.2</th>\n",
       "      <td>416.60416</td>\n",
       "      <td>475.72916</td>\n",
       "      <td>105.395836</td>\n",
       "      <td>61.562500</td>\n",
       "      <td>290.22916</td>\n",
       "      <td>202.520830</td>\n",
       "      <td>186.68750</td>\n",
       "      <td>94.937500</td>\n",
       "      <td>596.72920</td>\n",
       "      <td>545.68750</td>\n",
       "      <td>...</td>\n",
       "      <td>65.770836</td>\n",
       "      <td>480.35416</td>\n",
       "      <td>56.354168</td>\n",
       "      <td>346.312500</td>\n",
       "      <td>4254.6040</td>\n",
       "      <td>3043.97920</td>\n",
       "      <td>537.52080</td>\n",
       "      <td>197.687500</td>\n",
       "      <td>141.895830</td>\n",
       "      <td>265.35416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B.3</th>\n",
       "      <td>229.02083</td>\n",
       "      <td>940.89580</td>\n",
       "      <td>55.937500</td>\n",
       "      <td>61.520832</td>\n",
       "      <td>145.56250</td>\n",
       "      <td>5.104166</td>\n",
       "      <td>162.27083</td>\n",
       "      <td>335.187500</td>\n",
       "      <td>674.64580</td>\n",
       "      <td>464.14584</td>\n",
       "      <td>...</td>\n",
       "      <td>3.687500</td>\n",
       "      <td>724.97920</td>\n",
       "      <td>39.020832</td>\n",
       "      <td>109.729164</td>\n",
       "      <td>2436.8125</td>\n",
       "      <td>330.89584</td>\n",
       "      <td>861.60420</td>\n",
       "      <td>44.270832</td>\n",
       "      <td>395.479160</td>\n",
       "      <td>795.56250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B.4</th>\n",
       "      <td>466.81250</td>\n",
       "      <td>782.06250</td>\n",
       "      <td>107.562500</td>\n",
       "      <td>47.604168</td>\n",
       "      <td>244.89583</td>\n",
       "      <td>247.270830</td>\n",
       "      <td>171.35417</td>\n",
       "      <td>40.562500</td>\n",
       "      <td>550.18750</td>\n",
       "      <td>915.31250</td>\n",
       "      <td>...</td>\n",
       "      <td>88.229164</td>\n",
       "      <td>373.31250</td>\n",
       "      <td>104.687500</td>\n",
       "      <td>435.854160</td>\n",
       "      <td>5167.8540</td>\n",
       "      <td>890.27080</td>\n",
       "      <td>466.68750</td>\n",
       "      <td>134.604170</td>\n",
       "      <td>167.979170</td>\n",
       "      <td>370.81250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HC.1</th>\n",
       "      <td>473.22916</td>\n",
       "      <td>528.52080</td>\n",
       "      <td>170.312500</td>\n",
       "      <td>140.979170</td>\n",
       "      <td>251.68750</td>\n",
       "      <td>218.687500</td>\n",
       "      <td>166.72917</td>\n",
       "      <td>98.979164</td>\n",
       "      <td>630.93750</td>\n",
       "      <td>662.39580</td>\n",
       "      <td>...</td>\n",
       "      <td>31.187500</td>\n",
       "      <td>487.97916</td>\n",
       "      <td>7.562500</td>\n",
       "      <td>404.687500</td>\n",
       "      <td>6221.1040</td>\n",
       "      <td>836.85420</td>\n",
       "      <td>417.02084</td>\n",
       "      <td>54.937500</td>\n",
       "      <td>417.312500</td>\n",
       "      <td>330.35416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HC.2</th>\n",
       "      <td>309.27084</td>\n",
       "      <td>382.39584</td>\n",
       "      <td>135.062500</td>\n",
       "      <td>72.104164</td>\n",
       "      <td>231.56250</td>\n",
       "      <td>225.979170</td>\n",
       "      <td>156.89583</td>\n",
       "      <td>72.145836</td>\n",
       "      <td>494.18750</td>\n",
       "      <td>550.18750</td>\n",
       "      <td>...</td>\n",
       "      <td>17.104166</td>\n",
       "      <td>366.60416</td>\n",
       "      <td>12.520833</td>\n",
       "      <td>475.395840</td>\n",
       "      <td>5468.8125</td>\n",
       "      <td>1627.60410</td>\n",
       "      <td>326.77084</td>\n",
       "      <td>106.020836</td>\n",
       "      <td>631.770800</td>\n",
       "      <td>401.02084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HC.3</th>\n",
       "      <td>536.47920</td>\n",
       "      <td>1217.27090</td>\n",
       "      <td>54.062500</td>\n",
       "      <td>43.729168</td>\n",
       "      <td>314.81250</td>\n",
       "      <td>148.270830</td>\n",
       "      <td>311.39584</td>\n",
       "      <td>60.604168</td>\n",
       "      <td>623.81250</td>\n",
       "      <td>961.52080</td>\n",
       "      <td>...</td>\n",
       "      <td>12.395833</td>\n",
       "      <td>367.22916</td>\n",
       "      <td>28.145834</td>\n",
       "      <td>631.770800</td>\n",
       "      <td>6296.0625</td>\n",
       "      <td>899.18750</td>\n",
       "      <td>399.27084</td>\n",
       "      <td>38.854168</td>\n",
       "      <td>475.895840</td>\n",
       "      <td>477.85416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S.1</th>\n",
       "      <td>212.52083</td>\n",
       "      <td>887.89580</td>\n",
       "      <td>211.604170</td>\n",
       "      <td>7.479166</td>\n",
       "      <td>324.64584</td>\n",
       "      <td>78.020836</td>\n",
       "      <td>184.81250</td>\n",
       "      <td>98.562500</td>\n",
       "      <td>485.64584</td>\n",
       "      <td>835.31250</td>\n",
       "      <td>...</td>\n",
       "      <td>161.687500</td>\n",
       "      <td>763.27080</td>\n",
       "      <td>95.479164</td>\n",
       "      <td>379.437500</td>\n",
       "      <td>2957.6875</td>\n",
       "      <td>1118.47910</td>\n",
       "      <td>889.14580</td>\n",
       "      <td>91.770836</td>\n",
       "      <td>399.604160</td>\n",
       "      <td>635.47920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S.2</th>\n",
       "      <td>530.93750</td>\n",
       "      <td>536.72920</td>\n",
       "      <td>102.104164</td>\n",
       "      <td>107.895836</td>\n",
       "      <td>257.31250</td>\n",
       "      <td>157.229170</td>\n",
       "      <td>153.89583</td>\n",
       "      <td>106.104164</td>\n",
       "      <td>498.47916</td>\n",
       "      <td>744.81250</td>\n",
       "      <td>...</td>\n",
       "      <td>44.479168</td>\n",
       "      <td>457.89584</td>\n",
       "      <td>33.062500</td>\n",
       "      <td>364.979160</td>\n",
       "      <td>5213.2710</td>\n",
       "      <td>2793.60420</td>\n",
       "      <td>526.72920</td>\n",
       "      <td>189.770830</td>\n",
       "      <td>187.562500</td>\n",
       "      <td>317.22916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S.3</th>\n",
       "      <td>388.18750</td>\n",
       "      <td>503.97916</td>\n",
       "      <td>84.270836</td>\n",
       "      <td>17.854166</td>\n",
       "      <td>354.89584</td>\n",
       "      <td>146.104170</td>\n",
       "      <td>251.31250</td>\n",
       "      <td>91.479164</td>\n",
       "      <td>587.02080</td>\n",
       "      <td>921.31250</td>\n",
       "      <td>...</td>\n",
       "      <td>157.520830</td>\n",
       "      <td>350.14584</td>\n",
       "      <td>124.104164</td>\n",
       "      <td>385.729160</td>\n",
       "      <td>4858.2710</td>\n",
       "      <td>1895.81250</td>\n",
       "      <td>806.31250</td>\n",
       "      <td>150.937500</td>\n",
       "      <td>86.729164</td>\n",
       "      <td>381.89584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T.1</th>\n",
       "      <td>475.18750</td>\n",
       "      <td>486.22916</td>\n",
       "      <td>70.312500</td>\n",
       "      <td>56.104168</td>\n",
       "      <td>349.43750</td>\n",
       "      <td>247.520830</td>\n",
       "      <td>186.43750</td>\n",
       "      <td>130.020830</td>\n",
       "      <td>461.97916</td>\n",
       "      <td>639.56250</td>\n",
       "      <td>...</td>\n",
       "      <td>42.270832</td>\n",
       "      <td>383.39584</td>\n",
       "      <td>55.520832</td>\n",
       "      <td>550.979200</td>\n",
       "      <td>5612.9790</td>\n",
       "      <td>616.22920</td>\n",
       "      <td>645.22920</td>\n",
       "      <td>251.312500</td>\n",
       "      <td>149.979170</td>\n",
       "      <td>203.64583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T.2</th>\n",
       "      <td>490.60416</td>\n",
       "      <td>546.72920</td>\n",
       "      <td>96.395836</td>\n",
       "      <td>21.437500</td>\n",
       "      <td>350.14584</td>\n",
       "      <td>120.104164</td>\n",
       "      <td>214.60417</td>\n",
       "      <td>126.604164</td>\n",
       "      <td>501.27084</td>\n",
       "      <td>819.43750</td>\n",
       "      <td>...</td>\n",
       "      <td>52.395832</td>\n",
       "      <td>390.93750</td>\n",
       "      <td>58.395832</td>\n",
       "      <td>495.520840</td>\n",
       "      <td>5921.0210</td>\n",
       "      <td>2178.89580</td>\n",
       "      <td>631.52080</td>\n",
       "      <td>271.770840</td>\n",
       "      <td>117.895836</td>\n",
       "      <td>291.85416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T.3</th>\n",
       "      <td>600.18750</td>\n",
       "      <td>442.35416</td>\n",
       "      <td>108.895836</td>\n",
       "      <td>57.479168</td>\n",
       "      <td>239.27083</td>\n",
       "      <td>224.520830</td>\n",
       "      <td>195.35417</td>\n",
       "      <td>122.312500</td>\n",
       "      <td>368.52084</td>\n",
       "      <td>661.35420</td>\n",
       "      <td>...</td>\n",
       "      <td>44.770832</td>\n",
       "      <td>437.10416</td>\n",
       "      <td>50.020832</td>\n",
       "      <td>460.895840</td>\n",
       "      <td>6777.1460</td>\n",
       "      <td>684.97920</td>\n",
       "      <td>553.35420</td>\n",
       "      <td>171.729170</td>\n",
       "      <td>282.354160</td>\n",
       "      <td>270.31250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13 rows × 8658 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "ID_REF  ILMN_1796063  ILMN_1793729  ILMN_1655444  ILMN_1711453  ILMN_1660232  \\\n",
       "B.1        401.56250     544.81250    103.229164     57.312500     286.64584   \n",
       "B.2        416.60416     475.72916    105.395836     61.562500     290.22916   \n",
       "B.3        229.02083     940.89580     55.937500     61.520832     145.56250   \n",
       "B.4        466.81250     782.06250    107.562500     47.604168     244.89583   \n",
       "HC.1       473.22916     528.52080    170.312500    140.979170     251.68750   \n",
       "HC.2       309.27084     382.39584    135.062500     72.104164     231.56250   \n",
       "HC.3       536.47920    1217.27090     54.062500     43.729168     314.81250   \n",
       "S.1        212.52083     887.89580    211.604170      7.479166     324.64584   \n",
       "S.2        530.93750     536.72920    102.104164    107.895836     257.31250   \n",
       "S.3        388.18750     503.97916     84.270836     17.854166     354.89584   \n",
       "T.1        475.18750     486.22916     70.312500     56.104168     349.43750   \n",
       "T.2        490.60416     546.72920     96.395836     21.437500     350.14584   \n",
       "T.3        600.18750     442.35416    108.895836     57.479168     239.27083   \n",
       "\n",
       "ID_REF  ILMN_1763663  ILMN_1775074  ILMN_1809344  ILMN_1762281  ILMN_1734742  \\\n",
       "B.1       146.604170     153.10417    140.770830     472.89584     647.47920   \n",
       "B.2       202.520830     186.68750     94.937500     596.72920     545.68750   \n",
       "B.3         5.104166     162.27083    335.187500     674.64580     464.14584   \n",
       "B.4       247.270830     171.35417     40.562500     550.18750     915.31250   \n",
       "HC.1      218.687500     166.72917     98.979164     630.93750     662.39580   \n",
       "HC.2      225.979170     156.89583     72.145836     494.18750     550.18750   \n",
       "HC.3      148.270830     311.39584     60.604168     623.81250     961.52080   \n",
       "S.1        78.020836     184.81250     98.562500     485.64584     835.31250   \n",
       "S.2       157.229170     153.89583    106.104164     498.47916     744.81250   \n",
       "S.3       146.104170     251.31250     91.479164     587.02080     921.31250   \n",
       "T.1       247.520830     186.43750    130.020830     461.97916     639.56250   \n",
       "T.2       120.104164     214.60417    126.604164     501.27084     819.43750   \n",
       "T.3       224.520830     195.35417    122.312500     368.52084     661.35420   \n",
       "\n",
       "ID_REF  ...  ILMN_1761281  ILMN_2051684  ILMN_2387952  ILMN_1742577  \\\n",
       "B.1     ...     50.145832     362.60416     81.145836    484.437500   \n",
       "B.2     ...     65.770836     480.35416     56.354168    346.312500   \n",
       "B.3     ...      3.687500     724.97920     39.020832    109.729164   \n",
       "B.4     ...     88.229164     373.31250    104.687500    435.854160   \n",
       "HC.1    ...     31.187500     487.97916      7.562500    404.687500   \n",
       "HC.2    ...     17.104166     366.60416     12.520833    475.395840   \n",
       "HC.3    ...     12.395833     367.22916     28.145834    631.770800   \n",
       "S.1     ...    161.687500     763.27080     95.479164    379.437500   \n",
       "S.2     ...     44.479168     457.89584     33.062500    364.979160   \n",
       "S.3     ...    157.520830     350.14584    124.104164    385.729160   \n",
       "T.1     ...     42.270832     383.39584     55.520832    550.979200   \n",
       "T.2     ...     52.395832     390.93750     58.395832    495.520840   \n",
       "T.3     ...     44.770832     437.10416     50.020832    460.895840   \n",
       "\n",
       "ID_REF  ILMN_3243700  ILMN_1678522  ILMN_1738523  ILMN_2149766  ILMN_1720233  \\\n",
       "B.1        4329.9375    1689.47910     871.97920    174.395830    201.812500   \n",
       "B.2        4254.6040    3043.97920     537.52080    197.687500    141.895830   \n",
       "B.3        2436.8125     330.89584     861.60420     44.270832    395.479160   \n",
       "B.4        5167.8540     890.27080     466.68750    134.604170    167.979170   \n",
       "HC.1       6221.1040     836.85420     417.02084     54.937500    417.312500   \n",
       "HC.2       5468.8125    1627.60410     326.77084    106.020836    631.770800   \n",
       "HC.3       6296.0625     899.18750     399.27084     38.854168    475.895840   \n",
       "S.1        2957.6875    1118.47910     889.14580     91.770836    399.604160   \n",
       "S.2        5213.2710    2793.60420     526.72920    189.770830    187.562500   \n",
       "S.3        4858.2710    1895.81250     806.31250    150.937500     86.729164   \n",
       "T.1        5612.9790     616.22920     645.22920    251.312500    149.979170   \n",
       "T.2        5921.0210    2178.89580     631.52080    271.770840    117.895836   \n",
       "T.3        6777.1460     684.97920     553.35420    171.729170    282.354160   \n",
       "\n",
       "ID_REF  ILMN_1791388  \n",
       "B.1        377.39584  \n",
       "B.2        265.35416  \n",
       "B.3        795.56250  \n",
       "B.4        370.81250  \n",
       "HC.1       330.35416  \n",
       "HC.2       401.02084  \n",
       "HC.3       477.85416  \n",
       "S.1        635.47920  \n",
       "S.2        317.22916  \n",
       "S.3        381.89584  \n",
       "T.1        203.64583  \n",
       "T.2        291.85416  \n",
       "T.3        270.31250  \n",
       "\n",
       "[13 rows x 8658 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_T.head(13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5ae9afe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID_REF\n",
      "ILMN_1725881       31.790042\n",
      "ILMN_1910180       58.908901\n",
      "ILMN_1804174      193.276489\n",
      "ILMN_1796063    13679.923009\n",
      "ILMN_3284771        7.836917\n",
      "                    ...     \n",
      "ILMN_3166721       27.974982\n",
      "ILMN_3166728       11.850561\n",
      "ILMN_3166775       14.753317\n",
      "ILMN_3166789       12.113604\n",
      "ILMN_3166804       20.251892\n",
      "Length: 47332, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(varianza)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fa4ecf4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111484.76737880803\n"
     ]
    }
   ],
   "source": [
    "print(varianza.mean())\n",
    "# inicialwmnte son 47332, si utilizo un umbral de 10000 queda en 4369, y si utilizo uno de 1000 queda en 8658"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "358c59ea",
   "metadata": {},
   "source": [
    "## Autoencoder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b585c192",
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalizar datos\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "data = scaler.fit_transform(df_T)\n",
    "#datos entrenamiento y prueba\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "#arquitectura del autoencoder\n",
    "#Las capas de codificación tienen tamaños\n",
    "from keras.layers import Input, Dense, Dropout\n",
    "from keras.models import Model\n",
    "\n",
    "input_data = Input(shape=(8658,))\n",
    "encoded = Dense(4096, activation='relu')(input_data)\n",
    "encoded = Dense(2048, activation='relu')(encoded)\n",
    "encoded = Dense(1024, activation='relu')(encoded)\n",
    "encoded = Dense(512, activation='relu')(encoded)\n",
    "encoded = Dense(256, activation='relu')(encoded)\n",
    "encoded = Dense(128, activation='linear')(encoded)\n",
    "\n",
    "decoded = Dense(256, activation='relu')(encoded)\n",
    "decoded = Dense(512, activation='relu')(decoded)\n",
    "decoded = Dense(1024, activation='relu')(decoded)\n",
    "decoded = Dense(2048, activation='relu')(decoded)\n",
    "decoded = Dense(4096, activation='relu')(decoded)\n",
    "decoded = Dense(8658, activation='linear')(decoded)\n",
    "decoded= Dropout(0.05)(decoded)  #se hace por sobre ajuste\n",
    "autoencoder = Model(input_data, decoded)\n",
    "autoencoder.compile(optimizer='adam', loss='mse', metrics = ['MeanAbsolutePercentageError','RootMeanSquaredError'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6a3b229c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.2724 - mean_absolute_percentage_error: 1003914.6250 - root_mean_squared_error: 0.5219 - val_loss: 0.2273 - val_mean_absolute_percentage_error: 4799589.5000 - val_root_mean_squared_error: 0.4768\n",
      "Epoch 2/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2221 - mean_absolute_percentage_error: 5338622.5000 - root_mean_squared_error: 0.4713 - val_loss: 106.1015 - val_mean_absolute_percentage_error: 631600576.0000 - val_root_mean_squared_error: 10.3006\n",
      "Epoch 3/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 104.5636 - mean_absolute_percentage_error: 757526400.0000 - root_mean_squared_error: 10.2256 - val_loss: 0.1939 - val_mean_absolute_percentage_error: 7945377.5000 - val_root_mean_squared_error: 0.4404\n",
      "Epoch 4/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1916 - mean_absolute_percentage_error: 8515316.0000 - root_mean_squared_error: 0.4377 - val_loss: 0.2799 - val_mean_absolute_percentage_error: 786410.0000 - val_root_mean_squared_error: 0.5290\n",
      "Epoch 5/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2706 - mean_absolute_percentage_error: 1117234.6250 - root_mean_squared_error: 0.5202 - val_loss: 0.2871 - val_mean_absolute_percentage_error: 1102925.6250 - val_root_mean_squared_error: 0.5358\n",
      "Epoch 6/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2775 - mean_absolute_percentage_error: 1393792.0000 - root_mean_squared_error: 0.5268 - val_loss: 0.2813 - val_mean_absolute_percentage_error: 613238.6875 - val_root_mean_squared_error: 0.5303\n",
      "Epoch 7/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2720 - mean_absolute_percentage_error: 814062.3125 - root_mean_squared_error: 0.5215 - val_loss: 0.2670 - val_mean_absolute_percentage_error: 1266457.2500 - val_root_mean_squared_error: 0.5167\n",
      "Epoch 8/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2585 - mean_absolute_percentage_error: 1473528.3750 - root_mean_squared_error: 0.5084 - val_loss: 0.2013 - val_mean_absolute_percentage_error: 6730074.0000 - val_root_mean_squared_error: 0.4487\n",
      "Epoch 9/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1959 - mean_absolute_percentage_error: 8589198.0000 - root_mean_squared_error: 0.4426 - val_loss: 0.1251 - val_mean_absolute_percentage_error: 33373424.0000 - val_root_mean_squared_error: 0.3537\n",
      "Epoch 10/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1456 - mean_absolute_percentage_error: 44339048.0000 - root_mean_squared_error: 0.3816 - val_loss: 0.0987 - val_mean_absolute_percentage_error: 20081418.0000 - val_root_mean_squared_error: 0.3141\n",
      "Epoch 11/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1047 - mean_absolute_percentage_error: 26408706.0000 - root_mean_squared_error: 0.3236 - val_loss: 0.0978 - val_mean_absolute_percentage_error: 18740654.0000 - val_root_mean_squared_error: 0.3128\n",
      "Epoch 12/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1039 - mean_absolute_percentage_error: 24309564.0000 - root_mean_squared_error: 0.3223 - val_loss: 0.0824 - val_mean_absolute_percentage_error: 26844586.0000 - val_root_mean_squared_error: 0.2870\n",
      "Epoch 13/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0961 - mean_absolute_percentage_error: 34461324.0000 - root_mean_squared_error: 0.3100 - val_loss: 0.0848 - val_mean_absolute_percentage_error: 27556504.0000 - val_root_mean_squared_error: 0.2912\n",
      "Epoch 14/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0996 - mean_absolute_percentage_error: 34595512.0000 - root_mean_squared_error: 0.3155 - val_loss: 0.0918 - val_mean_absolute_percentage_error: 19510664.0000 - val_root_mean_squared_error: 0.3031\n",
      "Epoch 15/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0999 - mean_absolute_percentage_error: 24041568.0000 - root_mean_squared_error: 0.3161 - val_loss: 0.0879 - val_mean_absolute_percentage_error: 20499994.0000 - val_root_mean_squared_error: 0.2965\n",
      "Epoch 16/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0964 - mean_absolute_percentage_error: 24461212.0000 - root_mean_squared_error: 0.3105 - val_loss: 0.0826 - val_mean_absolute_percentage_error: 27766090.0000 - val_root_mean_squared_error: 0.2874\n",
      "Epoch 17/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0958 - mean_absolute_percentage_error: 32355088.0000 - root_mean_squared_error: 0.3094 - val_loss: 0.0791 - val_mean_absolute_percentage_error: 26087472.0000 - val_root_mean_squared_error: 0.2813\n",
      "Epoch 18/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0913 - mean_absolute_percentage_error: 29148660.0000 - root_mean_squared_error: 0.3022 - val_loss: 0.0825 - val_mean_absolute_percentage_error: 21797108.0000 - val_root_mean_squared_error: 0.2872\n",
      "Epoch 19/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0927 - mean_absolute_percentage_error: 23537860.0000 - root_mean_squared_error: 0.3045 - val_loss: 0.0778 - val_mean_absolute_percentage_error: 24203928.0000 - val_root_mean_squared_error: 0.2789\n",
      "Epoch 20/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0895 - mean_absolute_percentage_error: 25601624.0000 - root_mean_squared_error: 0.2992 - val_loss: 0.0792 - val_mean_absolute_percentage_error: 29081826.0000 - val_root_mean_squared_error: 0.2814\n",
      "Epoch 21/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0930 - mean_absolute_percentage_error: 30882716.0000 - root_mean_squared_error: 0.3050 - val_loss: 0.0762 - val_mean_absolute_percentage_error: 24317686.0000 - val_root_mean_squared_error: 0.2760\n",
      "Epoch 22/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0889 - mean_absolute_percentage_error: 25805460.0000 - root_mean_squared_error: 0.2981 - val_loss: 0.0778 - val_mean_absolute_percentage_error: 22661594.0000 - val_root_mean_squared_error: 0.2790\n",
      "Epoch 23/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0899 - mean_absolute_percentage_error: 24116244.0000 - root_mean_squared_error: 0.2998 - val_loss: 0.0741 - val_mean_absolute_percentage_error: 26041930.0000 - val_root_mean_squared_error: 0.2722\n",
      "Epoch 24/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0875 - mean_absolute_percentage_error: 27931116.0000 - root_mean_squared_error: 0.2958 - val_loss: 0.0746 - val_mean_absolute_percentage_error: 27150574.0000 - val_root_mean_squared_error: 0.2731\n",
      "Epoch 25/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0879 - mean_absolute_percentage_error: 29638964.0000 - root_mean_squared_error: 0.2965 - val_loss: 0.0750 - val_mean_absolute_percentage_error: 23305032.0000 - val_root_mean_squared_error: 0.2739\n",
      "Epoch 26/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0865 - mean_absolute_percentage_error: 25742308.0000 - root_mean_squared_error: 0.2941 - val_loss: 0.0750 - val_mean_absolute_percentage_error: 23079072.0000 - val_root_mean_squared_error: 0.2739\n",
      "Epoch 27/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0855 - mean_absolute_percentage_error: 25907184.0000 - root_mean_squared_error: 0.2925 - val_loss: 0.0734 - val_mean_absolute_percentage_error: 26034328.0000 - val_root_mean_squared_error: 0.2708\n",
      "Epoch 28/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0831 - mean_absolute_percentage_error: 29384336.0000 - root_mean_squared_error: 0.2883 - val_loss: 0.0727 - val_mean_absolute_percentage_error: 24988856.0000 - val_root_mean_squared_error: 0.2697\n",
      "Epoch 29/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0784 - mean_absolute_percentage_error: 28012090.0000 - root_mean_squared_error: 0.2799 - val_loss: 0.0738 - val_mean_absolute_percentage_error: 22676014.0000 - val_root_mean_squared_error: 0.2716\n",
      "Epoch 30/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0732 - mean_absolute_percentage_error: 24752012.0000 - root_mean_squared_error: 0.2706 - val_loss: 0.0712 - val_mean_absolute_percentage_error: 23782218.0000 - val_root_mean_squared_error: 0.2669\n",
      "Epoch 31/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step - loss: 0.0667 - mean_absolute_percentage_error: 23366866.0000 - root_mean_squared_error: 0.2583 - val_loss: 0.0710 - val_mean_absolute_percentage_error: 22777498.0000 - val_root_mean_squared_error: 0.2665\n",
      "Epoch 32/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0644 - mean_absolute_percentage_error: 19141214.0000 - root_mean_squared_error: 0.2537 - val_loss: 0.0721 - val_mean_absolute_percentage_error: 20460290.0000 - val_root_mean_squared_error: 0.2686\n",
      "Epoch 33/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0625 - mean_absolute_percentage_error: 15736427.0000 - root_mean_squared_error: 0.2499 - val_loss: 0.0714 - val_mean_absolute_percentage_error: 22556570.0000 - val_root_mean_squared_error: 0.2671\n",
      "Epoch 34/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0688 - mean_absolute_percentage_error: 18016276.0000 - root_mean_squared_error: 0.2623 - val_loss: 0.0729 - val_mean_absolute_percentage_error: 20105780.0000 - val_root_mean_squared_error: 0.2699\n",
      "Epoch 35/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0625 - mean_absolute_percentage_error: 16131347.0000 - root_mean_squared_error: 0.2500 - val_loss: 0.0710 - val_mean_absolute_percentage_error: 23160088.0000 - val_root_mean_squared_error: 0.2665\n",
      "Epoch 36/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0657 - mean_absolute_percentage_error: 16898646.0000 - root_mean_squared_error: 0.2563 - val_loss: 0.0714 - val_mean_absolute_percentage_error: 24731896.0000 - val_root_mean_squared_error: 0.2672\n",
      "Epoch 37/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0614 - mean_absolute_percentage_error: 16638128.0000 - root_mean_squared_error: 0.2478 - val_loss: 0.0715 - val_mean_absolute_percentage_error: 21497198.0000 - val_root_mean_squared_error: 0.2675\n",
      "Epoch 38/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0642 - mean_absolute_percentage_error: 16629549.0000 - root_mean_squared_error: 0.2534 - val_loss: 0.0707 - val_mean_absolute_percentage_error: 22108686.0000 - val_root_mean_squared_error: 0.2659\n",
      "Epoch 39/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0604 - mean_absolute_percentage_error: 18060070.0000 - root_mean_squared_error: 0.2457 - val_loss: 0.0707 - val_mean_absolute_percentage_error: 24700360.0000 - val_root_mean_squared_error: 0.2658\n",
      "Epoch 40/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0628 - mean_absolute_percentage_error: 20719862.0000 - root_mean_squared_error: 0.2505 - val_loss: 0.0719 - val_mean_absolute_percentage_error: 20215846.0000 - val_root_mean_squared_error: 0.2682\n",
      "Epoch 41/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0612 - mean_absolute_percentage_error: 16312110.0000 - root_mean_squared_error: 0.2474 - val_loss: 0.0715 - val_mean_absolute_percentage_error: 20003734.0000 - val_root_mean_squared_error: 0.2673\n",
      "Epoch 42/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0599 - mean_absolute_percentage_error: 15145867.0000 - root_mean_squared_error: 0.2446 - val_loss: 0.0723 - val_mean_absolute_percentage_error: 22714070.0000 - val_root_mean_squared_error: 0.2689\n",
      "Epoch 43/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0611 - mean_absolute_percentage_error: 16590360.0000 - root_mean_squared_error: 0.2472 - val_loss: 0.0710 - val_mean_absolute_percentage_error: 20564478.0000 - val_root_mean_squared_error: 0.2665\n",
      "Epoch 44/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0584 - mean_absolute_percentage_error: 14563088.0000 - root_mean_squared_error: 0.2416 - val_loss: 0.0713 - val_mean_absolute_percentage_error: 20942126.0000 - val_root_mean_squared_error: 0.2671\n",
      "Epoch 45/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0586 - mean_absolute_percentage_error: 14908083.0000 - root_mean_squared_error: 0.2421 - val_loss: 0.0703 - val_mean_absolute_percentage_error: 23909806.0000 - val_root_mean_squared_error: 0.2651\n",
      "Epoch 46/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0576 - mean_absolute_percentage_error: 16491219.0000 - root_mean_squared_error: 0.2399 - val_loss: 0.0703 - val_mean_absolute_percentage_error: 23495496.0000 - val_root_mean_squared_error: 0.2652\n",
      "Epoch 47/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0571 - mean_absolute_percentage_error: 15947827.0000 - root_mean_squared_error: 0.2390 - val_loss: 0.0713 - val_mean_absolute_percentage_error: 21467694.0000 - val_root_mean_squared_error: 0.2670\n",
      "Epoch 48/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0570 - mean_absolute_percentage_error: 14231366.0000 - root_mean_squared_error: 0.2388 - val_loss: 0.0704 - val_mean_absolute_percentage_error: 22143022.0000 - val_root_mean_squared_error: 0.2654\n",
      "Epoch 49/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0547 - mean_absolute_percentage_error: 14259438.0000 - root_mean_squared_error: 0.2339 - val_loss: 0.0701 - val_mean_absolute_percentage_error: 23797114.0000 - val_root_mean_squared_error: 0.2647\n",
      "Epoch 50/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0550 - mean_absolute_percentage_error: 14980698.0000 - root_mean_squared_error: 0.2345 - val_loss: 0.0698 - val_mean_absolute_percentage_error: 21919200.0000 - val_root_mean_squared_error: 0.2642\n",
      "Epoch 51/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0530 - mean_absolute_percentage_error: 13595245.0000 - root_mean_squared_error: 0.2303 - val_loss: 0.0707 - val_mean_absolute_percentage_error: 20520300.0000 - val_root_mean_squared_error: 0.2659\n",
      "Epoch 52/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0531 - mean_absolute_percentage_error: 12332784.0000 - root_mean_squared_error: 0.2304 - val_loss: 0.0694 - val_mean_absolute_percentage_error: 21870342.0000 - val_root_mean_squared_error: 0.2635\n",
      "Epoch 53/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0517 - mean_absolute_percentage_error: 12979442.0000 - root_mean_squared_error: 0.2273 - val_loss: 0.0692 - val_mean_absolute_percentage_error: 22879562.0000 - val_root_mean_squared_error: 0.2631\n",
      "Epoch 54/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0511 - mean_absolute_percentage_error: 13461141.0000 - root_mean_squared_error: 0.2262 - val_loss: 0.0702 - val_mean_absolute_percentage_error: 20448350.0000 - val_root_mean_squared_error: 0.2650\n",
      "Epoch 55/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0501 - mean_absolute_percentage_error: 11431235.0000 - root_mean_squared_error: 0.2239 - val_loss: 0.0704 - val_mean_absolute_percentage_error: 20549622.0000 - val_root_mean_squared_error: 0.2654\n",
      "Epoch 56/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0497 - mean_absolute_percentage_error: 10997342.0000 - root_mean_squared_error: 0.2229 - val_loss: 0.0694 - val_mean_absolute_percentage_error: 22611802.0000 - val_root_mean_squared_error: 0.2635\n",
      "Epoch 57/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0501 - mean_absolute_percentage_error: 12147000.0000 - root_mean_squared_error: 0.2239 - val_loss: 0.0701 - val_mean_absolute_percentage_error: 21890626.0000 - val_root_mean_squared_error: 0.2647\n",
      "Epoch 58/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0495 - mean_absolute_percentage_error: 11404810.0000 - root_mean_squared_error: 0.2225 - val_loss: 0.0707 - val_mean_absolute_percentage_error: 21135328.0000 - val_root_mean_squared_error: 0.2659\n",
      "Epoch 59/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0493 - mean_absolute_percentage_error: 11160283.0000 - root_mean_squared_error: 0.2220 - val_loss: 0.0703 - val_mean_absolute_percentage_error: 22410182.0000 - val_root_mean_squared_error: 0.2652\n",
      "Epoch 60/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0489 - mean_absolute_percentage_error: 11457842.0000 - root_mean_squared_error: 0.2212 - val_loss: 0.0702 - val_mean_absolute_percentage_error: 22877376.0000 - val_root_mean_squared_error: 0.2649\n",
      "Epoch 61/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step - loss: 0.0495 - mean_absolute_percentage_error: 12101861.0000 - root_mean_squared_error: 0.2226 - val_loss: 0.0720 - val_mean_absolute_percentage_error: 21336286.0000 - val_root_mean_squared_error: 0.2683\n",
      "Epoch 62/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0499 - mean_absolute_percentage_error: 10639317.0000 - root_mean_squared_error: 0.2235 - val_loss: 0.0711 - val_mean_absolute_percentage_error: 21367366.0000 - val_root_mean_squared_error: 0.2666\n",
      "Epoch 63/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0498 - mean_absolute_percentage_error: 11403171.0000 - root_mean_squared_error: 0.2233 - val_loss: 0.0701 - val_mean_absolute_percentage_error: 23636360.0000 - val_root_mean_squared_error: 0.2647\n",
      "Epoch 64/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0498 - mean_absolute_percentage_error: 12332691.0000 - root_mean_squared_error: 0.2232 - val_loss: 0.0708 - val_mean_absolute_percentage_error: 22428224.0000 - val_root_mean_squared_error: 0.2661\n",
      "Epoch 65/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0497 - mean_absolute_percentage_error: 11065744.0000 - root_mean_squared_error: 0.2229 - val_loss: 0.0714 - val_mean_absolute_percentage_error: 20847798.0000 - val_root_mean_squared_error: 0.2672\n",
      "Epoch 66/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0496 - mean_absolute_percentage_error: 10982619.0000 - root_mean_squared_error: 0.2227 - val_loss: 0.0697 - val_mean_absolute_percentage_error: 22701354.0000 - val_root_mean_squared_error: 0.2640\n",
      "Epoch 67/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0488 - mean_absolute_percentage_error: 11678850.0000 - root_mean_squared_error: 0.2209 - val_loss: 0.0704 - val_mean_absolute_percentage_error: 23119200.0000 - val_root_mean_squared_error: 0.2653\n",
      "Epoch 68/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0493 - mean_absolute_percentage_error: 11535421.0000 - root_mean_squared_error: 0.2221 - val_loss: 0.0707 - val_mean_absolute_percentage_error: 20941588.0000 - val_root_mean_squared_error: 0.2658\n",
      "Epoch 69/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0488 - mean_absolute_percentage_error: 10422878.0000 - root_mean_squared_error: 0.2208 - val_loss: 0.0698 - val_mean_absolute_percentage_error: 21604352.0000 - val_root_mean_squared_error: 0.2641\n",
      "Epoch 70/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0488 - mean_absolute_percentage_error: 10787127.0000 - root_mean_squared_error: 0.2210 - val_loss: 0.0708 - val_mean_absolute_percentage_error: 22733562.0000 - val_root_mean_squared_error: 0.2661\n",
      "Epoch 71/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0494 - mean_absolute_percentage_error: 11162561.0000 - root_mean_squared_error: 0.2222 - val_loss: 0.0696 - val_mean_absolute_percentage_error: 21793590.0000 - val_root_mean_squared_error: 0.2638\n",
      "Epoch 72/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0487 - mean_absolute_percentage_error: 10818792.0000 - root_mean_squared_error: 0.2206 - val_loss: 0.0722 - val_mean_absolute_percentage_error: 19854742.0000 - val_root_mean_squared_error: 0.2687\n",
      "Epoch 73/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0488 - mean_absolute_percentage_error: 9524750.0000 - root_mean_squared_error: 0.2209 - val_loss: 0.0693 - val_mean_absolute_percentage_error: 22596792.0000 - val_root_mean_squared_error: 0.2632\n",
      "Epoch 74/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0479 - mean_absolute_percentage_error: 11057384.0000 - root_mean_squared_error: 0.2188 - val_loss: 0.0689 - val_mean_absolute_percentage_error: 23002360.0000 - val_root_mean_squared_error: 0.2626\n",
      "Epoch 75/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0482 - mean_absolute_percentage_error: 11460139.0000 - root_mean_squared_error: 0.2195 - val_loss: 0.0729 - val_mean_absolute_percentage_error: 20043676.0000 - val_root_mean_squared_error: 0.2699\n",
      "Epoch 76/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0491 - mean_absolute_percentage_error: 9524048.0000 - root_mean_squared_error: 0.2216 - val_loss: 0.0708 - val_mean_absolute_percentage_error: 21359216.0000 - val_root_mean_squared_error: 0.2660\n",
      "Epoch 77/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0474 - mean_absolute_percentage_error: 10199103.0000 - root_mean_squared_error: 0.2177 - val_loss: 0.0694 - val_mean_absolute_percentage_error: 24196942.0000 - val_root_mean_squared_error: 0.2634\n",
      "Epoch 78/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0500 - mean_absolute_percentage_error: 12333626.0000 - root_mean_squared_error: 0.2235 - val_loss: 0.0753 - val_mean_absolute_percentage_error: 20983390.0000 - val_root_mean_squared_error: 0.2744\n",
      "Epoch 79/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0504 - mean_absolute_percentage_error: 10088348.0000 - root_mean_squared_error: 0.2246 - val_loss: 0.0761 - val_mean_absolute_percentage_error: 20238354.0000 - val_root_mean_squared_error: 0.2759\n",
      "Epoch 80/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0504 - mean_absolute_percentage_error: 9925796.0000 - root_mean_squared_error: 0.2245 - val_loss: 0.0713 - val_mean_absolute_percentage_error: 22105874.0000 - val_root_mean_squared_error: 0.2670\n",
      "Epoch 81/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0480 - mean_absolute_percentage_error: 11060725.0000 - root_mean_squared_error: 0.2190 - val_loss: 0.0687 - val_mean_absolute_percentage_error: 23577126.0000 - val_root_mean_squared_error: 0.2622\n",
      "Epoch 82/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0490 - mean_absolute_percentage_error: 12596163.0000 - root_mean_squared_error: 0.2215 - val_loss: 0.0687 - val_mean_absolute_percentage_error: 22302562.0000 - val_root_mean_squared_error: 0.2620\n",
      "Epoch 83/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0487 - mean_absolute_percentage_error: 11826099.0000 - root_mean_squared_error: 0.2208 - val_loss: 0.0694 - val_mean_absolute_percentage_error: 21786428.0000 - val_root_mean_squared_error: 0.2634\n",
      "Epoch 84/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0472 - mean_absolute_percentage_error: 10716133.0000 - root_mean_squared_error: 0.2172 - val_loss: 0.0708 - val_mean_absolute_percentage_error: 22044634.0000 - val_root_mean_squared_error: 0.2662\n",
      "Epoch 85/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0469 - mean_absolute_percentage_error: 10627254.0000 - root_mean_squared_error: 0.2165 - val_loss: 0.0670 - val_mean_absolute_percentage_error: 21477250.0000 - val_root_mean_squared_error: 0.2588\n",
      "Epoch 86/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0448 - mean_absolute_percentage_error: 10534477.0000 - root_mean_squared_error: 0.2116 - val_loss: 0.0673 - val_mean_absolute_percentage_error: 21603314.0000 - val_root_mean_squared_error: 0.2594\n",
      "Epoch 87/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0439 - mean_absolute_percentage_error: 10178210.0000 - root_mean_squared_error: 0.2096 - val_loss: 0.0683 - val_mean_absolute_percentage_error: 21316744.0000 - val_root_mean_squared_error: 0.2613\n",
      "Epoch 88/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0428 - mean_absolute_percentage_error: 9728150.0000 - root_mean_squared_error: 0.2068 - val_loss: 0.0652 - val_mean_absolute_percentage_error: 22300074.0000 - val_root_mean_squared_error: 0.2553\n",
      "Epoch 89/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0441 - mean_absolute_percentage_error: 9773453.0000 - root_mean_squared_error: 0.2101 - val_loss: 0.1110 - val_mean_absolute_percentage_error: 24378366.0000 - val_root_mean_squared_error: 0.3332\n",
      "Epoch 90/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0775 - mean_absolute_percentage_error: 13888038.0000 - root_mean_squared_error: 0.2783 - val_loss: 0.0772 - val_mean_absolute_percentage_error: 16791632.0000 - val_root_mean_squared_error: 0.2778\n",
      "Epoch 91/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step - loss: 0.0608 - mean_absolute_percentage_error: 10251176.0000 - root_mean_squared_error: 0.2466 - val_loss: 0.0694 - val_mean_absolute_percentage_error: 22838746.0000 - val_root_mean_squared_error: 0.2634\n",
      "Epoch 92/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0549 - mean_absolute_percentage_error: 14120565.0000 - root_mean_squared_error: 0.2342 - val_loss: 0.0661 - val_mean_absolute_percentage_error: 21408514.0000 - val_root_mean_squared_error: 0.2571\n",
      "Epoch 93/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0567 - mean_absolute_percentage_error: 17716636.0000 - root_mean_squared_error: 0.2381 - val_loss: 0.0788 - val_mean_absolute_percentage_error: 20218904.0000 - val_root_mean_squared_error: 0.2807\n",
      "Epoch 94/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0503 - mean_absolute_percentage_error: 10637861.0000 - root_mean_squared_error: 0.2244 - val_loss: 0.0728 - val_mean_absolute_percentage_error: 23606922.0000 - val_root_mean_squared_error: 0.2698\n",
      "Epoch 95/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0468 - mean_absolute_percentage_error: 11450243.0000 - root_mean_squared_error: 0.2162 - val_loss: 0.0684 - val_mean_absolute_percentage_error: 23806478.0000 - val_root_mean_squared_error: 0.2615\n",
      "Epoch 96/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0549 - mean_absolute_percentage_error: 13123238.0000 - root_mean_squared_error: 0.2343 - val_loss: 0.0672 - val_mean_absolute_percentage_error: 21246116.0000 - val_root_mean_squared_error: 0.2592\n",
      "Epoch 97/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0433 - mean_absolute_percentage_error: 10260690.0000 - root_mean_squared_error: 0.2081 - val_loss: 0.0672 - val_mean_absolute_percentage_error: 19497714.0000 - val_root_mean_squared_error: 0.2592\n",
      "Epoch 98/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0441 - mean_absolute_percentage_error: 10089274.0000 - root_mean_squared_error: 0.2101 - val_loss: 0.0632 - val_mean_absolute_percentage_error: 21399542.0000 - val_root_mean_squared_error: 0.2514\n",
      "Epoch 99/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0431 - mean_absolute_percentage_error: 12284521.0000 - root_mean_squared_error: 0.2077 - val_loss: 0.0650 - val_mean_absolute_percentage_error: 21565470.0000 - val_root_mean_squared_error: 0.2549\n",
      "Epoch 100/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0443 - mean_absolute_percentage_error: 13427530.0000 - root_mean_squared_error: 0.2106 - val_loss: 0.0646 - val_mean_absolute_percentage_error: 21616648.0000 - val_root_mean_squared_error: 0.2541\n",
      "Epoch 101/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0475 - mean_absolute_percentage_error: 10605695.0000 - root_mean_squared_error: 0.2180 - val_loss: 0.1010 - val_mean_absolute_percentage_error: 21921466.0000 - val_root_mean_squared_error: 0.3179\n",
      "Epoch 102/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0739 - mean_absolute_percentage_error: 13399755.0000 - root_mean_squared_error: 0.2719 - val_loss: 0.0965 - val_mean_absolute_percentage_error: 22405294.0000 - val_root_mean_squared_error: 0.3107\n",
      "Epoch 103/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0747 - mean_absolute_percentage_error: 14070666.0000 - root_mean_squared_error: 0.2733 - val_loss: 0.0733 - val_mean_absolute_percentage_error: 20239484.0000 - val_root_mean_squared_error: 0.2708\n",
      "Epoch 104/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0624 - mean_absolute_percentage_error: 14656611.0000 - root_mean_squared_error: 0.2497 - val_loss: 0.0651 - val_mean_absolute_percentage_error: 19625582.0000 - val_root_mean_squared_error: 0.2551\n",
      "Epoch 105/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0644 - mean_absolute_percentage_error: 16871182.0000 - root_mean_squared_error: 0.2537 - val_loss: 0.0692 - val_mean_absolute_percentage_error: 19653968.0000 - val_root_mean_squared_error: 0.2631\n",
      "Epoch 106/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0649 - mean_absolute_percentage_error: 16094494.0000 - root_mean_squared_error: 0.2548 - val_loss: 0.0701 - val_mean_absolute_percentage_error: 20670042.0000 - val_root_mean_squared_error: 0.2647\n",
      "Epoch 107/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0588 - mean_absolute_percentage_error: 14329403.0000 - root_mean_squared_error: 0.2426 - val_loss: 0.0717 - val_mean_absolute_percentage_error: 24245130.0000 - val_root_mean_squared_error: 0.2678\n",
      "Epoch 108/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0577 - mean_absolute_percentage_error: 15356366.0000 - root_mean_squared_error: 0.2402 - val_loss: 0.0747 - val_mean_absolute_percentage_error: 24936238.0000 - val_root_mean_squared_error: 0.2733\n",
      "Epoch 109/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0576 - mean_absolute_percentage_error: 15663557.0000 - root_mean_squared_error: 0.2400 - val_loss: 0.0717 - val_mean_absolute_percentage_error: 23065376.0000 - val_root_mean_squared_error: 0.2677\n",
      "Epoch 110/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0543 - mean_absolute_percentage_error: 13822291.0000 - root_mean_squared_error: 0.2330 - val_loss: 0.0696 - val_mean_absolute_percentage_error: 24183758.0000 - val_root_mean_squared_error: 0.2638\n",
      "Epoch 111/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0520 - mean_absolute_percentage_error: 13399272.0000 - root_mean_squared_error: 0.2280 - val_loss: 0.0697 - val_mean_absolute_percentage_error: 24642618.0000 - val_root_mean_squared_error: 0.2640\n",
      "Epoch 112/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0500 - mean_absolute_percentage_error: 12672467.0000 - root_mean_squared_error: 0.2236 - val_loss: 0.0676 - val_mean_absolute_percentage_error: 21679334.0000 - val_root_mean_squared_error: 0.2600\n",
      "Epoch 113/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0471 - mean_absolute_percentage_error: 9857888.0000 - root_mean_squared_error: 0.2171 - val_loss: 0.0666 - val_mean_absolute_percentage_error: 20887830.0000 - val_root_mean_squared_error: 0.2581\n",
      "Epoch 114/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0449 - mean_absolute_percentage_error: 9017253.0000 - root_mean_squared_error: 0.2120 - val_loss: 0.0644 - val_mean_absolute_percentage_error: 21209598.0000 - val_root_mean_squared_error: 0.2538\n",
      "Epoch 115/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0419 - mean_absolute_percentage_error: 8081797.0000 - root_mean_squared_error: 0.2046 - val_loss: 0.0637 - val_mean_absolute_percentage_error: 22850270.0000 - val_root_mean_squared_error: 0.2524\n",
      "Epoch 116/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0420 - mean_absolute_percentage_error: 8507307.0000 - root_mean_squared_error: 0.2051 - val_loss: 0.0657 - val_mean_absolute_percentage_error: 19863316.0000 - val_root_mean_squared_error: 0.2563\n",
      "Epoch 117/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0409 - mean_absolute_percentage_error: 7971861.5000 - root_mean_squared_error: 0.2023 - val_loss: 0.0636 - val_mean_absolute_percentage_error: 18935986.0000 - val_root_mean_squared_error: 0.2523\n",
      "Epoch 118/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0400 - mean_absolute_percentage_error: 8502542.0000 - root_mean_squared_error: 0.2000 - val_loss: 0.0616 - val_mean_absolute_percentage_error: 20137578.0000 - val_root_mean_squared_error: 0.2481\n",
      "Epoch 119/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0382 - mean_absolute_percentage_error: 9089466.0000 - root_mean_squared_error: 0.1956 - val_loss: 0.0649 - val_mean_absolute_percentage_error: 18346892.0000 - val_root_mean_squared_error: 0.2547\n",
      "Epoch 120/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0390 - mean_absolute_percentage_error: 7501533.0000 - root_mean_squared_error: 0.1974 - val_loss: 0.0637 - val_mean_absolute_percentage_error: 21966004.0000 - val_root_mean_squared_error: 0.2523\n",
      "Epoch 121/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step - loss: 0.0412 - mean_absolute_percentage_error: 8643824.0000 - root_mean_squared_error: 0.2031 - val_loss: 0.0655 - val_mean_absolute_percentage_error: 17029944.0000 - val_root_mean_squared_error: 0.2560\n",
      "Epoch 122/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0417 - mean_absolute_percentage_error: 6249092.5000 - root_mean_squared_error: 0.2041 - val_loss: 0.0617 - val_mean_absolute_percentage_error: 18725130.0000 - val_root_mean_squared_error: 0.2484\n",
      "Epoch 123/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0388 - mean_absolute_percentage_error: 6796825.5000 - root_mean_squared_error: 0.1970 - val_loss: 0.0644 - val_mean_absolute_percentage_error: 20474042.0000 - val_root_mean_squared_error: 0.2537\n",
      "Epoch 124/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0400 - mean_absolute_percentage_error: 7902593.5000 - root_mean_squared_error: 0.2000 - val_loss: 0.0674 - val_mean_absolute_percentage_error: 15864261.0000 - val_root_mean_squared_error: 0.2597\n",
      "Epoch 125/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0394 - mean_absolute_percentage_error: 6400483.0000 - root_mean_squared_error: 0.1985 - val_loss: 0.0643 - val_mean_absolute_percentage_error: 16233699.0000 - val_root_mean_squared_error: 0.2536\n",
      "Epoch 126/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0388 - mean_absolute_percentage_error: 6712897.5000 - root_mean_squared_error: 0.1970 - val_loss: 0.0624 - val_mean_absolute_percentage_error: 20011250.0000 - val_root_mean_squared_error: 0.2498\n",
      "Epoch 127/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0395 - mean_absolute_percentage_error: 7953101.0000 - root_mean_squared_error: 0.1988 - val_loss: 0.0609 - val_mean_absolute_percentage_error: 18769874.0000 - val_root_mean_squared_error: 0.2467\n",
      "Epoch 128/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0372 - mean_absolute_percentage_error: 7168129.5000 - root_mean_squared_error: 0.1928 - val_loss: 0.0632 - val_mean_absolute_percentage_error: 17543172.0000 - val_root_mean_squared_error: 0.2514\n",
      "Epoch 129/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0379 - mean_absolute_percentage_error: 6624103.0000 - root_mean_squared_error: 0.1948 - val_loss: 0.0618 - val_mean_absolute_percentage_error: 19276338.0000 - val_root_mean_squared_error: 0.2486\n",
      "Epoch 130/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0373 - mean_absolute_percentage_error: 7229458.5000 - root_mean_squared_error: 0.1932 - val_loss: 0.0611 - val_mean_absolute_percentage_error: 21265896.0000 - val_root_mean_squared_error: 0.2471\n",
      "Epoch 131/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0373 - mean_absolute_percentage_error: 7727177.5000 - root_mean_squared_error: 0.1932 - val_loss: 0.0608 - val_mean_absolute_percentage_error: 19949884.0000 - val_root_mean_squared_error: 0.2466\n",
      "Epoch 132/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0367 - mean_absolute_percentage_error: 7064859.0000 - root_mean_squared_error: 0.1916 - val_loss: 0.0625 - val_mean_absolute_percentage_error: 19245502.0000 - val_root_mean_squared_error: 0.2501\n",
      "Epoch 133/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0370 - mean_absolute_percentage_error: 7063932.0000 - root_mean_squared_error: 0.1924 - val_loss: 0.0610 - val_mean_absolute_percentage_error: 20267810.0000 - val_root_mean_squared_error: 0.2469\n",
      "Epoch 134/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0363 - mean_absolute_percentage_error: 7342219.0000 - root_mean_squared_error: 0.1906 - val_loss: 0.0608 - val_mean_absolute_percentage_error: 20826416.0000 - val_root_mean_squared_error: 0.2466\n",
      "Epoch 135/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0359 - mean_absolute_percentage_error: 7456489.0000 - root_mean_squared_error: 0.1894 - val_loss: 0.0604 - val_mean_absolute_percentage_error: 19670874.0000 - val_root_mean_squared_error: 0.2458\n",
      "Epoch 136/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0360 - mean_absolute_percentage_error: 7126527.0000 - root_mean_squared_error: 0.1898 - val_loss: 0.0619 - val_mean_absolute_percentage_error: 18360526.0000 - val_root_mean_squared_error: 0.2489\n",
      "Epoch 137/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0357 - mean_absolute_percentage_error: 6942621.0000 - root_mean_squared_error: 0.1889 - val_loss: 0.0610 - val_mean_absolute_percentage_error: 18414178.0000 - val_root_mean_squared_error: 0.2470\n",
      "Epoch 138/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0348 - mean_absolute_percentage_error: 6778933.0000 - root_mean_squared_error: 0.1865 - val_loss: 0.0605 - val_mean_absolute_percentage_error: 19415062.0000 - val_root_mean_squared_error: 0.2459\n",
      "Epoch 139/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0350 - mean_absolute_percentage_error: 7002848.0000 - root_mean_squared_error: 0.1872 - val_loss: 0.0605 - val_mean_absolute_percentage_error: 19261150.0000 - val_root_mean_squared_error: 0.2460\n",
      "Epoch 140/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0345 - mean_absolute_percentage_error: 6882729.0000 - root_mean_squared_error: 0.1859 - val_loss: 0.0611 - val_mean_absolute_percentage_error: 18308004.0000 - val_root_mean_squared_error: 0.2472\n",
      "Epoch 141/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0339 - mean_absolute_percentage_error: 6343187.5000 - root_mean_squared_error: 0.1841 - val_loss: 0.0611 - val_mean_absolute_percentage_error: 18508318.0000 - val_root_mean_squared_error: 0.2473\n",
      "Epoch 142/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0338 - mean_absolute_percentage_error: 6289820.0000 - root_mean_squared_error: 0.1839 - val_loss: 0.0609 - val_mean_absolute_percentage_error: 19459764.0000 - val_root_mean_squared_error: 0.2469\n",
      "Epoch 143/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0333 - mean_absolute_percentage_error: 6566415.0000 - root_mean_squared_error: 0.1826 - val_loss: 0.0612 - val_mean_absolute_percentage_error: 19618472.0000 - val_root_mean_squared_error: 0.2474\n",
      "Epoch 144/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0328 - mean_absolute_percentage_error: 6411122.5000 - root_mean_squared_error: 0.1810 - val_loss: 0.0614 - val_mean_absolute_percentage_error: 18521944.0000 - val_root_mean_squared_error: 0.2478\n",
      "Epoch 145/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0321 - mean_absolute_percentage_error: 6094607.0000 - root_mean_squared_error: 0.1792 - val_loss: 0.0615 - val_mean_absolute_percentage_error: 18543278.0000 - val_root_mean_squared_error: 0.2479\n",
      "Epoch 146/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0327 - mean_absolute_percentage_error: 6135756.5000 - root_mean_squared_error: 0.1807 - val_loss: 0.0619 - val_mean_absolute_percentage_error: 19394610.0000 - val_root_mean_squared_error: 0.2488\n",
      "Epoch 147/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0321 - mean_absolute_percentage_error: 6326782.5000 - root_mean_squared_error: 0.1792 - val_loss: 0.0616 - val_mean_absolute_percentage_error: 18664852.0000 - val_root_mean_squared_error: 0.2481\n",
      "Epoch 148/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0316 - mean_absolute_percentage_error: 6318377.0000 - root_mean_squared_error: 0.1779 - val_loss: 0.0620 - val_mean_absolute_percentage_error: 17901850.0000 - val_root_mean_squared_error: 0.2489\n",
      "Epoch 149/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0319 - mean_absolute_percentage_error: 6109305.0000 - root_mean_squared_error: 0.1785 - val_loss: 0.0621 - val_mean_absolute_percentage_error: 18108762.0000 - val_root_mean_squared_error: 0.2492\n",
      "Epoch 150/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0319 - mean_absolute_percentage_error: 6070997.0000 - root_mean_squared_error: 0.1785 - val_loss: 0.0624 - val_mean_absolute_percentage_error: 18707422.0000 - val_root_mean_squared_error: 0.2498\n",
      "Epoch 151/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step - loss: 0.0316 - mean_absolute_percentage_error: 6132691.5000 - root_mean_squared_error: 0.1779 - val_loss: 0.0629 - val_mean_absolute_percentage_error: 18692332.0000 - val_root_mean_squared_error: 0.2507\n",
      "Epoch 152/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0315 - mean_absolute_percentage_error: 5871704.5000 - root_mean_squared_error: 0.1774 - val_loss: 0.0627 - val_mean_absolute_percentage_error: 18214962.0000 - val_root_mean_squared_error: 0.2505\n",
      "Epoch 153/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0317 - mean_absolute_percentage_error: 5772836.5000 - root_mean_squared_error: 0.1780 - val_loss: 0.0621 - val_mean_absolute_percentage_error: 18161962.0000 - val_root_mean_squared_error: 0.2492\n",
      "Epoch 154/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0313 - mean_absolute_percentage_error: 5953736.0000 - root_mean_squared_error: 0.1768 - val_loss: 0.0624 - val_mean_absolute_percentage_error: 18893990.0000 - val_root_mean_squared_error: 0.2497\n",
      "Epoch 155/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0312 - mean_absolute_percentage_error: 5935620.0000 - root_mean_squared_error: 0.1765 - val_loss: 0.0623 - val_mean_absolute_percentage_error: 18808196.0000 - val_root_mean_squared_error: 0.2497\n",
      "Epoch 156/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0308 - mean_absolute_percentage_error: 5830865.0000 - root_mean_squared_error: 0.1754 - val_loss: 0.0616 - val_mean_absolute_percentage_error: 18321290.0000 - val_root_mean_squared_error: 0.2483\n",
      "Epoch 157/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0309 - mean_absolute_percentage_error: 5785236.0000 - root_mean_squared_error: 0.1757 - val_loss: 0.0621 - val_mean_absolute_percentage_error: 19023210.0000 - val_root_mean_squared_error: 0.2493\n",
      "Epoch 158/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0309 - mean_absolute_percentage_error: 5650901.5000 - root_mean_squared_error: 0.1758 - val_loss: 0.0617 - val_mean_absolute_percentage_error: 18947726.0000 - val_root_mean_squared_error: 0.2483\n",
      "Epoch 159/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0310 - mean_absolute_percentage_error: 5694744.5000 - root_mean_squared_error: 0.1761 - val_loss: 0.0615 - val_mean_absolute_percentage_error: 18510396.0000 - val_root_mean_squared_error: 0.2480\n",
      "Epoch 160/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0310 - mean_absolute_percentage_error: 5599854.0000 - root_mean_squared_error: 0.1759 - val_loss: 0.0622 - val_mean_absolute_percentage_error: 18651086.0000 - val_root_mean_squared_error: 0.2495\n",
      "Epoch 161/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0310 - mean_absolute_percentage_error: 5553180.0000 - root_mean_squared_error: 0.1762 - val_loss: 0.0620 - val_mean_absolute_percentage_error: 18817140.0000 - val_root_mean_squared_error: 0.2490\n",
      "Epoch 162/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0304 - mean_absolute_percentage_error: 5736776.5000 - root_mean_squared_error: 0.1745 - val_loss: 0.0621 - val_mean_absolute_percentage_error: 18803570.0000 - val_root_mean_squared_error: 0.2493\n",
      "Epoch 163/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0306 - mean_absolute_percentage_error: 5680979.0000 - root_mean_squared_error: 0.1749 - val_loss: 0.0625 - val_mean_absolute_percentage_error: 18592102.0000 - val_root_mean_squared_error: 0.2500\n",
      "Epoch 164/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0303 - mean_absolute_percentage_error: 5582918.0000 - root_mean_squared_error: 0.1741 - val_loss: 0.0622 - val_mean_absolute_percentage_error: 18659472.0000 - val_root_mean_squared_error: 0.2494\n",
      "Epoch 165/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0302 - mean_absolute_percentage_error: 5683118.5000 - root_mean_squared_error: 0.1737 - val_loss: 0.0631 - val_mean_absolute_percentage_error: 19086582.0000 - val_root_mean_squared_error: 0.2512\n",
      "Epoch 166/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0303 - mean_absolute_percentage_error: 5696561.5000 - root_mean_squared_error: 0.1742 - val_loss: 0.0626 - val_mean_absolute_percentage_error: 18437558.0000 - val_root_mean_squared_error: 0.2502\n",
      "Epoch 167/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0302 - mean_absolute_percentage_error: 5655679.0000 - root_mean_squared_error: 0.1737 - val_loss: 0.0635 - val_mean_absolute_percentage_error: 18534994.0000 - val_root_mean_squared_error: 0.2521\n",
      "Epoch 168/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0310 - mean_absolute_percentage_error: 5511774.5000 - root_mean_squared_error: 0.1760 - val_loss: 0.0626 - val_mean_absolute_percentage_error: 18102214.0000 - val_root_mean_squared_error: 0.2502\n",
      "Epoch 169/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0306 - mean_absolute_percentage_error: 5718967.0000 - root_mean_squared_error: 0.1749 - val_loss: 0.0639 - val_mean_absolute_percentage_error: 18653542.0000 - val_root_mean_squared_error: 0.2528\n",
      "Epoch 170/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0302 - mean_absolute_percentage_error: 5616820.0000 - root_mean_squared_error: 0.1737 - val_loss: 0.0628 - val_mean_absolute_percentage_error: 17701732.0000 - val_root_mean_squared_error: 0.2506\n",
      "Epoch 171/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0305 - mean_absolute_percentage_error: 5687488.5000 - root_mean_squared_error: 0.1745 - val_loss: 0.0652 - val_mean_absolute_percentage_error: 18636788.0000 - val_root_mean_squared_error: 0.2554\n",
      "Epoch 172/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0310 - mean_absolute_percentage_error: 5554296.5000 - root_mean_squared_error: 0.1762 - val_loss: 0.0630 - val_mean_absolute_percentage_error: 17320138.0000 - val_root_mean_squared_error: 0.2510\n",
      "Epoch 173/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0304 - mean_absolute_percentage_error: 5715991.0000 - root_mean_squared_error: 0.1744 - val_loss: 0.0647 - val_mean_absolute_percentage_error: 18490094.0000 - val_root_mean_squared_error: 0.2543\n",
      "Epoch 174/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0301 - mean_absolute_percentage_error: 5544723.0000 - root_mean_squared_error: 0.1735 - val_loss: 0.0648 - val_mean_absolute_percentage_error: 18222198.0000 - val_root_mean_squared_error: 0.2546\n",
      "Epoch 175/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0298 - mean_absolute_percentage_error: 5501749.0000 - root_mean_squared_error: 0.1725 - val_loss: 0.0643 - val_mean_absolute_percentage_error: 17222040.0000 - val_root_mean_squared_error: 0.2536\n",
      "Epoch 176/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0298 - mean_absolute_percentage_error: 5534713.0000 - root_mean_squared_error: 0.1726 - val_loss: 0.0656 - val_mean_absolute_percentage_error: 18525774.0000 - val_root_mean_squared_error: 0.2561\n",
      "Epoch 177/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0302 - mean_absolute_percentage_error: 5580558.5000 - root_mean_squared_error: 0.1737 - val_loss: 0.0700 - val_mean_absolute_percentage_error: 15961697.0000 - val_root_mean_squared_error: 0.2645\n",
      "Epoch 178/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0344 - mean_absolute_percentage_error: 6489039.5000 - root_mean_squared_error: 0.1855 - val_loss: 0.0675 - val_mean_absolute_percentage_error: 21217802.0000 - val_root_mean_squared_error: 0.2598\n",
      "Epoch 179/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0424 - mean_absolute_percentage_error: 7303585.0000 - root_mean_squared_error: 0.2059 - val_loss: 0.0648 - val_mean_absolute_percentage_error: 16435080.0000 - val_root_mean_squared_error: 0.2546\n",
      "Epoch 180/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0356 - mean_absolute_percentage_error: 7291773.0000 - root_mean_squared_error: 0.1886 - val_loss: 0.0722 - val_mean_absolute_percentage_error: 14027900.0000 - val_root_mean_squared_error: 0.2687\n",
      "Epoch 181/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step - loss: 0.0376 - mean_absolute_percentage_error: 6071516.5000 - root_mean_squared_error: 0.1938 - val_loss: 0.0675 - val_mean_absolute_percentage_error: 17329250.0000 - val_root_mean_squared_error: 0.2598\n",
      "Epoch 182/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0331 - mean_absolute_percentage_error: 6254555.0000 - root_mean_squared_error: 0.1820 - val_loss: 0.0694 - val_mean_absolute_percentage_error: 21816078.0000 - val_root_mean_squared_error: 0.2635\n",
      "Epoch 183/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0372 - mean_absolute_percentage_error: 8562254.0000 - root_mean_squared_error: 0.1928 - val_loss: 0.0633 - val_mean_absolute_percentage_error: 17889694.0000 - val_root_mean_squared_error: 0.2515\n",
      "Epoch 184/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0318 - mean_absolute_percentage_error: 6010587.5000 - root_mean_squared_error: 0.1782 - val_loss: 0.0756 - val_mean_absolute_percentage_error: 15347472.0000 - val_root_mean_squared_error: 0.2750\n",
      "Epoch 185/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0412 - mean_absolute_percentage_error: 5865373.5000 - root_mean_squared_error: 0.2030 - val_loss: 0.0652 - val_mean_absolute_percentage_error: 21570044.0000 - val_root_mean_squared_error: 0.2553\n",
      "Epoch 186/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0357 - mean_absolute_percentage_error: 8139129.0000 - root_mean_squared_error: 0.1889 - val_loss: 0.0661 - val_mean_absolute_percentage_error: 21788456.0000 - val_root_mean_squared_error: 0.2571\n",
      "Epoch 187/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0435 - mean_absolute_percentage_error: 9312857.0000 - root_mean_squared_error: 0.2086 - val_loss: 0.0876 - val_mean_absolute_percentage_error: 14979860.0000 - val_root_mean_squared_error: 0.2961\n",
      "Epoch 188/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0472 - mean_absolute_percentage_error: 6783441.5000 - root_mean_squared_error: 0.2172 - val_loss: 0.0902 - val_mean_absolute_percentage_error: 16018949.0000 - val_root_mean_squared_error: 0.3003\n",
      "Epoch 189/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0527 - mean_absolute_percentage_error: 7937183.0000 - root_mean_squared_error: 0.2297 - val_loss: 0.0699 - val_mean_absolute_percentage_error: 18244906.0000 - val_root_mean_squared_error: 0.2644\n",
      "Epoch 190/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0373 - mean_absolute_percentage_error: 6659567.5000 - root_mean_squared_error: 0.1931 - val_loss: 0.0841 - val_mean_absolute_percentage_error: 25507290.0000 - val_root_mean_squared_error: 0.2899\n",
      "Epoch 191/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0452 - mean_absolute_percentage_error: 9772826.0000 - root_mean_squared_error: 0.2126 - val_loss: 0.0658 - val_mean_absolute_percentage_error: 22121122.0000 - val_root_mean_squared_error: 0.2565\n",
      "Epoch 192/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0392 - mean_absolute_percentage_error: 8770598.0000 - root_mean_squared_error: 0.1979 - val_loss: 0.0602 - val_mean_absolute_percentage_error: 17239646.0000 - val_root_mean_squared_error: 0.2454\n",
      "Epoch 193/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0401 - mean_absolute_percentage_error: 8305501.5000 - root_mean_squared_error: 0.2003 - val_loss: 0.0653 - val_mean_absolute_percentage_error: 16642913.0000 - val_root_mean_squared_error: 0.2555\n",
      "Epoch 194/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0411 - mean_absolute_percentage_error: 7860712.0000 - root_mean_squared_error: 0.2026 - val_loss: 0.0642 - val_mean_absolute_percentage_error: 17176718.0000 - val_root_mean_squared_error: 0.2533\n",
      "Epoch 195/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0356 - mean_absolute_percentage_error: 7509822.5000 - root_mean_squared_error: 0.1887 - val_loss: 0.0595 - val_mean_absolute_percentage_error: 18258442.0000 - val_root_mean_squared_error: 0.2439\n",
      "Epoch 196/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0372 - mean_absolute_percentage_error: 7924052.0000 - root_mean_squared_error: 0.1929 - val_loss: 0.0663 - val_mean_absolute_percentage_error: 19982754.0000 - val_root_mean_squared_error: 0.2574\n",
      "Epoch 197/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0448 - mean_absolute_percentage_error: 13897811.0000 - root_mean_squared_error: 0.2116 - val_loss: 0.0730 - val_mean_absolute_percentage_error: 15030724.0000 - val_root_mean_squared_error: 0.2701\n",
      "Epoch 198/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0647 - mean_absolute_percentage_error: 9008038.0000 - root_mean_squared_error: 0.2544 - val_loss: 0.0641 - val_mean_absolute_percentage_error: 16312739.0000 - val_root_mean_squared_error: 0.2531\n",
      "Epoch 199/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0367 - mean_absolute_percentage_error: 6762297.0000 - root_mean_squared_error: 0.1916 - val_loss: 0.0619 - val_mean_absolute_percentage_error: 19801374.0000 - val_root_mean_squared_error: 0.2488\n",
      "Epoch 200/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0521 - mean_absolute_percentage_error: 12409868.0000 - root_mean_squared_error: 0.2283 - val_loss: 0.0732 - val_mean_absolute_percentage_error: 19409274.0000 - val_root_mean_squared_error: 0.2706\n",
      "Epoch 201/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0397 - mean_absolute_percentage_error: 8394834.0000 - root_mean_squared_error: 0.1993 - val_loss: 0.0752 - val_mean_absolute_percentage_error: 20239088.0000 - val_root_mean_squared_error: 0.2742\n",
      "Epoch 202/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0586 - mean_absolute_percentage_error: 10924339.0000 - root_mean_squared_error: 0.2420 - val_loss: 0.0803 - val_mean_absolute_percentage_error: 21623698.0000 - val_root_mean_squared_error: 0.2834\n",
      "Epoch 203/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0710 - mean_absolute_percentage_error: 17709404.0000 - root_mean_squared_error: 0.2665 - val_loss: 0.0777 - val_mean_absolute_percentage_error: 19412462.0000 - val_root_mean_squared_error: 0.2788\n",
      "Epoch 204/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0730 - mean_absolute_percentage_error: 16540000.0000 - root_mean_squared_error: 0.2701 - val_loss: 0.0809 - val_mean_absolute_percentage_error: 15079892.0000 - val_root_mean_squared_error: 0.2845\n",
      "Epoch 205/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0695 - mean_absolute_percentage_error: 12560013.0000 - root_mean_squared_error: 0.2637 - val_loss: 0.0702 - val_mean_absolute_percentage_error: 15720868.0000 - val_root_mean_squared_error: 0.2649\n",
      "Epoch 206/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0599 - mean_absolute_percentage_error: 12220301.0000 - root_mean_squared_error: 0.2447 - val_loss: 0.0616 - val_mean_absolute_percentage_error: 20966920.0000 - val_root_mean_squared_error: 0.2483\n",
      "Epoch 207/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0619 - mean_absolute_percentage_error: 15520509.0000 - root_mean_squared_error: 0.2488 - val_loss: 0.0628 - val_mean_absolute_percentage_error: 20053198.0000 - val_root_mean_squared_error: 0.2506\n",
      "Epoch 208/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0558 - mean_absolute_percentage_error: 13376190.0000 - root_mean_squared_error: 0.2363 - val_loss: 0.0701 - val_mean_absolute_percentage_error: 19746264.0000 - val_root_mean_squared_error: 0.2648\n",
      "Epoch 209/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0539 - mean_absolute_percentage_error: 11859451.0000 - root_mean_squared_error: 0.2322 - val_loss: 0.0695 - val_mean_absolute_percentage_error: 22872616.0000 - val_root_mean_squared_error: 0.2636\n",
      "Epoch 210/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0525 - mean_absolute_percentage_error: 11958925.0000 - root_mean_squared_error: 0.2291 - val_loss: 0.0724 - val_mean_absolute_percentage_error: 24750930.0000 - val_root_mean_squared_error: 0.2691\n",
      "Epoch 211/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step - loss: 0.0533 - mean_absolute_percentage_error: 12274106.0000 - root_mean_squared_error: 0.2309 - val_loss: 0.0706 - val_mean_absolute_percentage_error: 24061758.0000 - val_root_mean_squared_error: 0.2657\n",
      "Epoch 212/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0526 - mean_absolute_percentage_error: 11675742.0000 - root_mean_squared_error: 0.2293 - val_loss: 0.0689 - val_mean_absolute_percentage_error: 21460310.0000 - val_root_mean_squared_error: 0.2625\n",
      "Epoch 213/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0503 - mean_absolute_percentage_error: 10156613.0000 - root_mean_squared_error: 0.2243 - val_loss: 0.0644 - val_mean_absolute_percentage_error: 24133024.0000 - val_root_mean_squared_error: 0.2538\n",
      "Epoch 214/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0486 - mean_absolute_percentage_error: 10921826.0000 - root_mean_squared_error: 0.2205 - val_loss: 0.0618 - val_mean_absolute_percentage_error: 21963202.0000 - val_root_mean_squared_error: 0.2486\n",
      "Epoch 215/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0463 - mean_absolute_percentage_error: 10583733.0000 - root_mean_squared_error: 0.2152 - val_loss: 0.0632 - val_mean_absolute_percentage_error: 19246272.0000 - val_root_mean_squared_error: 0.2514\n",
      "Epoch 216/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0454 - mean_absolute_percentage_error: 9784835.0000 - root_mean_squared_error: 0.2131 - val_loss: 0.0616 - val_mean_absolute_percentage_error: 19491478.0000 - val_root_mean_squared_error: 0.2483\n",
      "Epoch 217/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0436 - mean_absolute_percentage_error: 10093395.0000 - root_mean_squared_error: 0.2089 - val_loss: 0.0595 - val_mean_absolute_percentage_error: 19476060.0000 - val_root_mean_squared_error: 0.2439\n",
      "Epoch 218/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0431 - mean_absolute_percentage_error: 10432126.0000 - root_mean_squared_error: 0.2075 - val_loss: 0.0601 - val_mean_absolute_percentage_error: 18289416.0000 - val_root_mean_squared_error: 0.2451\n",
      "Epoch 219/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0401 - mean_absolute_percentage_error: 9041867.0000 - root_mean_squared_error: 0.2004 - val_loss: 0.0611 - val_mean_absolute_percentage_error: 17337550.0000 - val_root_mean_squared_error: 0.2471\n",
      "Epoch 220/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0398 - mean_absolute_percentage_error: 7912370.5000 - root_mean_squared_error: 0.1995 - val_loss: 0.0596 - val_mean_absolute_percentage_error: 18807582.0000 - val_root_mean_squared_error: 0.2441\n",
      "Epoch 221/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0379 - mean_absolute_percentage_error: 7811600.0000 - root_mean_squared_error: 0.1947 - val_loss: 0.0596 - val_mean_absolute_percentage_error: 19973128.0000 - val_root_mean_squared_error: 0.2441\n",
      "Epoch 222/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0370 - mean_absolute_percentage_error: 7776307.0000 - root_mean_squared_error: 0.1922 - val_loss: 0.0605 - val_mean_absolute_percentage_error: 18434326.0000 - val_root_mean_squared_error: 0.2461\n",
      "Epoch 223/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0362 - mean_absolute_percentage_error: 7357711.0000 - root_mean_squared_error: 0.1903 - val_loss: 0.0607 - val_mean_absolute_percentage_error: 19834044.0000 - val_root_mean_squared_error: 0.2463\n",
      "Epoch 224/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0374 - mean_absolute_percentage_error: 7651033.0000 - root_mean_squared_error: 0.1934 - val_loss: 0.0709 - val_mean_absolute_percentage_error: 19560600.0000 - val_root_mean_squared_error: 0.2663\n",
      "Epoch 225/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0441 - mean_absolute_percentage_error: 7668317.0000 - root_mean_squared_error: 0.2099 - val_loss: 0.0610 - val_mean_absolute_percentage_error: 17771842.0000 - val_root_mean_squared_error: 0.2470\n",
      "Epoch 226/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0379 - mean_absolute_percentage_error: 6548887.5000 - root_mean_squared_error: 0.1947 - val_loss: 0.0637 - val_mean_absolute_percentage_error: 20270570.0000 - val_root_mean_squared_error: 0.2523\n",
      "Epoch 227/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0410 - mean_absolute_percentage_error: 7377855.0000 - root_mean_squared_error: 0.2024 - val_loss: 0.0610 - val_mean_absolute_percentage_error: 18944458.0000 - val_root_mean_squared_error: 0.2470\n",
      "Epoch 228/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0356 - mean_absolute_percentage_error: 7231026.5000 - root_mean_squared_error: 0.1888 - val_loss: 0.0612 - val_mean_absolute_percentage_error: 18932452.0000 - val_root_mean_squared_error: 0.2474\n",
      "Epoch 229/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0380 - mean_absolute_percentage_error: 8513260.0000 - root_mean_squared_error: 0.1950 - val_loss: 0.0608 - val_mean_absolute_percentage_error: 18353034.0000 - val_root_mean_squared_error: 0.2467\n",
      "Epoch 230/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0356 - mean_absolute_percentage_error: 7914429.5000 - root_mean_squared_error: 0.1886 - val_loss: 0.0606 - val_mean_absolute_percentage_error: 18968788.0000 - val_root_mean_squared_error: 0.2462\n",
      "Epoch 231/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0354 - mean_absolute_percentage_error: 7048729.0000 - root_mean_squared_error: 0.1882 - val_loss: 0.0605 - val_mean_absolute_percentage_error: 20383024.0000 - val_root_mean_squared_error: 0.2460\n",
      "Epoch 232/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0355 - mean_absolute_percentage_error: 7221152.0000 - root_mean_squared_error: 0.1884 - val_loss: 0.0593 - val_mean_absolute_percentage_error: 19487824.0000 - val_root_mean_squared_error: 0.2435\n",
      "Epoch 233/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0339 - mean_absolute_percentage_error: 7286598.5000 - root_mean_squared_error: 0.1842 - val_loss: 0.0611 - val_mean_absolute_percentage_error: 17687846.0000 - val_root_mean_squared_error: 0.2472\n",
      "Epoch 234/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0340 - mean_absolute_percentage_error: 6985664.0000 - root_mean_squared_error: 0.1843 - val_loss: 0.0618 - val_mean_absolute_percentage_error: 16814898.0000 - val_root_mean_squared_error: 0.2486\n",
      "Epoch 235/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0334 - mean_absolute_percentage_error: 6505498.5000 - root_mean_squared_error: 0.1828 - val_loss: 0.0606 - val_mean_absolute_percentage_error: 18372754.0000 - val_root_mean_squared_error: 0.2462\n",
      "Epoch 236/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0336 - mean_absolute_percentage_error: 6474081.0000 - root_mean_squared_error: 0.1833 - val_loss: 0.0606 - val_mean_absolute_percentage_error: 19549024.0000 - val_root_mean_squared_error: 0.2463\n",
      "Epoch 237/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0326 - mean_absolute_percentage_error: 6339635.0000 - root_mean_squared_error: 0.1805 - val_loss: 0.0602 - val_mean_absolute_percentage_error: 18219234.0000 - val_root_mean_squared_error: 0.2454\n",
      "Epoch 238/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0312 - mean_absolute_percentage_error: 5894515.0000 - root_mean_squared_error: 0.1766 - val_loss: 0.0618 - val_mean_absolute_percentage_error: 17097234.0000 - val_root_mean_squared_error: 0.2487\n",
      "Epoch 239/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0319 - mean_absolute_percentage_error: 5727928.0000 - root_mean_squared_error: 0.1786 - val_loss: 0.0602 - val_mean_absolute_percentage_error: 17972100.0000 - val_root_mean_squared_error: 0.2454\n",
      "Epoch 240/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0311 - mean_absolute_percentage_error: 5762083.0000 - root_mean_squared_error: 0.1764 - val_loss: 0.0609 - val_mean_absolute_percentage_error: 18562982.0000 - val_root_mean_squared_error: 0.2467\n",
      "Epoch 241/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step - loss: 0.0312 - mean_absolute_percentage_error: 5913462.5000 - root_mean_squared_error: 0.1765 - val_loss: 0.0611 - val_mean_absolute_percentage_error: 17582306.0000 - val_root_mean_squared_error: 0.2471\n",
      "Epoch 242/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0314 - mean_absolute_percentage_error: 5723411.0000 - root_mean_squared_error: 0.1772 - val_loss: 0.0618 - val_mean_absolute_percentage_error: 17056004.0000 - val_root_mean_squared_error: 0.2486\n",
      "Epoch 243/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0310 - mean_absolute_percentage_error: 5843428.0000 - root_mean_squared_error: 0.1760 - val_loss: 0.0611 - val_mean_absolute_percentage_error: 17434814.0000 - val_root_mean_squared_error: 0.2473\n",
      "Epoch 244/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0308 - mean_absolute_percentage_error: 5883899.0000 - root_mean_squared_error: 0.1755 - val_loss: 0.0611 - val_mean_absolute_percentage_error: 17635480.0000 - val_root_mean_squared_error: 0.2472\n",
      "Epoch 245/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0303 - mean_absolute_percentage_error: 5777703.0000 - root_mean_squared_error: 0.1741 - val_loss: 0.0610 - val_mean_absolute_percentage_error: 17579568.0000 - val_root_mean_squared_error: 0.2471\n",
      "Epoch 246/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0305 - mean_absolute_percentage_error: 5482096.0000 - root_mean_squared_error: 0.1746 - val_loss: 0.0607 - val_mean_absolute_percentage_error: 17955522.0000 - val_root_mean_squared_error: 0.2465\n",
      "Epoch 247/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0307 - mean_absolute_percentage_error: 5449148.0000 - root_mean_squared_error: 0.1751 - val_loss: 0.0605 - val_mean_absolute_percentage_error: 18466190.0000 - val_root_mean_squared_error: 0.2460\n",
      "Epoch 248/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0304 - mean_absolute_percentage_error: 5515763.0000 - root_mean_squared_error: 0.1743 - val_loss: 0.0606 - val_mean_absolute_percentage_error: 18035596.0000 - val_root_mean_squared_error: 0.2462\n",
      "Epoch 249/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0294 - mean_absolute_percentage_error: 5369511.5000 - root_mean_squared_error: 0.1716 - val_loss: 0.0613 - val_mean_absolute_percentage_error: 17165518.0000 - val_root_mean_squared_error: 0.2475\n",
      "Epoch 250/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0297 - mean_absolute_percentage_error: 5315060.0000 - root_mean_squared_error: 0.1724 - val_loss: 0.0609 - val_mean_absolute_percentage_error: 16998360.0000 - val_root_mean_squared_error: 0.2468\n",
      "Epoch 251/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0303 - mean_absolute_percentage_error: 5394090.5000 - root_mean_squared_error: 0.1741 - val_loss: 0.0606 - val_mean_absolute_percentage_error: 17423332.0000 - val_root_mean_squared_error: 0.2462\n",
      "Epoch 252/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0300 - mean_absolute_percentage_error: 5331597.0000 - root_mean_squared_error: 0.1732 - val_loss: 0.0602 - val_mean_absolute_percentage_error: 17844158.0000 - val_root_mean_squared_error: 0.2454\n",
      "Epoch 253/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0299 - mean_absolute_percentage_error: 5037640.5000 - root_mean_squared_error: 0.1729 - val_loss: 0.0604 - val_mean_absolute_percentage_error: 17724840.0000 - val_root_mean_squared_error: 0.2457\n",
      "Epoch 254/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0294 - mean_absolute_percentage_error: 4898232.5000 - root_mean_squared_error: 0.1713 - val_loss: 0.0606 - val_mean_absolute_percentage_error: 17492768.0000 - val_root_mean_squared_error: 0.2462\n",
      "Epoch 255/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0300 - mean_absolute_percentage_error: 4977222.5000 - root_mean_squared_error: 0.1731 - val_loss: 0.0612 - val_mean_absolute_percentage_error: 17187138.0000 - val_root_mean_squared_error: 0.2473\n",
      "Epoch 256/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0291 - mean_absolute_percentage_error: 5226408.5000 - root_mean_squared_error: 0.1705 - val_loss: 0.0612 - val_mean_absolute_percentage_error: 16898330.0000 - val_root_mean_squared_error: 0.2474\n",
      "Epoch 257/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0289 - mean_absolute_percentage_error: 5004713.0000 - root_mean_squared_error: 0.1700 - val_loss: 0.0612 - val_mean_absolute_percentage_error: 17062666.0000 - val_root_mean_squared_error: 0.2474\n",
      "Epoch 258/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0291 - mean_absolute_percentage_error: 4829646.0000 - root_mean_squared_error: 0.1705 - val_loss: 0.0606 - val_mean_absolute_percentage_error: 17447368.0000 - val_root_mean_squared_error: 0.2461\n",
      "Epoch 259/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0289 - mean_absolute_percentage_error: 5036713.0000 - root_mean_squared_error: 0.1700 - val_loss: 0.0614 - val_mean_absolute_percentage_error: 16941774.0000 - val_root_mean_squared_error: 0.2477\n",
      "Epoch 260/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0290 - mean_absolute_percentage_error: 4830773.5000 - root_mean_squared_error: 0.1703 - val_loss: 0.0605 - val_mean_absolute_percentage_error: 17211362.0000 - val_root_mean_squared_error: 0.2460\n",
      "Epoch 261/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0287 - mean_absolute_percentage_error: 4855849.0000 - root_mean_squared_error: 0.1694 - val_loss: 0.0614 - val_mean_absolute_percentage_error: 16781244.0000 - val_root_mean_squared_error: 0.2478\n",
      "Epoch 262/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0284 - mean_absolute_percentage_error: 4570235.0000 - root_mean_squared_error: 0.1684 - val_loss: 0.0601 - val_mean_absolute_percentage_error: 17996494.0000 - val_root_mean_squared_error: 0.2451\n",
      "Epoch 263/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0280 - mean_absolute_percentage_error: 4960000.0000 - root_mean_squared_error: 0.1673 - val_loss: 0.0628 - val_mean_absolute_percentage_error: 16496021.0000 - val_root_mean_squared_error: 0.2505\n",
      "Epoch 264/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0289 - mean_absolute_percentage_error: 4559211.5000 - root_mean_squared_error: 0.1701 - val_loss: 0.0610 - val_mean_absolute_percentage_error: 18072050.0000 - val_root_mean_squared_error: 0.2470\n",
      "Epoch 265/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0294 - mean_absolute_percentage_error: 5215335.0000 - root_mean_squared_error: 0.1714 - val_loss: 0.0661 - val_mean_absolute_percentage_error: 15410576.0000 - val_root_mean_squared_error: 0.2572\n",
      "Epoch 266/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0287 - mean_absolute_percentage_error: 4409236.0000 - root_mean_squared_error: 0.1696 - val_loss: 0.0609 - val_mean_absolute_percentage_error: 18815970.0000 - val_root_mean_squared_error: 0.2467\n",
      "Epoch 267/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0287 - mean_absolute_percentage_error: 4939045.5000 - root_mean_squared_error: 0.1695 - val_loss: 0.0612 - val_mean_absolute_percentage_error: 17209134.0000 - val_root_mean_squared_error: 0.2473\n",
      "Epoch 268/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0265 - mean_absolute_percentage_error: 4231315.0000 - root_mean_squared_error: 0.1628 - val_loss: 0.0608 - val_mean_absolute_percentage_error: 17340064.0000 - val_root_mean_squared_error: 0.2466\n",
      "Epoch 269/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0257 - mean_absolute_percentage_error: 4073289.5000 - root_mean_squared_error: 0.1605 - val_loss: 0.0604 - val_mean_absolute_percentage_error: 18813776.0000 - val_root_mean_squared_error: 0.2458\n",
      "Epoch 270/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0268 - mean_absolute_percentage_error: 4268866.5000 - root_mean_squared_error: 0.1639 - val_loss: 0.0609 - val_mean_absolute_percentage_error: 17080070.0000 - val_root_mean_squared_error: 0.2468\n",
      "Epoch 271/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step - loss: 0.0249 - mean_absolute_percentage_error: 3785695.2500 - root_mean_squared_error: 0.1577 - val_loss: 0.0624 - val_mean_absolute_percentage_error: 16941966.0000 - val_root_mean_squared_error: 0.2498\n",
      "Epoch 272/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0257 - mean_absolute_percentage_error: 3798080.5000 - root_mean_squared_error: 0.1603 - val_loss: 0.0608 - val_mean_absolute_percentage_error: 19324556.0000 - val_root_mean_squared_error: 0.2465\n",
      "Epoch 273/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0259 - mean_absolute_percentage_error: 3842794.0000 - root_mean_squared_error: 0.1608 - val_loss: 0.0602 - val_mean_absolute_percentage_error: 17726354.0000 - val_root_mean_squared_error: 0.2453\n",
      "Epoch 274/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0247 - mean_absolute_percentage_error: 3409622.7500 - root_mean_squared_error: 0.1571 - val_loss: 0.0644 - val_mean_absolute_percentage_error: 16119701.0000 - val_root_mean_squared_error: 0.2538\n",
      "Epoch 275/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0250 - mean_absolute_percentage_error: 3251261.5000 - root_mean_squared_error: 0.1581 - val_loss: 0.0596 - val_mean_absolute_percentage_error: 18484836.0000 - val_root_mean_squared_error: 0.2442\n",
      "Epoch 276/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0244 - mean_absolute_percentage_error: 3256707.5000 - root_mean_squared_error: 0.1562 - val_loss: 0.0602 - val_mean_absolute_percentage_error: 19295994.0000 - val_root_mean_squared_error: 0.2454\n",
      "Epoch 277/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0240 - mean_absolute_percentage_error: 3317134.7500 - root_mean_squared_error: 0.1550 - val_loss: 0.0619 - val_mean_absolute_percentage_error: 16906952.0000 - val_root_mean_squared_error: 0.2487\n",
      "Epoch 278/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0245 - mean_absolute_percentage_error: 3053204.7500 - root_mean_squared_error: 0.1565 - val_loss: 0.0615 - val_mean_absolute_percentage_error: 17040550.0000 - val_root_mean_squared_error: 0.2480\n",
      "Epoch 279/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0237 - mean_absolute_percentage_error: 2936401.5000 - root_mean_squared_error: 0.1540 - val_loss: 0.0595 - val_mean_absolute_percentage_error: 19072478.0000 - val_root_mean_squared_error: 0.2438\n",
      "Epoch 280/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0242 - mean_absolute_percentage_error: 3112513.2500 - root_mean_squared_error: 0.1556 - val_loss: 0.0594 - val_mean_absolute_percentage_error: 18403042.0000 - val_root_mean_squared_error: 0.2436\n",
      "Epoch 281/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0235 - mean_absolute_percentage_error: 3014928.5000 - root_mean_squared_error: 0.1532 - val_loss: 0.0626 - val_mean_absolute_percentage_error: 16877214.0000 - val_root_mean_squared_error: 0.2501\n",
      "Epoch 282/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0236 - mean_absolute_percentage_error: 2898026.0000 - root_mean_squared_error: 0.1538 - val_loss: 0.0598 - val_mean_absolute_percentage_error: 18278168.0000 - val_root_mean_squared_error: 0.2445\n",
      "Epoch 283/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0238 - mean_absolute_percentage_error: 2978760.0000 - root_mean_squared_error: 0.1544 - val_loss: 0.0597 - val_mean_absolute_percentage_error: 19340340.0000 - val_root_mean_squared_error: 0.2444\n",
      "Epoch 284/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0230 - mean_absolute_percentage_error: 3114338.0000 - root_mean_squared_error: 0.1515 - val_loss: 0.0621 - val_mean_absolute_percentage_error: 17983280.0000 - val_root_mean_squared_error: 0.2492\n",
      "Epoch 285/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0233 - mean_absolute_percentage_error: 3049758.0000 - root_mean_squared_error: 0.1528 - val_loss: 0.0606 - val_mean_absolute_percentage_error: 18283582.0000 - val_root_mean_squared_error: 0.2461\n",
      "Epoch 286/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0230 - mean_absolute_percentage_error: 2757683.5000 - root_mean_squared_error: 0.1515 - val_loss: 0.0602 - val_mean_absolute_percentage_error: 18678858.0000 - val_root_mean_squared_error: 0.2454\n",
      "Epoch 287/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0229 - mean_absolute_percentage_error: 2797843.5000 - root_mean_squared_error: 0.1514 - val_loss: 0.0626 - val_mean_absolute_percentage_error: 18018030.0000 - val_root_mean_squared_error: 0.2502\n",
      "Epoch 288/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0228 - mean_absolute_percentage_error: 2762161.2500 - root_mean_squared_error: 0.1510 - val_loss: 0.0625 - val_mean_absolute_percentage_error: 17968538.0000 - val_root_mean_squared_error: 0.2499\n",
      "Epoch 289/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0219 - mean_absolute_percentage_error: 2621758.0000 - root_mean_squared_error: 0.1479 - val_loss: 0.0614 - val_mean_absolute_percentage_error: 18674018.0000 - val_root_mean_squared_error: 0.2479\n",
      "Epoch 290/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0224 - mean_absolute_percentage_error: 2670111.7500 - root_mean_squared_error: 0.1498 - val_loss: 0.0632 - val_mean_absolute_percentage_error: 18694512.0000 - val_root_mean_squared_error: 0.2513\n",
      "Epoch 291/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0222 - mean_absolute_percentage_error: 2813671.5000 - root_mean_squared_error: 0.1492 - val_loss: 0.0639 - val_mean_absolute_percentage_error: 18487122.0000 - val_root_mean_squared_error: 0.2529\n",
      "Epoch 292/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0222 - mean_absolute_percentage_error: 2736588.5000 - root_mean_squared_error: 0.1488 - val_loss: 0.0627 - val_mean_absolute_percentage_error: 18696582.0000 - val_root_mean_squared_error: 0.2503\n",
      "Epoch 293/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0218 - mean_absolute_percentage_error: 2570168.0000 - root_mean_squared_error: 0.1477 - val_loss: 0.0643 - val_mean_absolute_percentage_error: 18700686.0000 - val_root_mean_squared_error: 0.2535\n",
      "Epoch 294/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0211 - mean_absolute_percentage_error: 2669211.0000 - root_mean_squared_error: 0.1452 - val_loss: 0.0657 - val_mean_absolute_percentage_error: 18748586.0000 - val_root_mean_squared_error: 0.2563\n",
      "Epoch 295/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0217 - mean_absolute_percentage_error: 2622574.7500 - root_mean_squared_error: 0.1472 - val_loss: 0.0633 - val_mean_absolute_percentage_error: 19114916.0000 - val_root_mean_squared_error: 0.2516\n",
      "Epoch 296/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0209 - mean_absolute_percentage_error: 2529080.7500 - root_mean_squared_error: 0.1446 - val_loss: 0.0674 - val_mean_absolute_percentage_error: 18865258.0000 - val_root_mean_squared_error: 0.2596\n",
      "Epoch 297/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0211 - mean_absolute_percentage_error: 2546630.5000 - root_mean_squared_error: 0.1451 - val_loss: 0.0653 - val_mean_absolute_percentage_error: 19413482.0000 - val_root_mean_squared_error: 0.2555\n",
      "Epoch 298/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0209 - mean_absolute_percentage_error: 2499344.0000 - root_mean_squared_error: 0.1445 - val_loss: 0.0661 - val_mean_absolute_percentage_error: 18948592.0000 - val_root_mean_squared_error: 0.2572\n",
      "Epoch 299/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0208 - mean_absolute_percentage_error: 2381115.7500 - root_mean_squared_error: 0.1441 - val_loss: 0.0681 - val_mean_absolute_percentage_error: 19113732.0000 - val_root_mean_squared_error: 0.2610\n",
      "Epoch 300/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0202 - mean_absolute_percentage_error: 2397448.7500 - root_mean_squared_error: 0.1423 - val_loss: 0.0660 - val_mean_absolute_percentage_error: 20186274.0000 - val_root_mean_squared_error: 0.2568\n",
      "Epoch 301/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step - loss: 0.0205 - mean_absolute_percentage_error: 2417878.7500 - root_mean_squared_error: 0.1433 - val_loss: 0.0698 - val_mean_absolute_percentage_error: 19555382.0000 - val_root_mean_squared_error: 0.2642\n",
      "Epoch 302/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0196 - mean_absolute_percentage_error: 2383701.2500 - root_mean_squared_error: 0.1402 - val_loss: 0.0659 - val_mean_absolute_percentage_error: 20225494.0000 - val_root_mean_squared_error: 0.2567\n",
      "Epoch 303/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0207 - mean_absolute_percentage_error: 2408673.2500 - root_mean_squared_error: 0.1440 - val_loss: 0.0698 - val_mean_absolute_percentage_error: 19362726.0000 - val_root_mean_squared_error: 0.2642\n",
      "Epoch 304/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0199 - mean_absolute_percentage_error: 2206326.0000 - root_mean_squared_error: 0.1410 - val_loss: 0.0686 - val_mean_absolute_percentage_error: 19917876.0000 - val_root_mean_squared_error: 0.2620\n",
      "Epoch 305/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0198 - mean_absolute_percentage_error: 2213915.5000 - root_mean_squared_error: 0.1407 - val_loss: 0.0683 - val_mean_absolute_percentage_error: 20666352.0000 - val_root_mean_squared_error: 0.2613\n",
      "Epoch 306/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0194 - mean_absolute_percentage_error: 2243223.2500 - root_mean_squared_error: 0.1394 - val_loss: 0.0706 - val_mean_absolute_percentage_error: 19770984.0000 - val_root_mean_squared_error: 0.2658\n",
      "Epoch 307/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0195 - mean_absolute_percentage_error: 2135379.7500 - root_mean_squared_error: 0.1398 - val_loss: 0.0681 - val_mean_absolute_percentage_error: 20214074.0000 - val_root_mean_squared_error: 0.2609\n",
      "Epoch 308/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0191 - mean_absolute_percentage_error: 2098196.0000 - root_mean_squared_error: 0.1382 - val_loss: 0.0707 - val_mean_absolute_percentage_error: 20224842.0000 - val_root_mean_squared_error: 0.2658\n",
      "Epoch 309/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0186 - mean_absolute_percentage_error: 2044386.3750 - root_mean_squared_error: 0.1362 - val_loss: 0.0714 - val_mean_absolute_percentage_error: 20285324.0000 - val_root_mean_squared_error: 0.2671\n",
      "Epoch 310/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0186 - mean_absolute_percentage_error: 1918554.0000 - root_mean_squared_error: 0.1365 - val_loss: 0.0717 - val_mean_absolute_percentage_error: 20825060.0000 - val_root_mean_squared_error: 0.2678\n",
      "Epoch 311/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0185 - mean_absolute_percentage_error: 1898953.2500 - root_mean_squared_error: 0.1361 - val_loss: 0.0722 - val_mean_absolute_percentage_error: 20729676.0000 - val_root_mean_squared_error: 0.2688\n",
      "Epoch 312/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0184 - mean_absolute_percentage_error: 1924166.7500 - root_mean_squared_error: 0.1357 - val_loss: 0.0682 - val_mean_absolute_percentage_error: 20833606.0000 - val_root_mean_squared_error: 0.2612\n",
      "Epoch 313/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0187 - mean_absolute_percentage_error: 1980421.6250 - root_mean_squared_error: 0.1367 - val_loss: 0.0758 - val_mean_absolute_percentage_error: 18781294.0000 - val_root_mean_squared_error: 0.2754\n",
      "Epoch 314/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0197 - mean_absolute_percentage_error: 1991057.6250 - root_mean_squared_error: 0.1402 - val_loss: 0.0752 - val_mean_absolute_percentage_error: 23044514.0000 - val_root_mean_squared_error: 0.2742\n",
      "Epoch 315/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0329 - mean_absolute_percentage_error: 4891800.0000 - root_mean_squared_error: 0.1813 - val_loss: 0.0998 - val_mean_absolute_percentage_error: 14181471.0000 - val_root_mean_squared_error: 0.3159\n",
      "Epoch 316/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0740 - mean_absolute_percentage_error: 6860087.0000 - root_mean_squared_error: 0.2720 - val_loss: 0.0913 - val_mean_absolute_percentage_error: 15403677.0000 - val_root_mean_squared_error: 0.3022\n",
      "Epoch 317/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0558 - mean_absolute_percentage_error: 5306749.0000 - root_mean_squared_error: 0.2363 - val_loss: 0.0703 - val_mean_absolute_percentage_error: 18458992.0000 - val_root_mean_squared_error: 0.2651\n",
      "Epoch 318/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0421 - mean_absolute_percentage_error: 7295799.0000 - root_mean_squared_error: 0.2053 - val_loss: 0.0688 - val_mean_absolute_percentage_error: 20206736.0000 - val_root_mean_squared_error: 0.2624\n",
      "Epoch 319/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0472 - mean_absolute_percentage_error: 8876989.0000 - root_mean_squared_error: 0.2173 - val_loss: 0.0661 - val_mean_absolute_percentage_error: 18328744.0000 - val_root_mean_squared_error: 0.2571\n",
      "Epoch 320/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0423 - mean_absolute_percentage_error: 7241737.0000 - root_mean_squared_error: 0.2057 - val_loss: 0.0623 - val_mean_absolute_percentage_error: 18229022.0000 - val_root_mean_squared_error: 0.2495\n",
      "Epoch 321/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0378 - mean_absolute_percentage_error: 8125125.0000 - root_mean_squared_error: 0.1945 - val_loss: 0.0607 - val_mean_absolute_percentage_error: 21331328.0000 - val_root_mean_squared_error: 0.2463\n",
      "Epoch 322/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0400 - mean_absolute_percentage_error: 10363193.0000 - root_mean_squared_error: 0.2000 - val_loss: 0.0617 - val_mean_absolute_percentage_error: 22178044.0000 - val_root_mean_squared_error: 0.2483\n",
      "Epoch 323/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0347 - mean_absolute_percentage_error: 8903906.0000 - root_mean_squared_error: 0.1862 - val_loss: 0.0666 - val_mean_absolute_percentage_error: 23081392.0000 - val_root_mean_squared_error: 0.2580\n",
      "Epoch 324/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0355 - mean_absolute_percentage_error: 7157021.5000 - root_mean_squared_error: 0.1884 - val_loss: 0.0672 - val_mean_absolute_percentage_error: 23168418.0000 - val_root_mean_squared_error: 0.2592\n",
      "Epoch 325/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0352 - mean_absolute_percentage_error: 6732984.0000 - root_mean_squared_error: 0.1875 - val_loss: 0.0629 - val_mean_absolute_percentage_error: 21750674.0000 - val_root_mean_squared_error: 0.2509\n",
      "Epoch 326/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0318 - mean_absolute_percentage_error: 6926534.5000 - root_mean_squared_error: 0.1782 - val_loss: 0.0618 - val_mean_absolute_percentage_error: 20918054.0000 - val_root_mean_squared_error: 0.2486\n",
      "Epoch 327/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0320 - mean_absolute_percentage_error: 7007177.0000 - root_mean_squared_error: 0.1788 - val_loss: 0.0603 - val_mean_absolute_percentage_error: 19705058.0000 - val_root_mean_squared_error: 0.2455\n",
      "Epoch 328/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0294 - mean_absolute_percentage_error: 6132017.0000 - root_mean_squared_error: 0.1715 - val_loss: 0.0605 - val_mean_absolute_percentage_error: 19617334.0000 - val_root_mean_squared_error: 0.2459\n",
      "Epoch 329/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0301 - mean_absolute_percentage_error: 5694331.0000 - root_mean_squared_error: 0.1735 - val_loss: 0.0618 - val_mean_absolute_percentage_error: 20131946.0000 - val_root_mean_squared_error: 0.2485\n",
      "Epoch 330/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0285 - mean_absolute_percentage_error: 5260250.0000 - root_mean_squared_error: 0.1688 - val_loss: 0.0614 - val_mean_absolute_percentage_error: 18304566.0000 - val_root_mean_squared_error: 0.2478\n",
      "Epoch 331/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step - loss: 0.0273 - mean_absolute_percentage_error: 4746061.0000 - root_mean_squared_error: 0.1652 - val_loss: 0.0637 - val_mean_absolute_percentage_error: 17048392.0000 - val_root_mean_squared_error: 0.2524\n",
      "Epoch 332/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0273 - mean_absolute_percentage_error: 4451963.5000 - root_mean_squared_error: 0.1651 - val_loss: 0.0631 - val_mean_absolute_percentage_error: 18176256.0000 - val_root_mean_squared_error: 0.2512\n",
      "Epoch 333/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0261 - mean_absolute_percentage_error: 4591280.0000 - root_mean_squared_error: 0.1615 - val_loss: 0.0635 - val_mean_absolute_percentage_error: 19557170.0000 - val_root_mean_squared_error: 0.2519\n",
      "Epoch 334/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0251 - mean_absolute_percentage_error: 4690218.5000 - root_mean_squared_error: 0.1584 - val_loss: 0.0643 - val_mean_absolute_percentage_error: 19216318.0000 - val_root_mean_squared_error: 0.2535\n",
      "Epoch 335/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0240 - mean_absolute_percentage_error: 3976746.5000 - root_mean_squared_error: 0.1550 - val_loss: 0.0649 - val_mean_absolute_percentage_error: 19337418.0000 - val_root_mean_squared_error: 0.2548\n",
      "Epoch 336/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0226 - mean_absolute_percentage_error: 3544613.5000 - root_mean_squared_error: 0.1504 - val_loss: 0.0648 - val_mean_absolute_percentage_error: 20336866.0000 - val_root_mean_squared_error: 0.2546\n",
      "Epoch 337/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0225 - mean_absolute_percentage_error: 3617354.7500 - root_mean_squared_error: 0.1500 - val_loss: 0.0646 - val_mean_absolute_percentage_error: 20257550.0000 - val_root_mean_squared_error: 0.2541\n",
      "Epoch 338/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0223 - mean_absolute_percentage_error: 3389432.0000 - root_mean_squared_error: 0.1492 - val_loss: 0.0653 - val_mean_absolute_percentage_error: 19981078.0000 - val_root_mean_squared_error: 0.2555\n",
      "Epoch 339/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0217 - mean_absolute_percentage_error: 3217152.5000 - root_mean_squared_error: 0.1475 - val_loss: 0.0652 - val_mean_absolute_percentage_error: 20532238.0000 - val_root_mean_squared_error: 0.2553\n",
      "Epoch 340/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0217 - mean_absolute_percentage_error: 3139157.5000 - root_mean_squared_error: 0.1472 - val_loss: 0.0640 - val_mean_absolute_percentage_error: 20593870.0000 - val_root_mean_squared_error: 0.2529\n",
      "Epoch 341/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0208 - mean_absolute_percentage_error: 3012078.7500 - root_mean_squared_error: 0.1441 - val_loss: 0.0649 - val_mean_absolute_percentage_error: 20404160.0000 - val_root_mean_squared_error: 0.2548\n",
      "Epoch 342/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0209 - mean_absolute_percentage_error: 2813717.5000 - root_mean_squared_error: 0.1447 - val_loss: 0.0652 - val_mean_absolute_percentage_error: 20482726.0000 - val_root_mean_squared_error: 0.2553\n",
      "Epoch 343/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0199 - mean_absolute_percentage_error: 2763294.5000 - root_mean_squared_error: 0.1412 - val_loss: 0.0651 - val_mean_absolute_percentage_error: 20813050.0000 - val_root_mean_squared_error: 0.2552\n",
      "Epoch 344/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0207 - mean_absolute_percentage_error: 2778910.2500 - root_mean_squared_error: 0.1438 - val_loss: 0.0670 - val_mean_absolute_percentage_error: 20833734.0000 - val_root_mean_squared_error: 0.2588\n",
      "Epoch 345/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0202 - mean_absolute_percentage_error: 2827741.5000 - root_mean_squared_error: 0.1422 - val_loss: 0.0675 - val_mean_absolute_percentage_error: 20581126.0000 - val_root_mean_squared_error: 0.2598\n",
      "Epoch 346/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0194 - mean_absolute_percentage_error: 2831022.5000 - root_mean_squared_error: 0.1392 - val_loss: 0.0672 - val_mean_absolute_percentage_error: 21078218.0000 - val_root_mean_squared_error: 0.2592\n",
      "Epoch 347/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0200 - mean_absolute_percentage_error: 2769549.5000 - root_mean_squared_error: 0.1416 - val_loss: 0.0672 - val_mean_absolute_percentage_error: 21115532.0000 - val_root_mean_squared_error: 0.2593\n",
      "Epoch 348/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0194 - mean_absolute_percentage_error: 2640319.5000 - root_mean_squared_error: 0.1394 - val_loss: 0.0673 - val_mean_absolute_percentage_error: 20802134.0000 - val_root_mean_squared_error: 0.2594\n",
      "Epoch 349/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0192 - mean_absolute_percentage_error: 2444039.5000 - root_mean_squared_error: 0.1386 - val_loss: 0.0669 - val_mean_absolute_percentage_error: 20914972.0000 - val_root_mean_squared_error: 0.2586\n",
      "Epoch 350/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0194 - mean_absolute_percentage_error: 2379960.2500 - root_mean_squared_error: 0.1391 - val_loss: 0.0677 - val_mean_absolute_percentage_error: 21013206.0000 - val_root_mean_squared_error: 0.2601\n",
      "Epoch 351/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0191 - mean_absolute_percentage_error: 2348544.5000 - root_mean_squared_error: 0.1381 - val_loss: 0.0679 - val_mean_absolute_percentage_error: 20913882.0000 - val_root_mean_squared_error: 0.2607\n",
      "Epoch 352/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0190 - mean_absolute_percentage_error: 2293373.0000 - root_mean_squared_error: 0.1379 - val_loss: 0.0680 - val_mean_absolute_percentage_error: 21113458.0000 - val_root_mean_squared_error: 0.2609\n",
      "Epoch 353/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0189 - mean_absolute_percentage_error: 2267451.2500 - root_mean_squared_error: 0.1376 - val_loss: 0.0700 - val_mean_absolute_percentage_error: 21561976.0000 - val_root_mean_squared_error: 0.2645\n",
      "Epoch 354/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0192 - mean_absolute_percentage_error: 2269962.7500 - root_mean_squared_error: 0.1386 - val_loss: 0.0686 - val_mean_absolute_percentage_error: 21601000.0000 - val_root_mean_squared_error: 0.2620\n",
      "Epoch 355/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0186 - mean_absolute_percentage_error: 2178966.5000 - root_mean_squared_error: 0.1364 - val_loss: 0.0707 - val_mean_absolute_percentage_error: 21716870.0000 - val_root_mean_squared_error: 0.2660\n",
      "Epoch 356/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0177 - mean_absolute_percentage_error: 2102594.2500 - root_mean_squared_error: 0.1332 - val_loss: 0.0704 - val_mean_absolute_percentage_error: 21974778.0000 - val_root_mean_squared_error: 0.2654\n",
      "Epoch 357/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0184 - mean_absolute_percentage_error: 2015528.3750 - root_mean_squared_error: 0.1358 - val_loss: 0.0700 - val_mean_absolute_percentage_error: 21781460.0000 - val_root_mean_squared_error: 0.2645\n",
      "Epoch 358/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0179 - mean_absolute_percentage_error: 1913674.3750 - root_mean_squared_error: 0.1338 - val_loss: 0.0701 - val_mean_absolute_percentage_error: 21638352.0000 - val_root_mean_squared_error: 0.2647\n",
      "Epoch 359/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0182 - mean_absolute_percentage_error: 1869467.3750 - root_mean_squared_error: 0.1347 - val_loss: 0.0702 - val_mean_absolute_percentage_error: 21767286.0000 - val_root_mean_squared_error: 0.2650\n",
      "Epoch 360/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0178 - mean_absolute_percentage_error: 1833592.6250 - root_mean_squared_error: 0.1333 - val_loss: 0.0697 - val_mean_absolute_percentage_error: 21922206.0000 - val_root_mean_squared_error: 0.2641\n",
      "Epoch 361/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step - loss: 0.0177 - mean_absolute_percentage_error: 1758402.0000 - root_mean_squared_error: 0.1329 - val_loss: 0.0702 - val_mean_absolute_percentage_error: 22105280.0000 - val_root_mean_squared_error: 0.2650\n",
      "Epoch 362/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0169 - mean_absolute_percentage_error: 1687183.2500 - root_mean_squared_error: 0.1301 - val_loss: 0.0703 - val_mean_absolute_percentage_error: 22038206.0000 - val_root_mean_squared_error: 0.2652\n",
      "Epoch 363/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0168 - mean_absolute_percentage_error: 1636499.2500 - root_mean_squared_error: 0.1296 - val_loss: 0.0703 - val_mean_absolute_percentage_error: 21989118.0000 - val_root_mean_squared_error: 0.2652\n",
      "Epoch 364/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0167 - mean_absolute_percentage_error: 1517097.2500 - root_mean_squared_error: 0.1293 - val_loss: 0.0704 - val_mean_absolute_percentage_error: 22341822.0000 - val_root_mean_squared_error: 0.2653\n",
      "Epoch 365/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0168 - mean_absolute_percentage_error: 1464912.3750 - root_mean_squared_error: 0.1295 - val_loss: 0.0705 - val_mean_absolute_percentage_error: 22518888.0000 - val_root_mean_squared_error: 0.2656\n",
      "Epoch 366/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0168 - mean_absolute_percentage_error: 1358982.5000 - root_mean_squared_error: 0.1296 - val_loss: 0.0710 - val_mean_absolute_percentage_error: 22231030.0000 - val_root_mean_squared_error: 0.2665\n",
      "Epoch 367/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0162 - mean_absolute_percentage_error: 1306539.6250 - root_mean_squared_error: 0.1272 - val_loss: 0.0714 - val_mean_absolute_percentage_error: 22607370.0000 - val_root_mean_squared_error: 0.2672\n",
      "Epoch 368/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0164 - mean_absolute_percentage_error: 1217546.8750 - root_mean_squared_error: 0.1281 - val_loss: 0.0714 - val_mean_absolute_percentage_error: 22915306.0000 - val_root_mean_squared_error: 0.2672\n",
      "Epoch 369/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0163 - mean_absolute_percentage_error: 1219517.2500 - root_mean_squared_error: 0.1277 - val_loss: 0.0718 - val_mean_absolute_percentage_error: 22891398.0000 - val_root_mean_squared_error: 0.2680\n",
      "Epoch 370/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0158 - mean_absolute_percentage_error: 1180653.2500 - root_mean_squared_error: 0.1256 - val_loss: 0.0713 - val_mean_absolute_percentage_error: 22071240.0000 - val_root_mean_squared_error: 0.2670\n",
      "Epoch 371/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0161 - mean_absolute_percentage_error: 1217389.2500 - root_mean_squared_error: 0.1270 - val_loss: 0.0727 - val_mean_absolute_percentage_error: 23312210.0000 - val_root_mean_squared_error: 0.2695\n",
      "Epoch 372/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0171 - mean_absolute_percentage_error: 1237596.2500 - root_mean_squared_error: 0.1307 - val_loss: 0.0724 - val_mean_absolute_percentage_error: 22033528.0000 - val_root_mean_squared_error: 0.2690\n",
      "Epoch 373/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0163 - mean_absolute_percentage_error: 1248547.5000 - root_mean_squared_error: 0.1276 - val_loss: 0.0730 - val_mean_absolute_percentage_error: 22868816.0000 - val_root_mean_squared_error: 0.2701\n",
      "Epoch 374/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0158 - mean_absolute_percentage_error: 1058385.2500 - root_mean_squared_error: 0.1256 - val_loss: 0.0725 - val_mean_absolute_percentage_error: 23254166.0000 - val_root_mean_squared_error: 0.2693\n",
      "Epoch 375/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0155 - mean_absolute_percentage_error: 1136019.2500 - root_mean_squared_error: 0.1243 - val_loss: 0.0722 - val_mean_absolute_percentage_error: 22228592.0000 - val_root_mean_squared_error: 0.2687\n",
      "Epoch 376/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0154 - mean_absolute_percentage_error: 1057572.2500 - root_mean_squared_error: 0.1242 - val_loss: 0.0730 - val_mean_absolute_percentage_error: 22299030.0000 - val_root_mean_squared_error: 0.2703\n",
      "Epoch 377/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0151 - mean_absolute_percentage_error: 1031365.5000 - root_mean_squared_error: 0.1229 - val_loss: 0.0730 - val_mean_absolute_percentage_error: 23015192.0000 - val_root_mean_squared_error: 0.2702\n",
      "Epoch 378/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0153 - mean_absolute_percentage_error: 989969.0000 - root_mean_squared_error: 0.1237 - val_loss: 0.0726 - val_mean_absolute_percentage_error: 22565768.0000 - val_root_mean_squared_error: 0.2694\n",
      "Epoch 379/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0154 - mean_absolute_percentage_error: 1029505.6875 - root_mean_squared_error: 0.1240 - val_loss: 0.0735 - val_mean_absolute_percentage_error: 22318822.0000 - val_root_mean_squared_error: 0.2711\n",
      "Epoch 380/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0151 - mean_absolute_percentage_error: 924720.3750 - root_mean_squared_error: 0.1231 - val_loss: 0.0744 - val_mean_absolute_percentage_error: 23178226.0000 - val_root_mean_squared_error: 0.2728\n",
      "Epoch 381/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0151 - mean_absolute_percentage_error: 873872.1250 - root_mean_squared_error: 0.1229 - val_loss: 0.0734 - val_mean_absolute_percentage_error: 22678152.0000 - val_root_mean_squared_error: 0.2710\n",
      "Epoch 382/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0149 - mean_absolute_percentage_error: 925906.8125 - root_mean_squared_error: 0.1221 - val_loss: 0.0762 - val_mean_absolute_percentage_error: 23183398.0000 - val_root_mean_squared_error: 0.2760\n",
      "Epoch 383/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0151 - mean_absolute_percentage_error: 815982.8750 - root_mean_squared_error: 0.1229 - val_loss: 0.0740 - val_mean_absolute_percentage_error: 22642120.0000 - val_root_mean_squared_error: 0.2720\n",
      "Epoch 384/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0145 - mean_absolute_percentage_error: 798552.3125 - root_mean_squared_error: 0.1204 - val_loss: 0.0740 - val_mean_absolute_percentage_error: 22895754.0000 - val_root_mean_squared_error: 0.2720\n",
      "Epoch 385/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0149 - mean_absolute_percentage_error: 820234.9375 - root_mean_squared_error: 0.1222 - val_loss: 0.0765 - val_mean_absolute_percentage_error: 23289432.0000 - val_root_mean_squared_error: 0.2766\n",
      "Epoch 386/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0145 - mean_absolute_percentage_error: 769576.6875 - root_mean_squared_error: 0.1206 - val_loss: 0.0733 - val_mean_absolute_percentage_error: 21583062.0000 - val_root_mean_squared_error: 0.2707\n",
      "Epoch 387/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0146 - mean_absolute_percentage_error: 811169.3125 - root_mean_squared_error: 0.1207 - val_loss: 0.0776 - val_mean_absolute_percentage_error: 23621834.0000 - val_root_mean_squared_error: 0.2785\n",
      "Epoch 388/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0138 - mean_absolute_percentage_error: 665465.8125 - root_mean_squared_error: 0.1175 - val_loss: 0.0797 - val_mean_absolute_percentage_error: 23865102.0000 - val_root_mean_squared_error: 0.2822\n",
      "Epoch 389/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0145 - mean_absolute_percentage_error: 657478.6250 - root_mean_squared_error: 0.1204 - val_loss: 0.0748 - val_mean_absolute_percentage_error: 22142938.0000 - val_root_mean_squared_error: 0.2735\n",
      "Epoch 390/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0139 - mean_absolute_percentage_error: 659798.2500 - root_mean_squared_error: 0.1180 - val_loss: 0.0748 - val_mean_absolute_percentage_error: 22763362.0000 - val_root_mean_squared_error: 0.2735\n",
      "Epoch 391/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step - loss: 0.0143 - mean_absolute_percentage_error: 596504.8125 - root_mean_squared_error: 0.1197 - val_loss: 0.0767 - val_mean_absolute_percentage_error: 23428286.0000 - val_root_mean_squared_error: 0.2769\n",
      "Epoch 392/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0145 - mean_absolute_percentage_error: 634228.1250 - root_mean_squared_error: 0.1205 - val_loss: 0.0760 - val_mean_absolute_percentage_error: 22831898.0000 - val_root_mean_squared_error: 0.2758\n",
      "Epoch 393/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0139 - mean_absolute_percentage_error: 501298.6875 - root_mean_squared_error: 0.1180 - val_loss: 0.0759 - val_mean_absolute_percentage_error: 22625322.0000 - val_root_mean_squared_error: 0.2756\n",
      "Epoch 394/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0139 - mean_absolute_percentage_error: 521135.5000 - root_mean_squared_error: 0.1177 - val_loss: 0.0777 - val_mean_absolute_percentage_error: 23478430.0000 - val_root_mean_squared_error: 0.2788\n",
      "Epoch 395/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0137 - mean_absolute_percentage_error: 476836.1875 - root_mean_squared_error: 0.1170 - val_loss: 0.0796 - val_mean_absolute_percentage_error: 23841424.0000 - val_root_mean_squared_error: 0.2820\n",
      "Epoch 396/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0138 - mean_absolute_percentage_error: 488498.0625 - root_mean_squared_error: 0.1176 - val_loss: 0.0762 - val_mean_absolute_percentage_error: 22828944.0000 - val_root_mean_squared_error: 0.2760\n",
      "Epoch 397/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0139 - mean_absolute_percentage_error: 432166.4062 - root_mean_squared_error: 0.1179 - val_loss: 0.0762 - val_mean_absolute_percentage_error: 22640400.0000 - val_root_mean_squared_error: 0.2760\n",
      "Epoch 398/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0131 - mean_absolute_percentage_error: 436540.0938 - root_mean_squared_error: 0.1145 - val_loss: 0.0786 - val_mean_absolute_percentage_error: 23370166.0000 - val_root_mean_squared_error: 0.2803\n",
      "Epoch 399/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0130 - mean_absolute_percentage_error: 390643.5625 - root_mean_squared_error: 0.1142 - val_loss: 0.0802 - val_mean_absolute_percentage_error: 23745920.0000 - val_root_mean_squared_error: 0.2833\n",
      "Epoch 400/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0139 - mean_absolute_percentage_error: 379351.1875 - root_mean_squared_error: 0.1180 - val_loss: 0.0789 - val_mean_absolute_percentage_error: 23243720.0000 - val_root_mean_squared_error: 0.2808\n",
      "Epoch 401/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0133 - mean_absolute_percentage_error: 347240.7188 - root_mean_squared_error: 0.1155 - val_loss: 0.0781 - val_mean_absolute_percentage_error: 23049374.0000 - val_root_mean_squared_error: 0.2795\n",
      "Epoch 402/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0139 - mean_absolute_percentage_error: 329437.0938 - root_mean_squared_error: 0.1179 - val_loss: 0.0792 - val_mean_absolute_percentage_error: 23451346.0000 - val_root_mean_squared_error: 0.2814\n",
      "Epoch 403/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0133 - mean_absolute_percentage_error: 358027.0938 - root_mean_squared_error: 0.1154 - val_loss: 0.0795 - val_mean_absolute_percentage_error: 23600424.0000 - val_root_mean_squared_error: 0.2820\n",
      "Epoch 404/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0136 - mean_absolute_percentage_error: 315720.1250 - root_mean_squared_error: 0.1166 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23256670.0000 - val_root_mean_squared_error: 0.2802\n",
      "Epoch 405/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0136 - mean_absolute_percentage_error: 319990.8750 - root_mean_squared_error: 0.1168 - val_loss: 0.0782 - val_mean_absolute_percentage_error: 23078570.0000 - val_root_mean_squared_error: 0.2797\n",
      "Epoch 406/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0139 - mean_absolute_percentage_error: 305262.0312 - root_mean_squared_error: 0.1180 - val_loss: 0.0795 - val_mean_absolute_percentage_error: 23287662.0000 - val_root_mean_squared_error: 0.2820\n",
      "Epoch 407/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0140 - mean_absolute_percentage_error: 296331.0000 - root_mean_squared_error: 0.1183 - val_loss: 0.0798 - val_mean_absolute_percentage_error: 23422040.0000 - val_root_mean_squared_error: 0.2825\n",
      "Epoch 408/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0137 - mean_absolute_percentage_error: 292538.1562 - root_mean_squared_error: 0.1170 - val_loss: 0.0782 - val_mean_absolute_percentage_error: 23192080.0000 - val_root_mean_squared_error: 0.2796\n",
      "Epoch 409/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0129 - mean_absolute_percentage_error: 267661.0000 - root_mean_squared_error: 0.1134 - val_loss: 0.0773 - val_mean_absolute_percentage_error: 22967120.0000 - val_root_mean_squared_error: 0.2780\n",
      "Epoch 410/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0137 - mean_absolute_percentage_error: 255783.5469 - root_mean_squared_error: 0.1171 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23155522.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 411/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0134 - mean_absolute_percentage_error: 227015.4688 - root_mean_squared_error: 0.1159 - val_loss: 0.0797 - val_mean_absolute_percentage_error: 23438630.0000 - val_root_mean_squared_error: 0.2823\n",
      "Epoch 412/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0134 - mean_absolute_percentage_error: 236611.5469 - root_mean_squared_error: 0.1157 - val_loss: 0.0790 - val_mean_absolute_percentage_error: 23319762.0000 - val_root_mean_squared_error: 0.2811\n",
      "Epoch 413/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0133 - mean_absolute_percentage_error: 199669.3281 - root_mean_squared_error: 0.1155 - val_loss: 0.0778 - val_mean_absolute_percentage_error: 23014162.0000 - val_root_mean_squared_error: 0.2789\n",
      "Epoch 414/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0131 - mean_absolute_percentage_error: 229896.7188 - root_mean_squared_error: 0.1144 - val_loss: 0.0779 - val_mean_absolute_percentage_error: 23026912.0000 - val_root_mean_squared_error: 0.2791\n",
      "Epoch 415/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0134 - mean_absolute_percentage_error: 186193.2812 - root_mean_squared_error: 0.1158 - val_loss: 0.0787 - val_mean_absolute_percentage_error: 23220418.0000 - val_root_mean_squared_error: 0.2805\n",
      "Epoch 416/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0135 - mean_absolute_percentage_error: 187752.0312 - root_mean_squared_error: 0.1162 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23186634.0000 - val_root_mean_squared_error: 0.2802\n",
      "Epoch 417/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0133 - mean_absolute_percentage_error: 173260.8281 - root_mean_squared_error: 0.1151 - val_loss: 0.0778 - val_mean_absolute_percentage_error: 23056378.0000 - val_root_mean_squared_error: 0.2789\n",
      "Epoch 418/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0130 - mean_absolute_percentage_error: 166403.9688 - root_mean_squared_error: 0.1142 - val_loss: 0.0779 - val_mean_absolute_percentage_error: 23138010.0000 - val_root_mean_squared_error: 0.2792\n",
      "Epoch 419/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0130 - mean_absolute_percentage_error: 180676.0938 - root_mean_squared_error: 0.1140 - val_loss: 0.0787 - val_mean_absolute_percentage_error: 23279862.0000 - val_root_mean_squared_error: 0.2806\n",
      "Epoch 420/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0138 - mean_absolute_percentage_error: 147733.5469 - root_mean_squared_error: 0.1174 - val_loss: 0.0786 - val_mean_absolute_percentage_error: 23221992.0000 - val_root_mean_squared_error: 0.2804\n",
      "Epoch 421/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step - loss: 0.0134 - mean_absolute_percentage_error: 152194.0781 - root_mean_squared_error: 0.1156 - val_loss: 0.0777 - val_mean_absolute_percentage_error: 23055378.0000 - val_root_mean_squared_error: 0.2788\n",
      "Epoch 422/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0133 - mean_absolute_percentage_error: 138959.5938 - root_mean_squared_error: 0.1153 - val_loss: 0.0775 - val_mean_absolute_percentage_error: 23043512.0000 - val_root_mean_squared_error: 0.2784\n",
      "Epoch 423/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0134 - mean_absolute_percentage_error: 143967.2344 - root_mean_squared_error: 0.1159 - val_loss: 0.0783 - val_mean_absolute_percentage_error: 23211766.0000 - val_root_mean_squared_error: 0.2798\n",
      "Epoch 424/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0135 - mean_absolute_percentage_error: 128994.5781 - root_mean_squared_error: 0.1160 - val_loss: 0.0788 - val_mean_absolute_percentage_error: 23294946.0000 - val_root_mean_squared_error: 0.2807\n",
      "Epoch 425/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0137 - mean_absolute_percentage_error: 123856.5391 - root_mean_squared_error: 0.1170 - val_loss: 0.0784 - val_mean_absolute_percentage_error: 23174238.0000 - val_root_mean_squared_error: 0.2800\n",
      "Epoch 426/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0134 - mean_absolute_percentage_error: 121987.6484 - root_mean_squared_error: 0.1155 - val_loss: 0.0780 - val_mean_absolute_percentage_error: 23081370.0000 - val_root_mean_squared_error: 0.2793\n",
      "Epoch 427/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0138 - mean_absolute_percentage_error: 110152.7266 - root_mean_squared_error: 0.1174 - val_loss: 0.0781 - val_mean_absolute_percentage_error: 23166050.0000 - val_root_mean_squared_error: 0.2795\n",
      "Epoch 428/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0134 - mean_absolute_percentage_error: 100945.8359 - root_mean_squared_error: 0.1158 - val_loss: 0.0783 - val_mean_absolute_percentage_error: 23237302.0000 - val_root_mean_squared_error: 0.2799\n",
      "Epoch 429/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0134 - mean_absolute_percentage_error: 98528.7344 - root_mean_squared_error: 0.1158 - val_loss: 0.0783 - val_mean_absolute_percentage_error: 23173706.0000 - val_root_mean_squared_error: 0.2799\n",
      "Epoch 430/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0136 - mean_absolute_percentage_error: 94432.1875 - root_mean_squared_error: 0.1165 - val_loss: 0.0784 - val_mean_absolute_percentage_error: 23150032.0000 - val_root_mean_squared_error: 0.2800\n",
      "Epoch 431/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0139 - mean_absolute_percentage_error: 84445.3594 - root_mean_squared_error: 0.1178 - val_loss: 0.0787 - val_mean_absolute_percentage_error: 23234750.0000 - val_root_mean_squared_error: 0.2805\n",
      "Epoch 432/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0137 - mean_absolute_percentage_error: 87704.1094 - root_mean_squared_error: 0.1171 - val_loss: 0.0788 - val_mean_absolute_percentage_error: 23265870.0000 - val_root_mean_squared_error: 0.2808\n",
      "Epoch 433/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0137 - mean_absolute_percentage_error: 80830.6719 - root_mean_squared_error: 0.1172 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23185574.0000 - val_root_mean_squared_error: 0.2802\n",
      "Epoch 434/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0140 - mean_absolute_percentage_error: 76875.2578 - root_mean_squared_error: 0.1185 - val_loss: 0.0783 - val_mean_absolute_percentage_error: 23137938.0000 - val_root_mean_squared_error: 0.2799\n",
      "Epoch 435/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0136 - mean_absolute_percentage_error: 73300.9531 - root_mean_squared_error: 0.1167 - val_loss: 0.0786 - val_mean_absolute_percentage_error: 23192062.0000 - val_root_mean_squared_error: 0.2804\n",
      "Epoch 436/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0130 - mean_absolute_percentage_error: 66524.7969 - root_mean_squared_error: 0.1139 - val_loss: 0.0789 - val_mean_absolute_percentage_error: 23255974.0000 - val_root_mean_squared_error: 0.2809\n",
      "Epoch 437/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0141 - mean_absolute_percentage_error: 67363.1094 - root_mean_squared_error: 0.1189 - val_loss: 0.0788 - val_mean_absolute_percentage_error: 23235306.0000 - val_root_mean_squared_error: 0.2807\n",
      "Epoch 438/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0141 - mean_absolute_percentage_error: 61326.1016 - root_mean_squared_error: 0.1186 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23178774.0000 - val_root_mean_squared_error: 0.2802\n",
      "Epoch 439/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0137 - mean_absolute_percentage_error: 60797.5547 - root_mean_squared_error: 0.1170 - val_loss: 0.0786 - val_mean_absolute_percentage_error: 23189182.0000 - val_root_mean_squared_error: 0.2803\n",
      "Epoch 440/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0138 - mean_absolute_percentage_error: 56816.8242 - root_mean_squared_error: 0.1173 - val_loss: 0.0787 - val_mean_absolute_percentage_error: 23230872.0000 - val_root_mean_squared_error: 0.2805\n",
      "Epoch 441/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0135 - mean_absolute_percentage_error: 53880.1445 - root_mean_squared_error: 0.1164 - val_loss: 0.0786 - val_mean_absolute_percentage_error: 23212222.0000 - val_root_mean_squared_error: 0.2803\n",
      "Epoch 442/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0134 - mean_absolute_percentage_error: 56804.9375 - root_mean_squared_error: 0.1157 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23180160.0000 - val_root_mean_squared_error: 0.2802\n",
      "Epoch 443/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0138 - mean_absolute_percentage_error: 46987.4922 - root_mean_squared_error: 0.1173 - val_loss: 0.0786 - val_mean_absolute_percentage_error: 23218936.0000 - val_root_mean_squared_error: 0.2804\n",
      "Epoch 444/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0137 - mean_absolute_percentage_error: 49207.4805 - root_mean_squared_error: 0.1170 - val_loss: 0.0787 - val_mean_absolute_percentage_error: 23258058.0000 - val_root_mean_squared_error: 0.2806\n",
      "Epoch 445/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0138 - mean_absolute_percentage_error: 46815.6055 - root_mean_squared_error: 0.1177 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23217510.0000 - val_root_mean_squared_error: 0.2803\n",
      "Epoch 446/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0134 - mean_absolute_percentage_error: 41738.8672 - root_mean_squared_error: 0.1157 - val_loss: 0.0783 - val_mean_absolute_percentage_error: 23167096.0000 - val_root_mean_squared_error: 0.2799\n",
      "Epoch 447/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0138 - mean_absolute_percentage_error: 42616.1172 - root_mean_squared_error: 0.1173 - val_loss: 0.0784 - val_mean_absolute_percentage_error: 23188134.0000 - val_root_mean_squared_error: 0.2800\n",
      "Epoch 448/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0128 - mean_absolute_percentage_error: 36924.9727 - root_mean_squared_error: 0.1130 - val_loss: 0.0786 - val_mean_absolute_percentage_error: 23235678.0000 - val_root_mean_squared_error: 0.2803\n",
      "Epoch 449/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0140 - mean_absolute_percentage_error: 37584.9453 - root_mean_squared_error: 0.1183 - val_loss: 0.0786 - val_mean_absolute_percentage_error: 23233994.0000 - val_root_mean_squared_error: 0.2803\n",
      "Epoch 450/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0139 - mean_absolute_percentage_error: 34688.4297 - root_mean_squared_error: 0.1177 - val_loss: 0.0784 - val_mean_absolute_percentage_error: 23199278.0000 - val_root_mean_squared_error: 0.2800\n",
      "Epoch 451/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0137 - mean_absolute_percentage_error: 34659.3281 - root_mean_squared_error: 0.1171 - val_loss: 0.0784 - val_mean_absolute_percentage_error: 23194742.0000 - val_root_mean_squared_error: 0.2800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 452/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0137 - mean_absolute_percentage_error: 30558.5898 - root_mean_squared_error: 0.1169 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23219882.0000 - val_root_mean_squared_error: 0.2802\n",
      "Epoch 453/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0135 - mean_absolute_percentage_error: 30371.3477 - root_mean_squared_error: 0.1162 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23217030.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 454/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0137 - mean_absolute_percentage_error: 27364.9570 - root_mean_squared_error: 0.1169 - val_loss: 0.0784 - val_mean_absolute_percentage_error: 23189490.0000 - val_root_mean_squared_error: 0.2800\n",
      "Epoch 455/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0143 - mean_absolute_percentage_error: 27764.0059 - root_mean_squared_error: 0.1198 - val_loss: 0.0784 - val_mean_absolute_percentage_error: 23196296.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 456/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0133 - mean_absolute_percentage_error: 25729.9102 - root_mean_squared_error: 0.1154 - val_loss: 0.0786 - val_mean_absolute_percentage_error: 23228190.0000 - val_root_mean_squared_error: 0.2803\n",
      "Epoch 457/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0137 - mean_absolute_percentage_error: 26270.6934 - root_mean_squared_error: 0.1170 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23222082.0000 - val_root_mean_squared_error: 0.2802\n",
      "Epoch 458/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0136 - mean_absolute_percentage_error: 24752.1797 - root_mean_squared_error: 0.1165 - val_loss: 0.0784 - val_mean_absolute_percentage_error: 23188922.0000 - val_root_mean_squared_error: 0.2799\n",
      "Epoch 459/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0131 - mean_absolute_percentage_error: 22567.8848 - root_mean_squared_error: 0.1145 - val_loss: 0.0784 - val_mean_absolute_percentage_error: 23188394.0000 - val_root_mean_squared_error: 0.2799\n",
      "Epoch 460/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0133 - mean_absolute_percentage_error: 23144.4258 - root_mean_squared_error: 0.1153 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23214480.0000 - val_root_mean_squared_error: 0.2802\n",
      "Epoch 461/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0136 - mean_absolute_percentage_error: 19854.1367 - root_mean_squared_error: 0.1164 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23218448.0000 - val_root_mean_squared_error: 0.2803\n",
      "Epoch 462/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0129 - mean_absolute_percentage_error: 20624.9570 - root_mean_squared_error: 0.1138 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23199578.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 463/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0139 - mean_absolute_percentage_error: 18352.1504 - root_mean_squared_error: 0.1178 - val_loss: 0.0784 - val_mean_absolute_percentage_error: 23193294.0000 - val_root_mean_squared_error: 0.2800\n",
      "Epoch 464/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0135 - mean_absolute_percentage_error: 19124.3965 - root_mean_squared_error: 0.1160 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23205366.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 465/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0138 - mean_absolute_percentage_error: 16557.8164 - root_mean_squared_error: 0.1176 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23207590.0000 - val_root_mean_squared_error: 0.2802\n",
      "Epoch 466/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0128 - mean_absolute_percentage_error: 17065.7559 - root_mean_squared_error: 0.1129 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23194494.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 467/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0128 - mean_absolute_percentage_error: 15634.1152 - root_mean_squared_error: 0.1133 - val_loss: 0.0784 - val_mean_absolute_percentage_error: 23195166.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 468/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0133 - mean_absolute_percentage_error: 14120.3701 - root_mean_squared_error: 0.1154 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23212282.0000 - val_root_mean_squared_error: 0.2802\n",
      "Epoch 469/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0135 - mean_absolute_percentage_error: 14604.5918 - root_mean_squared_error: 0.1164 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23212728.0000 - val_root_mean_squared_error: 0.2802\n",
      "Epoch 470/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0135 - mean_absolute_percentage_error: 12570.6660 - root_mean_squared_error: 0.1161 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23195906.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 471/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0136 - mean_absolute_percentage_error: 13016.9219 - root_mean_squared_error: 0.1168 - val_loss: 0.0784 - val_mean_absolute_percentage_error: 23194222.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 472/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0142 - mean_absolute_percentage_error: 12137.4092 - root_mean_squared_error: 0.1190 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23207758.0000 - val_root_mean_squared_error: 0.2802\n",
      "Epoch 473/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0140 - mean_absolute_percentage_error: 11369.2041 - root_mean_squared_error: 0.1182 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23209960.0000 - val_root_mean_squared_error: 0.2802\n",
      "Epoch 474/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0139 - mean_absolute_percentage_error: 10751.4766 - root_mean_squared_error: 0.1179 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23200658.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 475/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0139 - mean_absolute_percentage_error: 9985.2715 - root_mean_squared_error: 0.1180 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23198840.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 476/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0134 - mean_absolute_percentage_error: 10199.4277 - root_mean_squared_error: 0.1158 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23205944.0000 - val_root_mean_squared_error: 0.2802\n",
      "Epoch 477/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0133 - mean_absolute_percentage_error: 8902.5010 - root_mean_squared_error: 0.1153 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23207130.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 478/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0140 - mean_absolute_percentage_error: 8602.9033 - root_mean_squared_error: 0.1183 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23200446.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 479/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0133 - mean_absolute_percentage_error: 8120.4624 - root_mean_squared_error: 0.1154 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23200384.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 480/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0136 - mean_absolute_percentage_error: 7684.8447 - root_mean_squared_error: 0.1165 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23207842.0000 - val_root_mean_squared_error: 0.2802\n",
      "Epoch 481/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0134 - mean_absolute_percentage_error: 7678.6016 - root_mean_squared_error: 0.1158 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23206528.0000 - val_root_mean_squared_error: 0.2802\n",
      "Epoch 482/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0136 - mean_absolute_percentage_error: 7244.4697 - root_mean_squared_error: 0.1165 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23197550.0000 - val_root_mean_squared_error: 0.2801\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 483/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0136 - mean_absolute_percentage_error: 6982.1187 - root_mean_squared_error: 0.1166 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23198472.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 484/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0137 - mean_absolute_percentage_error: 6481.3096 - root_mean_squared_error: 0.1169 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23207014.0000 - val_root_mean_squared_error: 0.2802\n",
      "Epoch 485/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0137 - mean_absolute_percentage_error: 6367.0547 - root_mean_squared_error: 0.1169 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23207358.0000 - val_root_mean_squared_error: 0.2802\n",
      "Epoch 486/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0141 - mean_absolute_percentage_error: 5843.0952 - root_mean_squared_error: 0.1185 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23201386.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 487/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0134 - mean_absolute_percentage_error: 5665.1436 - root_mean_squared_error: 0.1156 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23200830.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 488/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0132 - mean_absolute_percentage_error: 5302.1523 - root_mean_squared_error: 0.1147 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23204186.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 489/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0139 - mean_absolute_percentage_error: 5341.9956 - root_mean_squared_error: 0.1180 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203368.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 490/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0140 - mean_absolute_percentage_error: 4858.2788 - root_mean_squared_error: 0.1182 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23199886.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 491/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0133 - mean_absolute_percentage_error: 5099.1270 - root_mean_squared_error: 0.1155 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23201810.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 492/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0143 - mean_absolute_percentage_error: 4242.8735 - root_mean_squared_error: 0.1197 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23206878.0000 - val_root_mean_squared_error: 0.2802\n",
      "Epoch 493/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0136 - mean_absolute_percentage_error: 4664.6147 - root_mean_squared_error: 0.1164 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23205016.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 494/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0138 - mean_absolute_percentage_error: 3952.2358 - root_mean_squared_error: 0.1176 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23198950.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 495/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0134 - mean_absolute_percentage_error: 3896.4500 - root_mean_squared_error: 0.1159 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23199670.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 496/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0140 - mean_absolute_percentage_error: 3876.9312 - root_mean_squared_error: 0.1184 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23204704.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 497/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0143 - mean_absolute_percentage_error: 3349.5769 - root_mean_squared_error: 0.1197 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23204872.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 498/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0132 - mean_absolute_percentage_error: 3494.7781 - root_mean_squared_error: 0.1148 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23202162.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 499/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0137 - mean_absolute_percentage_error: 3098.0996 - root_mean_squared_error: 0.1170 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23202574.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 500/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0138 - mean_absolute_percentage_error: 2954.8613 - root_mean_squared_error: 0.1177 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23204240.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 501/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0138 - mean_absolute_percentage_error: 2765.9077 - root_mean_squared_error: 0.1175 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203118.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 502/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0142 - mean_absolute_percentage_error: 2686.2903 - root_mean_squared_error: 0.1192 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23201394.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 503/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0139 - mean_absolute_percentage_error: 2520.3965 - root_mean_squared_error: 0.1177 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203056.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 504/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0137 - mean_absolute_percentage_error: 2406.7922 - root_mean_squared_error: 0.1168 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23205530.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 505/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0139 - mean_absolute_percentage_error: 2295.2275 - root_mean_squared_error: 0.1180 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23204262.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 506/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0138 - mean_absolute_percentage_error: 2237.7227 - root_mean_squared_error: 0.1173 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23201790.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 507/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0136 - mean_absolute_percentage_error: 2080.0969 - root_mean_squared_error: 0.1165 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23202702.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 508/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0134 - mean_absolute_percentage_error: 1965.2239 - root_mean_squared_error: 0.1159 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23204400.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 509/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0137 - mean_absolute_percentage_error: 1882.9102 - root_mean_squared_error: 0.1170 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203536.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 510/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0133 - mean_absolute_percentage_error: 1765.0364 - root_mean_squared_error: 0.1153 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23202654.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 511/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0134 - mean_absolute_percentage_error: 1608.6035 - root_mean_squared_error: 0.1157 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203608.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 512/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0138 - mean_absolute_percentage_error: 1547.7969 - root_mean_squared_error: 0.1175 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23204040.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 513/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0139 - mean_absolute_percentage_error: 1509.5883 - root_mean_squared_error: 0.1181 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23202856.0000 - val_root_mean_squared_error: 0.2801\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 514/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0136 - mean_absolute_percentage_error: 1405.3005 - root_mean_squared_error: 0.1166 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23202424.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 515/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0141 - mean_absolute_percentage_error: 1394.4988 - root_mean_squared_error: 0.1189 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203718.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 516/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0137 - mean_absolute_percentage_error: 1276.1047 - root_mean_squared_error: 0.1173 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23204342.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 517/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0134 - mean_absolute_percentage_error: 1262.0325 - root_mean_squared_error: 0.1156 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203098.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 518/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0138 - mean_absolute_percentage_error: 1132.9714 - root_mean_squared_error: 0.1173 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23202534.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 519/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0136 - mean_absolute_percentage_error: 1123.5378 - root_mean_squared_error: 0.1166 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203654.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 520/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0139 - mean_absolute_percentage_error: 1069.2957 - root_mean_squared_error: 0.1181 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203994.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 521/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0139 - mean_absolute_percentage_error: 996.4707 - root_mean_squared_error: 0.1177 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203070.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 522/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0139 - mean_absolute_percentage_error: 1018.0027 - root_mean_squared_error: 0.1179 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203014.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 523/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0135 - mean_absolute_percentage_error: 887.5760 - root_mean_squared_error: 0.1161 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203704.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 524/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0135 - mean_absolute_percentage_error: 887.6932 - root_mean_squared_error: 0.1162 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203494.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 525/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0137 - mean_absolute_percentage_error: 794.6835 - root_mean_squared_error: 0.1169 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23202808.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 526/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0135 - mean_absolute_percentage_error: 842.0214 - root_mean_squared_error: 0.1164 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203074.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 527/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0137 - mean_absolute_percentage_error: 730.1341 - root_mean_squared_error: 0.1171 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203824.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 528/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0137 - mean_absolute_percentage_error: 766.6000 - root_mean_squared_error: 0.1170 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203528.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 529/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0136 - mean_absolute_percentage_error: 679.1139 - root_mean_squared_error: 0.1165 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23202734.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 530/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0134 - mean_absolute_percentage_error: 665.7342 - root_mean_squared_error: 0.1156 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23202952.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 531/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0134 - mean_absolute_percentage_error: 630.2993 - root_mean_squared_error: 0.1156 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203594.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 532/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0140 - mean_absolute_percentage_error: 591.8226 - root_mean_squared_error: 0.1184 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203366.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 533/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0134 - mean_absolute_percentage_error: 561.4480 - root_mean_squared_error: 0.1159 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23202954.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 534/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0136 - mean_absolute_percentage_error: 541.5764 - root_mean_squared_error: 0.1165 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203250.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 535/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0134 - mean_absolute_percentage_error: 490.7512 - root_mean_squared_error: 0.1157 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203480.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 536/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0135 - mean_absolute_percentage_error: 489.4500 - root_mean_squared_error: 0.1161 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203090.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 537/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0137 - mean_absolute_percentage_error: 449.1188 - root_mean_squared_error: 0.1172 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23202942.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 538/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0141 - mean_absolute_percentage_error: 452.3491 - root_mean_squared_error: 0.1186 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203398.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 539/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0140 - mean_absolute_percentage_error: 408.4372 - root_mean_squared_error: 0.1185 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203594.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 540/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0137 - mean_absolute_percentage_error: 408.5024 - root_mean_squared_error: 0.1171 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203190.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 541/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0136 - mean_absolute_percentage_error: 379.5311 - root_mean_squared_error: 0.1168 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23202942.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 542/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0131 - mean_absolute_percentage_error: 347.8688 - root_mean_squared_error: 0.1146 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203238.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 543/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0135 - mean_absolute_percentage_error: 347.0668 - root_mean_squared_error: 0.1161 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203398.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 544/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0142 - mean_absolute_percentage_error: 301.3802 - root_mean_squared_error: 0.1192 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203222.0000 - val_root_mean_squared_error: 0.2801\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 545/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0135 - mean_absolute_percentage_error: 313.1079 - root_mean_squared_error: 0.1161 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203266.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 546/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0137 - mean_absolute_percentage_error: 283.0305 - root_mean_squared_error: 0.1171 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203446.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 547/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0133 - mean_absolute_percentage_error: 278.9603 - root_mean_squared_error: 0.1153 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203304.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 548/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0131 - mean_absolute_percentage_error: 262.1649 - root_mean_squared_error: 0.1144 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203098.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 549/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0139 - mean_absolute_percentage_error: 249.3477 - root_mean_squared_error: 0.1180 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203210.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 550/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0141 - mean_absolute_percentage_error: 239.2004 - root_mean_squared_error: 0.1187 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203408.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 551/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0138 - mean_absolute_percentage_error: 228.6764 - root_mean_squared_error: 0.1174 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203328.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 552/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0140 - mean_absolute_percentage_error: 216.5578 - root_mean_squared_error: 0.1182 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203138.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 553/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0137 - mean_absolute_percentage_error: 202.9042 - root_mean_squared_error: 0.1172 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203242.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 554/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0132 - mean_absolute_percentage_error: 195.7166 - root_mean_squared_error: 0.1148 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203386.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 555/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0139 - mean_absolute_percentage_error: 182.1353 - root_mean_squared_error: 0.1178 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203272.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 556/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0134 - mean_absolute_percentage_error: 173.4939 - root_mean_squared_error: 0.1159 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203198.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 557/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0136 - mean_absolute_percentage_error: 166.9607 - root_mean_squared_error: 0.1168 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203320.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 558/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0135 - mean_absolute_percentage_error: 161.9277 - root_mean_squared_error: 0.1162 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203342.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 559/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0139 - mean_absolute_percentage_error: 153.9964 - root_mean_squared_error: 0.1179 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203174.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 560/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0135 - mean_absolute_percentage_error: 154.1400 - root_mean_squared_error: 0.1164 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203170.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 561/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0136 - mean_absolute_percentage_error: 139.1584 - root_mean_squared_error: 0.1168 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203350.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 562/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0135 - mean_absolute_percentage_error: 138.5123 - root_mean_squared_error: 0.1161 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203376.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 563/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0138 - mean_absolute_percentage_error: 126.8844 - root_mean_squared_error: 0.1175 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203226.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 564/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0132 - mean_absolute_percentage_error: 129.1512 - root_mean_squared_error: 0.1147 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203198.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 565/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0135 - mean_absolute_percentage_error: 112.9881 - root_mean_squared_error: 0.1163 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203306.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 566/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0137 - mean_absolute_percentage_error: 118.5689 - root_mean_squared_error: 0.1172 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203298.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 567/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0128 - mean_absolute_percentage_error: 103.1161 - root_mean_squared_error: 0.1132 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203202.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 568/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0134 - mean_absolute_percentage_error: 106.3152 - root_mean_squared_error: 0.1159 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203258.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 569/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0140 - mean_absolute_percentage_error: 98.0047 - root_mean_squared_error: 0.1184 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203344.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 570/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0128 - mean_absolute_percentage_error: 96.0180 - root_mean_squared_error: 0.1131 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 571/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0134 - mean_absolute_percentage_error: 90.7843 - root_mean_squared_error: 0.1156 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203176.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 572/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0135 - mean_absolute_percentage_error: 90.4019 - root_mean_squared_error: 0.1161 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203248.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 573/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0137 - mean_absolute_percentage_error: 81.4768 - root_mean_squared_error: 0.1172 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203354.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 574/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0138 - mean_absolute_percentage_error: 79.6286 - root_mean_squared_error: 0.1174 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203294.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 575/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0134 - mean_absolute_percentage_error: 73.8298 - root_mean_squared_error: 0.1157 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203198.0000 - val_root_mean_squared_error: 0.2801\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 576/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0137 - mean_absolute_percentage_error: 69.5252 - root_mean_squared_error: 0.1172 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203256.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 577/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0137 - mean_absolute_percentage_error: 67.9403 - root_mean_squared_error: 0.1173 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203326.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 578/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0137 - mean_absolute_percentage_error: 61.3405 - root_mean_squared_error: 0.1171 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203254.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 579/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0135 - mean_absolute_percentage_error: 60.5157 - root_mean_squared_error: 0.1161 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203214.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 580/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0136 - mean_absolute_percentage_error: 55.7773 - root_mean_squared_error: 0.1166 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203280.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 581/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0139 - mean_absolute_percentage_error: 55.6710 - root_mean_squared_error: 0.1179 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203304.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 582/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0137 - mean_absolute_percentage_error: 51.2251 - root_mean_squared_error: 0.1171 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203254.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 583/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0130 - mean_absolute_percentage_error: 50.8542 - root_mean_squared_error: 0.1140 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203234.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 584/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0138 - mean_absolute_percentage_error: 47.6215 - root_mean_squared_error: 0.1176 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203280.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 585/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0135 - mean_absolute_percentage_error: 46.3270 - root_mean_squared_error: 0.1161 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203286.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 586/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0139 - mean_absolute_percentage_error: 44.3231 - root_mean_squared_error: 0.1178 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203256.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 587/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0137 - mean_absolute_percentage_error: 40.9298 - root_mean_squared_error: 0.1170 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203246.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 588/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0133 - mean_absolute_percentage_error: 39.8859 - root_mean_squared_error: 0.1151 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 589/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0140 - mean_absolute_percentage_error: 37.8864 - root_mean_squared_error: 0.1183 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203274.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 590/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0131 - mean_absolute_percentage_error: 37.2891 - root_mean_squared_error: 0.1146 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 591/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0131 - mean_absolute_percentage_error: 33.8518 - root_mean_squared_error: 0.1146 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203248.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 592/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0140 - mean_absolute_percentage_error: 36.1385 - root_mean_squared_error: 0.1184 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203266.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 593/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0133 - mean_absolute_percentage_error: 31.3148 - root_mean_squared_error: 0.1152 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203272.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 594/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0140 - mean_absolute_percentage_error: 33.1934 - root_mean_squared_error: 0.1184 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203258.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 595/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0138 - mean_absolute_percentage_error: 28.9824 - root_mean_squared_error: 0.1173 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203250.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 596/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0129 - mean_absolute_percentage_error: 28.3523 - root_mean_squared_error: 0.1138 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 597/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0133 - mean_absolute_percentage_error: 26.7756 - root_mean_squared_error: 0.1153 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203278.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 598/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0138 - mean_absolute_percentage_error: 25.2963 - root_mean_squared_error: 0.1176 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203270.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 599/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0138 - mean_absolute_percentage_error: 24.3766 - root_mean_squared_error: 0.1173 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203258.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 600/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0135 - mean_absolute_percentage_error: 24.3429 - root_mean_squared_error: 0.1163 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203256.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 601/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0135 - mean_absolute_percentage_error: 22.6544 - root_mean_squared_error: 0.1163 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203266.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 602/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0136 - mean_absolute_percentage_error: 22.3844 - root_mean_squared_error: 0.1165 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203272.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 603/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0132 - mean_absolute_percentage_error: 21.6782 - root_mean_squared_error: 0.1150 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203270.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 604/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0131 - mean_absolute_percentage_error: 20.6674 - root_mean_squared_error: 0.1145 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 605/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0136 - mean_absolute_percentage_error: 20.6108 - root_mean_squared_error: 0.1165 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 606/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0135 - mean_absolute_percentage_error: 18.7407 - root_mean_squared_error: 0.1163 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 607/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0133 - mean_absolute_percentage_error: 18.5406 - root_mean_squared_error: 0.1153 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203270.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 608/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0134 - mean_absolute_percentage_error: 17.6890 - root_mean_squared_error: 0.1157 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203270.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 609/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0135 - mean_absolute_percentage_error: 17.7773 - root_mean_squared_error: 0.1163 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203258.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 610/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0138 - mean_absolute_percentage_error: 16.6017 - root_mean_squared_error: 0.1174 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203258.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 611/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0138 - mean_absolute_percentage_error: 16.5461 - root_mean_squared_error: 0.1175 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203272.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 612/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0137 - mean_absolute_percentage_error: 16.5791 - root_mean_squared_error: 0.1170 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203272.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 613/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0136 - mean_absolute_percentage_error: 14.6255 - root_mean_squared_error: 0.1166 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203266.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 614/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0135 - mean_absolute_percentage_error: 15.1227 - root_mean_squared_error: 0.1163 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203266.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 615/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0133 - mean_absolute_percentage_error: 15.0591 - root_mean_squared_error: 0.1155 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203262.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 616/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0141 - mean_absolute_percentage_error: 13.2672 - root_mean_squared_error: 0.1185 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203262.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 617/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0140 - mean_absolute_percentage_error: 14.7909 - root_mean_squared_error: 0.1183 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 618/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0140 - mean_absolute_percentage_error: 13.9133 - root_mean_squared_error: 0.1184 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 619/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0134 - mean_absolute_percentage_error: 12.7714 - root_mean_squared_error: 0.1156 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203266.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 620/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0145 - mean_absolute_percentage_error: 13.7421 - root_mean_squared_error: 0.1205 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203262.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 621/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0135 - mean_absolute_percentage_error: 12.1807 - root_mean_squared_error: 0.1164 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 622/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0144 - mean_absolute_percentage_error: 12.3544 - root_mean_squared_error: 0.1202 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203270.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 623/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0128 - mean_absolute_percentage_error: 12.1506 - root_mean_squared_error: 0.1130 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203270.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 624/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0141 - mean_absolute_percentage_error: 11.3978 - root_mean_squared_error: 0.1189 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203262.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 625/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0135 - mean_absolute_percentage_error: 11.4051 - root_mean_squared_error: 0.1162 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203262.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 626/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0140 - mean_absolute_percentage_error: 10.4236 - root_mean_squared_error: 0.1182 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203262.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 627/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0131 - mean_absolute_percentage_error: 10.5249 - root_mean_squared_error: 0.1145 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203266.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 628/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0135 - mean_absolute_percentage_error: 10.3089 - root_mean_squared_error: 0.1162 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203270.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 629/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0138 - mean_absolute_percentage_error: 9.5680 - root_mean_squared_error: 0.1173 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203270.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 630/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0134 - mean_absolute_percentage_error: 10.2084 - root_mean_squared_error: 0.1156 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 631/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0136 - mean_absolute_percentage_error: 9.3537 - root_mean_squared_error: 0.1164 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 632/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0134 - mean_absolute_percentage_error: 9.0124 - root_mean_squared_error: 0.1158 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203266.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 633/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0134 - mean_absolute_percentage_error: 9.0423 - root_mean_squared_error: 0.1160 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 634/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0134 - mean_absolute_percentage_error: 8.4758 - root_mean_squared_error: 0.1158 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203266.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 635/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0137 - mean_absolute_percentage_error: 8.1995 - root_mean_squared_error: 0.1171 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 636/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0134 - mean_absolute_percentage_error: 8.1957 - root_mean_squared_error: 0.1157 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 637/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0131 - mean_absolute_percentage_error: 7.9512 - root_mean_squared_error: 0.1145 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203266.0000 - val_root_mean_squared_error: 0.2801\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 638/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0139 - mean_absolute_percentage_error: 7.9676 - root_mean_squared_error: 0.1178 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203266.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 639/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0134 - mean_absolute_percentage_error: 7.7599 - root_mean_squared_error: 0.1156 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 640/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0137 - mean_absolute_percentage_error: 8.0123 - root_mean_squared_error: 0.1170 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 641/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0133 - mean_absolute_percentage_error: 7.8028 - root_mean_squared_error: 0.1155 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 642/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0140 - mean_absolute_percentage_error: 7.9004 - root_mean_squared_error: 0.1182 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203266.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 643/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0137 - mean_absolute_percentage_error: 7.7708 - root_mean_squared_error: 0.1170 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203266.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 644/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0140 - mean_absolute_percentage_error: 7.4270 - root_mean_squared_error: 0.1183 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203266.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 645/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0139 - mean_absolute_percentage_error: 7.4330 - root_mean_squared_error: 0.1179 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 646/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0133 - mean_absolute_percentage_error: 7.4594 - root_mean_squared_error: 0.1155 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 647/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0139 - mean_absolute_percentage_error: 7.5172 - root_mean_squared_error: 0.1180 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203270.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 648/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0137 - mean_absolute_percentage_error: 7.3700 - root_mean_squared_error: 0.1169 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203270.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 649/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0134 - mean_absolute_percentage_error: 6.8442 - root_mean_squared_error: 0.1157 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203270.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 650/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0136 - mean_absolute_percentage_error: 7.2274 - root_mean_squared_error: 0.1165 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 651/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0135 - mean_absolute_percentage_error: 7.6562 - root_mean_squared_error: 0.1162 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 652/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0137 - mean_absolute_percentage_error: 7.1604 - root_mean_squared_error: 0.1169 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 653/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0137 - mean_absolute_percentage_error: 7.5338 - root_mean_squared_error: 0.1173 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 654/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0136 - mean_absolute_percentage_error: 7.4176 - root_mean_squared_error: 0.1168 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 655/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0137 - mean_absolute_percentage_error: 7.1890 - root_mean_squared_error: 0.1168 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 656/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0134 - mean_absolute_percentage_error: 6.9481 - root_mean_squared_error: 0.1159 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 657/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0139 - mean_absolute_percentage_error: 6.8671 - root_mean_squared_error: 0.1179 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203266.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 658/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0135 - mean_absolute_percentage_error: 7.0588 - root_mean_squared_error: 0.1164 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203266.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 659/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0134 - mean_absolute_percentage_error: 7.2054 - root_mean_squared_error: 0.1158 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203262.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 660/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0136 - mean_absolute_percentage_error: 7.0253 - root_mean_squared_error: 0.1166 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 661/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0134 - mean_absolute_percentage_error: 6.9444 - root_mean_squared_error: 0.1157 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 662/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0130 - mean_absolute_percentage_error: 7.2524 - root_mean_squared_error: 0.1142 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 663/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0138 - mean_absolute_percentage_error: 7.0607 - root_mean_squared_error: 0.1174 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 664/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0132 - mean_absolute_percentage_error: 7.0533 - root_mean_squared_error: 0.1148 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203270.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 665/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0134 - mean_absolute_percentage_error: 6.8396 - root_mean_squared_error: 0.1158 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203266.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 666/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0135 - mean_absolute_percentage_error: 6.5688 - root_mean_squared_error: 0.1164 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203270.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 667/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0139 - mean_absolute_percentage_error: 7.3192 - root_mean_squared_error: 0.1179 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 668/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0134 - mean_absolute_percentage_error: 6.7903 - root_mean_squared_error: 0.1156 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 669/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step - loss: 0.0136 - mean_absolute_percentage_error: 6.6143 - root_mean_squared_error: 0.1166 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 670/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0133 - mean_absolute_percentage_error: 6.5434 - root_mean_squared_error: 0.1154 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 671/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0138 - mean_absolute_percentage_error: 7.0353 - root_mean_squared_error: 0.1175 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 672/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0134 - mean_absolute_percentage_error: 7.1093 - root_mean_squared_error: 0.1156 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 673/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0134 - mean_absolute_percentage_error: 6.5063 - root_mean_squared_error: 0.1156 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 674/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0140 - mean_absolute_percentage_error: 6.8997 - root_mean_squared_error: 0.1184 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203266.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 675/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0138 - mean_absolute_percentage_error: 6.8983 - root_mean_squared_error: 0.1177 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203266.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 676/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0138 - mean_absolute_percentage_error: 6.4535 - root_mean_squared_error: 0.1174 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203266.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 677/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0135 - mean_absolute_percentage_error: 6.6204 - root_mean_squared_error: 0.1161 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203266.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 678/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0131 - mean_absolute_percentage_error: 6.3750 - root_mean_squared_error: 0.1144 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 679/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0132 - mean_absolute_percentage_error: 6.2585 - root_mean_squared_error: 0.1148 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 680/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0133 - mean_absolute_percentage_error: 6.3825 - root_mean_squared_error: 0.1154 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203266.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 681/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0136 - mean_absolute_percentage_error: 6.6863 - root_mean_squared_error: 0.1164 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203266.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 682/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0134 - mean_absolute_percentage_error: 6.2263 - root_mean_squared_error: 0.1158 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 683/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0144 - mean_absolute_percentage_error: 6.3101 - root_mean_squared_error: 0.1200 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 684/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0133 - mean_absolute_percentage_error: 6.7587 - root_mean_squared_error: 0.1151 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 685/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0136 - mean_absolute_percentage_error: 6.5583 - root_mean_squared_error: 0.1167 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203266.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 686/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0138 - mean_absolute_percentage_error: 6.3866 - root_mean_squared_error: 0.1175 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 687/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0140 - mean_absolute_percentage_error: 6.6991 - root_mean_squared_error: 0.1183 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203262.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 688/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0140 - mean_absolute_percentage_error: 6.8047 - root_mean_squared_error: 0.1185 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 689/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0138 - mean_absolute_percentage_error: 7.1148 - root_mean_squared_error: 0.1176 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 690/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0139 - mean_absolute_percentage_error: 6.5824 - root_mean_squared_error: 0.1178 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 691/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0133 - mean_absolute_percentage_error: 6.8419 - root_mean_squared_error: 0.1152 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 692/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0142 - mean_absolute_percentage_error: 6.9041 - root_mean_squared_error: 0.1191 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203266.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 693/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0133 - mean_absolute_percentage_error: 6.1429 - root_mean_squared_error: 0.1152 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 694/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0139 - mean_absolute_percentage_error: 6.7298 - root_mean_squared_error: 0.1180 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 695/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0136 - mean_absolute_percentage_error: 7.1461 - root_mean_squared_error: 0.1167 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203266.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 696/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0139 - mean_absolute_percentage_error: 6.3964 - root_mean_squared_error: 0.1178 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203266.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 697/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0142 - mean_absolute_percentage_error: 6.6725 - root_mean_squared_error: 0.1193 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 698/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0134 - mean_absolute_percentage_error: 6.9434 - root_mean_squared_error: 0.1156 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 699/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0134 - mean_absolute_percentage_error: 6.2933 - root_mean_squared_error: 0.1157 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203266.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 700/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step - loss: 0.0137 - mean_absolute_percentage_error: 6.8065 - root_mean_squared_error: 0.1169 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203266.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 701/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0132 - mean_absolute_percentage_error: 6.6788 - root_mean_squared_error: 0.1150 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203266.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 702/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0139 - mean_absolute_percentage_error: 6.4835 - root_mean_squared_error: 0.1177 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203266.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 703/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0145 - mean_absolute_percentage_error: 6.7670 - root_mean_squared_error: 0.1203 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203266.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 704/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0140 - mean_absolute_percentage_error: 6.4531 - root_mean_squared_error: 0.1185 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 705/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0137 - mean_absolute_percentage_error: 6.4063 - root_mean_squared_error: 0.1172 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 706/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0138 - mean_absolute_percentage_error: 7.0613 - root_mean_squared_error: 0.1175 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 707/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0130 - mean_absolute_percentage_error: 6.3760 - root_mean_squared_error: 0.1142 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 708/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0134 - mean_absolute_percentage_error: 6.8381 - root_mean_squared_error: 0.1158 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 709/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0136 - mean_absolute_percentage_error: 7.4203 - root_mean_squared_error: 0.1167 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 710/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0139 - mean_absolute_percentage_error: 6.7012 - root_mean_squared_error: 0.1177 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203266.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 711/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0138 - mean_absolute_percentage_error: 7.0477 - root_mean_squared_error: 0.1176 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203266.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 712/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0134 - mean_absolute_percentage_error: 6.8377 - root_mean_squared_error: 0.1159 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203266.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 713/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0134 - mean_absolute_percentage_error: 6.6299 - root_mean_squared_error: 0.1158 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 714/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0142 - mean_absolute_percentage_error: 6.5724 - root_mean_squared_error: 0.1191 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 715/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0138 - mean_absolute_percentage_error: 7.0904 - root_mean_squared_error: 0.1175 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203266.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 716/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0138 - mean_absolute_percentage_error: 6.4945 - root_mean_squared_error: 0.1174 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203270.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 717/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0140 - mean_absolute_percentage_error: 6.2798 - root_mean_squared_error: 0.1181 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203266.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 718/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0139 - mean_absolute_percentage_error: 6.4118 - root_mean_squared_error: 0.1178 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 719/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0138 - mean_absolute_percentage_error: 6.7842 - root_mean_squared_error: 0.1177 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 720/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0139 - mean_absolute_percentage_error: 6.2557 - root_mean_squared_error: 0.1178 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203266.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 721/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0135 - mean_absolute_percentage_error: 6.5628 - root_mean_squared_error: 0.1163 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203266.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 722/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0140 - mean_absolute_percentage_error: 6.4497 - root_mean_squared_error: 0.1181 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 723/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0135 - mean_absolute_percentage_error: 7.1003 - root_mean_squared_error: 0.1160 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 724/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0138 - mean_absolute_percentage_error: 6.7589 - root_mean_squared_error: 0.1175 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203266.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 725/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0143 - mean_absolute_percentage_error: 7.0844 - root_mean_squared_error: 0.1197 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203270.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 726/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0133 - mean_absolute_percentage_error: 7.1388 - root_mean_squared_error: 0.1152 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203266.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 727/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0135 - mean_absolute_percentage_error: 6.7299 - root_mean_squared_error: 0.1163 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203266.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 728/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0134 - mean_absolute_percentage_error: 6.8892 - root_mean_squared_error: 0.1157 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 729/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0139 - mean_absolute_percentage_error: 6.9263 - root_mean_squared_error: 0.1178 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 730/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0137 - mean_absolute_percentage_error: 6.9427 - root_mean_squared_error: 0.1172 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203266.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 731/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step - loss: 0.0135 - mean_absolute_percentage_error: 7.2368 - root_mean_squared_error: 0.1160 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203266.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 732/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0139 - mean_absolute_percentage_error: 7.0911 - root_mean_squared_error: 0.1179 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 733/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0133 - mean_absolute_percentage_error: 6.8783 - root_mean_squared_error: 0.1153 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 734/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0143 - mean_absolute_percentage_error: 7.2407 - root_mean_squared_error: 0.1194 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203266.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 735/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0135 - mean_absolute_percentage_error: 6.7697 - root_mean_squared_error: 0.1163 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203266.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 736/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0138 - mean_absolute_percentage_error: 7.0999 - root_mean_squared_error: 0.1176 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203270.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 737/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0135 - mean_absolute_percentage_error: 6.6774 - root_mean_squared_error: 0.1160 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203266.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 738/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0137 - mean_absolute_percentage_error: 6.7376 - root_mean_squared_error: 0.1170 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 739/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0131 - mean_absolute_percentage_error: 6.7796 - root_mean_squared_error: 0.1144 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203266.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 740/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0136 - mean_absolute_percentage_error: 6.8964 - root_mean_squared_error: 0.1166 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203270.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 741/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0136 - mean_absolute_percentage_error: 6.9244 - root_mean_squared_error: 0.1165 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 742/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0137 - mean_absolute_percentage_error: 6.5827 - root_mean_squared_error: 0.1169 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 743/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0138 - mean_absolute_percentage_error: 6.5696 - root_mean_squared_error: 0.1174 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 744/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0137 - mean_absolute_percentage_error: 6.8308 - root_mean_squared_error: 0.1172 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203266.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 745/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0135 - mean_absolute_percentage_error: 6.9496 - root_mean_squared_error: 0.1162 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203266.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 746/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0137 - mean_absolute_percentage_error: 6.8600 - root_mean_squared_error: 0.1170 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203266.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 747/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0139 - mean_absolute_percentage_error: 6.9740 - root_mean_squared_error: 0.1180 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203262.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 748/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0133 - mean_absolute_percentage_error: 6.8519 - root_mean_squared_error: 0.1152 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203266.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 749/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0139 - mean_absolute_percentage_error: 6.8127 - root_mean_squared_error: 0.1178 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203266.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 750/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0134 - mean_absolute_percentage_error: 7.6109 - root_mean_squared_error: 0.1159 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203266.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 751/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0133 - mean_absolute_percentage_error: 6.3519 - root_mean_squared_error: 0.1152 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 752/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0134 - mean_absolute_percentage_error: 6.8778 - root_mean_squared_error: 0.1159 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 753/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0137 - mean_absolute_percentage_error: 6.6995 - root_mean_squared_error: 0.1172 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 754/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0141 - mean_absolute_percentage_error: 6.8128 - root_mean_squared_error: 0.1186 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203270.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 755/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0139 - mean_absolute_percentage_error: 7.0001 - root_mean_squared_error: 0.1178 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 756/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0141 - mean_absolute_percentage_error: 6.7459 - root_mean_squared_error: 0.1188 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 757/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0137 - mean_absolute_percentage_error: 6.7823 - root_mean_squared_error: 0.1171 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203266.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 758/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0140 - mean_absolute_percentage_error: 6.6427 - root_mean_squared_error: 0.1184 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203270.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 759/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0139 - mean_absolute_percentage_error: 6.7113 - root_mean_squared_error: 0.1178 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203266.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 760/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0141 - mean_absolute_percentage_error: 6.7903 - root_mean_squared_error: 0.1188 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203266.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 761/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0141 - mean_absolute_percentage_error: 6.7300 - root_mean_squared_error: 0.1187 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 762/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step - loss: 0.0138 - mean_absolute_percentage_error: 6.4172 - root_mean_squared_error: 0.1174 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 763/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0134 - mean_absolute_percentage_error: 6.5685 - root_mean_squared_error: 0.1158 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203270.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 764/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0142 - mean_absolute_percentage_error: 6.6105 - root_mean_squared_error: 0.1192 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203270.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 765/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0135 - mean_absolute_percentage_error: 6.2135 - root_mean_squared_error: 0.1162 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 766/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0138 - mean_absolute_percentage_error: 6.6826 - root_mean_squared_error: 0.1174 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 767/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0143 - mean_absolute_percentage_error: 7.0974 - root_mean_squared_error: 0.1194 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 768/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0137 - mean_absolute_percentage_error: 6.5899 - root_mean_squared_error: 0.1171 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203270.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 769/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0143 - mean_absolute_percentage_error: 6.6673 - root_mean_squared_error: 0.1194 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203266.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 770/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0136 - mean_absolute_percentage_error: 6.7310 - root_mean_squared_error: 0.1168 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 771/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0138 - mean_absolute_percentage_error: 6.4927 - root_mean_squared_error: 0.1173 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 772/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0137 - mean_absolute_percentage_error: 6.6871 - root_mean_squared_error: 0.1173 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203266.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 773/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0140 - mean_absolute_percentage_error: 7.0073 - root_mean_squared_error: 0.1184 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203266.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 774/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0139 - mean_absolute_percentage_error: 6.4794 - root_mean_squared_error: 0.1178 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203262.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 775/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0139 - mean_absolute_percentage_error: 6.5858 - root_mean_squared_error: 0.1178 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 776/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0138 - mean_absolute_percentage_error: 6.9830 - root_mean_squared_error: 0.1173 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203272.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 777/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0139 - mean_absolute_percentage_error: 7.1319 - root_mean_squared_error: 0.1178 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 778/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0135 - mean_absolute_percentage_error: 6.9177 - root_mean_squared_error: 0.1160 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203262.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 779/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0138 - mean_absolute_percentage_error: 7.3898 - root_mean_squared_error: 0.1176 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203266.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 780/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0135 - mean_absolute_percentage_error: 7.2165 - root_mean_squared_error: 0.1164 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203270.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 781/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0136 - mean_absolute_percentage_error: 7.5984 - root_mean_squared_error: 0.1165 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203270.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 782/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0132 - mean_absolute_percentage_error: 6.5451 - root_mean_squared_error: 0.1151 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 783/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0139 - mean_absolute_percentage_error: 8.0734 - root_mean_squared_error: 0.1180 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 784/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0136 - mean_absolute_percentage_error: 7.8507 - root_mean_squared_error: 0.1166 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203272.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 785/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0137 - mean_absolute_percentage_error: 8.3365 - root_mean_squared_error: 0.1170 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 786/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0137 - mean_absolute_percentage_error: 7.3756 - root_mean_squared_error: 0.1172 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 787/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0136 - mean_absolute_percentage_error: 7.2522 - root_mean_squared_error: 0.1166 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203266.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 788/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0137 - mean_absolute_percentage_error: 7.8429 - root_mean_squared_error: 0.1170 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203266.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 789/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0137 - mean_absolute_percentage_error: 6.8322 - root_mean_squared_error: 0.1169 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203266.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 790/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0137 - mean_absolute_percentage_error: 7.2015 - root_mean_squared_error: 0.1172 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203266.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 791/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0132 - mean_absolute_percentage_error: 7.0743 - root_mean_squared_error: 0.1147 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 792/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0139 - mean_absolute_percentage_error: 6.8252 - root_mean_squared_error: 0.1178 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 793/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step - loss: 0.0135 - mean_absolute_percentage_error: 6.6285 - root_mean_squared_error: 0.1163 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 794/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0135 - mean_absolute_percentage_error: 6.4918 - root_mean_squared_error: 0.1160 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 795/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0137 - mean_absolute_percentage_error: 6.4227 - root_mean_squared_error: 0.1172 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 796/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0137 - mean_absolute_percentage_error: 6.3690 - root_mean_squared_error: 0.1170 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 797/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0135 - mean_absolute_percentage_error: 6.6034 - root_mean_squared_error: 0.1162 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203266.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 798/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0138 - mean_absolute_percentage_error: 6.4788 - root_mean_squared_error: 0.1174 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203266.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 799/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0134 - mean_absolute_percentage_error: 6.5963 - root_mean_squared_error: 0.1156 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203266.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 800/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0140 - mean_absolute_percentage_error: 6.7571 - root_mean_squared_error: 0.1183 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203266.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 801/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0139 - mean_absolute_percentage_error: 6.6629 - root_mean_squared_error: 0.1179 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203266.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 802/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0133 - mean_absolute_percentage_error: 6.3351 - root_mean_squared_error: 0.1153 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 803/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0138 - mean_absolute_percentage_error: 6.3729 - root_mean_squared_error: 0.1174 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 804/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0140 - mean_absolute_percentage_error: 6.6482 - root_mean_squared_error: 0.1183 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 805/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0138 - mean_absolute_percentage_error: 6.8212 - root_mean_squared_error: 0.1174 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 806/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0134 - mean_absolute_percentage_error: 6.4602 - root_mean_squared_error: 0.1158 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203266.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 807/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0140 - mean_absolute_percentage_error: 6.3067 - root_mean_squared_error: 0.1184 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203266.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 808/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0141 - mean_absolute_percentage_error: 6.6916 - root_mean_squared_error: 0.1188 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203266.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 809/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0135 - mean_absolute_percentage_error: 6.4321 - root_mean_squared_error: 0.1161 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 810/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0135 - mean_absolute_percentage_error: 6.2112 - root_mean_squared_error: 0.1161 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 811/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0138 - mean_absolute_percentage_error: 6.5459 - root_mean_squared_error: 0.1176 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 812/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0140 - mean_absolute_percentage_error: 6.3953 - root_mean_squared_error: 0.1184 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203266.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 813/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0137 - mean_absolute_percentage_error: 6.8114 - root_mean_squared_error: 0.1170 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203266.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 814/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0133 - mean_absolute_percentage_error: 6.4714 - root_mean_squared_error: 0.1155 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 815/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0135 - mean_absolute_percentage_error: 6.8408 - root_mean_squared_error: 0.1160 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 816/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0139 - mean_absolute_percentage_error: 6.7164 - root_mean_squared_error: 0.1179 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 817/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0136 - mean_absolute_percentage_error: 6.9112 - root_mean_squared_error: 0.1168 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203266.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 818/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0133 - mean_absolute_percentage_error: 6.5393 - root_mean_squared_error: 0.1151 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 819/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0139 - mean_absolute_percentage_error: 7.0667 - root_mean_squared_error: 0.1178 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203262.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 820/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0136 - mean_absolute_percentage_error: 6.4563 - root_mean_squared_error: 0.1166 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 821/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0136 - mean_absolute_percentage_error: 7.0484 - root_mean_squared_error: 0.1167 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203266.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 822/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0135 - mean_absolute_percentage_error: 7.2710 - root_mean_squared_error: 0.1161 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203266.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 823/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0139 - mean_absolute_percentage_error: 6.3721 - root_mean_squared_error: 0.1178 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203266.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 824/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step - loss: 0.0131 - mean_absolute_percentage_error: 7.2894 - root_mean_squared_error: 0.1147 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 825/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0129 - mean_absolute_percentage_error: 6.5583 - root_mean_squared_error: 0.1134 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 826/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0142 - mean_absolute_percentage_error: 6.7949 - root_mean_squared_error: 0.1191 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 827/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0136 - mean_absolute_percentage_error: 7.0340 - root_mean_squared_error: 0.1164 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 828/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0138 - mean_absolute_percentage_error: 6.9972 - root_mean_squared_error: 0.1174 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203266.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 829/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0136 - mean_absolute_percentage_error: 6.9683 - root_mean_squared_error: 0.1166 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203270.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 830/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0130 - mean_absolute_percentage_error: 6.7249 - root_mean_squared_error: 0.1140 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203270.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 831/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0127 - mean_absolute_percentage_error: 7.2964 - root_mean_squared_error: 0.1126 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 832/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0134 - mean_absolute_percentage_error: 7.3994 - root_mean_squared_error: 0.1156 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 833/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0136 - mean_absolute_percentage_error: 6.9769 - root_mean_squared_error: 0.1166 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203266.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 834/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0136 - mean_absolute_percentage_error: 7.3522 - root_mean_squared_error: 0.1166 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203266.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 835/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0139 - mean_absolute_percentage_error: 7.7806 - root_mean_squared_error: 0.1177 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 836/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0134 - mean_absolute_percentage_error: 6.7032 - root_mean_squared_error: 0.1157 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 837/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0138 - mean_absolute_percentage_error: 8.1052 - root_mean_squared_error: 0.1173 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203270.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 838/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0136 - mean_absolute_percentage_error: 7.8003 - root_mean_squared_error: 0.1166 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203270.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 839/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0140 - mean_absolute_percentage_error: 6.8245 - root_mean_squared_error: 0.1183 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203262.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 840/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0134 - mean_absolute_percentage_error: 9.1382 - root_mean_squared_error: 0.1157 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203262.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 841/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0138 - mean_absolute_percentage_error: 6.9687 - root_mean_squared_error: 0.1175 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203266.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 842/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0138 - mean_absolute_percentage_error: 8.1026 - root_mean_squared_error: 0.1173 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 843/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0136 - mean_absolute_percentage_error: 7.3069 - root_mean_squared_error: 0.1164 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203262.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 844/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0133 - mean_absolute_percentage_error: 7.5696 - root_mean_squared_error: 0.1151 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 845/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0133 - mean_absolute_percentage_error: 7.2762 - root_mean_squared_error: 0.1153 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203266.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 846/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0137 - mean_absolute_percentage_error: 7.7372 - root_mean_squared_error: 0.1169 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203266.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 847/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0139 - mean_absolute_percentage_error: 6.5835 - root_mean_squared_error: 0.1181 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 848/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0133 - mean_absolute_percentage_error: 7.8560 - root_mean_squared_error: 0.1155 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 849/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0134 - mean_absolute_percentage_error: 7.4314 - root_mean_squared_error: 0.1159 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203266.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 850/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0136 - mean_absolute_percentage_error: 6.8498 - root_mean_squared_error: 0.1165 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203266.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 851/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0134 - mean_absolute_percentage_error: 7.2874 - root_mean_squared_error: 0.1159 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203262.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 852/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0136 - mean_absolute_percentage_error: 7.7169 - root_mean_squared_error: 0.1167 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 853/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0136 - mean_absolute_percentage_error: 7.5172 - root_mean_squared_error: 0.1166 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203262.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 854/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0136 - mean_absolute_percentage_error: 7.5668 - root_mean_squared_error: 0.1166 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203266.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 855/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step - loss: 0.0137 - mean_absolute_percentage_error: 7.2632 - root_mean_squared_error: 0.1171 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203266.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 856/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0133 - mean_absolute_percentage_error: 7.3896 - root_mean_squared_error: 0.1153 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 857/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0138 - mean_absolute_percentage_error: 7.6086 - root_mean_squared_error: 0.1174 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203266.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 858/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0136 - mean_absolute_percentage_error: 7.2178 - root_mean_squared_error: 0.1165 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203266.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 859/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0137 - mean_absolute_percentage_error: 7.0804 - root_mean_squared_error: 0.1169 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203270.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 860/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0144 - mean_absolute_percentage_error: 7.4751 - root_mean_squared_error: 0.1202 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 861/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0135 - mean_absolute_percentage_error: 7.4812 - root_mean_squared_error: 0.1162 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 862/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0136 - mean_absolute_percentage_error: 7.1866 - root_mean_squared_error: 0.1166 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 863/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0145 - mean_absolute_percentage_error: 7.1333 - root_mean_squared_error: 0.1204 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 864/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0136 - mean_absolute_percentage_error: 7.4601 - root_mean_squared_error: 0.1165 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 865/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0135 - mean_absolute_percentage_error: 6.6172 - root_mean_squared_error: 0.1162 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 866/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0130 - mean_absolute_percentage_error: 6.7949 - root_mean_squared_error: 0.1139 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 867/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0139 - mean_absolute_percentage_error: 7.2792 - root_mean_squared_error: 0.1177 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 868/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0137 - mean_absolute_percentage_error: 6.2601 - root_mean_squared_error: 0.1169 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 869/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0138 - mean_absolute_percentage_error: 7.2345 - root_mean_squared_error: 0.1173 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 870/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0130 - mean_absolute_percentage_error: 6.8991 - root_mean_squared_error: 0.1138 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 871/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0136 - mean_absolute_percentage_error: 6.8514 - root_mean_squared_error: 0.1165 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 872/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0141 - mean_absolute_percentage_error: 7.1277 - root_mean_squared_error: 0.1187 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203262.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 873/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0135 - mean_absolute_percentage_error: 6.7639 - root_mean_squared_error: 0.1161 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 874/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0138 - mean_absolute_percentage_error: 7.0476 - root_mean_squared_error: 0.1174 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 875/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0128 - mean_absolute_percentage_error: 6.4552 - root_mean_squared_error: 0.1132 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203270.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 876/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0141 - mean_absolute_percentage_error: 6.8132 - root_mean_squared_error: 0.1187 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 877/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0137 - mean_absolute_percentage_error: 6.5788 - root_mean_squared_error: 0.1169 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203266.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 878/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0135 - mean_absolute_percentage_error: 7.0426 - root_mean_squared_error: 0.1160 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 879/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0137 - mean_absolute_percentage_error: 6.7850 - root_mean_squared_error: 0.1170 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 880/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0139 - mean_absolute_percentage_error: 7.0056 - root_mean_squared_error: 0.1180 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203266.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 881/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0138 - mean_absolute_percentage_error: 6.7875 - root_mean_squared_error: 0.1174 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203266.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 882/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0135 - mean_absolute_percentage_error: 7.2845 - root_mean_squared_error: 0.1161 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 883/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0136 - mean_absolute_percentage_error: 7.1371 - root_mean_squared_error: 0.1166 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 884/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0135 - mean_absolute_percentage_error: 7.1271 - root_mean_squared_error: 0.1164 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 885/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0140 - mean_absolute_percentage_error: 6.7248 - root_mean_squared_error: 0.1183 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 886/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step - loss: 0.0128 - mean_absolute_percentage_error: 6.9250 - root_mean_squared_error: 0.1132 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203270.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 887/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0137 - mean_absolute_percentage_error: 6.6222 - root_mean_squared_error: 0.1169 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203266.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 888/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0134 - mean_absolute_percentage_error: 6.8900 - root_mean_squared_error: 0.1156 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 889/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0137 - mean_absolute_percentage_error: 6.8928 - root_mean_squared_error: 0.1170 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 890/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0134 - mean_absolute_percentage_error: 6.6985 - root_mean_squared_error: 0.1159 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203270.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 891/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0140 - mean_absolute_percentage_error: 6.6264 - root_mean_squared_error: 0.1182 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 892/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0136 - mean_absolute_percentage_error: 6.5052 - root_mean_squared_error: 0.1167 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 893/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0135 - mean_absolute_percentage_error: 6.8895 - root_mean_squared_error: 0.1162 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203262.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 894/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0134 - mean_absolute_percentage_error: 6.5048 - root_mean_squared_error: 0.1156 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203266.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 895/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0138 - mean_absolute_percentage_error: 6.7638 - root_mean_squared_error: 0.1174 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 896/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0138 - mean_absolute_percentage_error: 6.5753 - root_mean_squared_error: 0.1174 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 897/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0138 - mean_absolute_percentage_error: 6.8126 - root_mean_squared_error: 0.1176 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203270.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 898/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0130 - mean_absolute_percentage_error: 6.7725 - root_mean_squared_error: 0.1139 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203266.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 899/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0134 - mean_absolute_percentage_error: 6.7389 - root_mean_squared_error: 0.1158 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 900/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0135 - mean_absolute_percentage_error: 6.6331 - root_mean_squared_error: 0.1163 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 901/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0140 - mean_absolute_percentage_error: 6.7902 - root_mean_squared_error: 0.1184 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203266.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 902/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0137 - mean_absolute_percentage_error: 6.8338 - root_mean_squared_error: 0.1168 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 903/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0135 - mean_absolute_percentage_error: 6.6756 - root_mean_squared_error: 0.1162 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 904/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0135 - mean_absolute_percentage_error: 6.2266 - root_mean_squared_error: 0.1160 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 905/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0138 - mean_absolute_percentage_error: 6.6563 - root_mean_squared_error: 0.1174 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 906/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0137 - mean_absolute_percentage_error: 6.4299 - root_mean_squared_error: 0.1171 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203266.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 907/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0136 - mean_absolute_percentage_error: 6.7356 - root_mean_squared_error: 0.1164 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 908/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0131 - mean_absolute_percentage_error: 6.7323 - root_mean_squared_error: 0.1144 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 909/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0136 - mean_absolute_percentage_error: 6.5121 - root_mean_squared_error: 0.1166 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 910/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0136 - mean_absolute_percentage_error: 6.8926 - root_mean_squared_error: 0.1168 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 911/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0130 - mean_absolute_percentage_error: 6.1838 - root_mean_squared_error: 0.1139 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203262.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 912/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0137 - mean_absolute_percentage_error: 6.5284 - root_mean_squared_error: 0.1169 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203262.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 913/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0140 - mean_absolute_percentage_error: 7.1172 - root_mean_squared_error: 0.1183 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 914/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0135 - mean_absolute_percentage_error: 6.4360 - root_mean_squared_error: 0.1161 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203270.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 915/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0131 - mean_absolute_percentage_error: 6.9740 - root_mean_squared_error: 0.1143 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203266.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 916/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0138 - mean_absolute_percentage_error: 7.1440 - root_mean_squared_error: 0.1175 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 917/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step - loss: 0.0137 - mean_absolute_percentage_error: 6.8612 - root_mean_squared_error: 0.1172 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 918/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0134 - mean_absolute_percentage_error: 7.1935 - root_mean_squared_error: 0.1159 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203270.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 919/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0137 - mean_absolute_percentage_error: 6.9744 - root_mean_squared_error: 0.1172 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 920/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0135 - mean_absolute_percentage_error: 6.9458 - root_mean_squared_error: 0.1161 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 921/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0133 - mean_absolute_percentage_error: 7.4535 - root_mean_squared_error: 0.1153 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 922/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0136 - mean_absolute_percentage_error: 6.4922 - root_mean_squared_error: 0.1168 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203270.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 923/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0139 - mean_absolute_percentage_error: 7.3400 - root_mean_squared_error: 0.1179 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 924/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0138 - mean_absolute_percentage_error: 7.2426 - root_mean_squared_error: 0.1174 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 925/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0142 - mean_absolute_percentage_error: 7.1234 - root_mean_squared_error: 0.1192 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203266.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 926/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0136 - mean_absolute_percentage_error: 7.1697 - root_mean_squared_error: 0.1168 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 927/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0134 - mean_absolute_percentage_error: 6.8917 - root_mean_squared_error: 0.1158 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 928/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0134 - mean_absolute_percentage_error: 6.4680 - root_mean_squared_error: 0.1156 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203272.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 929/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0138 - mean_absolute_percentage_error: 6.8264 - root_mean_squared_error: 0.1175 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203266.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 930/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0142 - mean_absolute_percentage_error: 6.7519 - root_mean_squared_error: 0.1192 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203262.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 931/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0135 - mean_absolute_percentage_error: 7.0984 - root_mean_squared_error: 0.1162 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 932/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0138 - mean_absolute_percentage_error: 6.9497 - root_mean_squared_error: 0.1175 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 933/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0134 - mean_absolute_percentage_error: 7.7515 - root_mean_squared_error: 0.1156 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 934/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0139 - mean_absolute_percentage_error: 7.7437 - root_mean_squared_error: 0.1180 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 935/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0134 - mean_absolute_percentage_error: 6.7969 - root_mean_squared_error: 0.1158 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203262.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 936/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0138 - mean_absolute_percentage_error: 8.0054 - root_mean_squared_error: 0.1175 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203266.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 937/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0130 - mean_absolute_percentage_error: 6.9614 - root_mean_squared_error: 0.1140 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203270.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 938/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0131 - mean_absolute_percentage_error: 7.0137 - root_mean_squared_error: 0.1144 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 939/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0136 - mean_absolute_percentage_error: 6.9228 - root_mean_squared_error: 0.1168 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 940/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0134 - mean_absolute_percentage_error: 6.9958 - root_mean_squared_error: 0.1158 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 941/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0137 - mean_absolute_percentage_error: 6.7384 - root_mean_squared_error: 0.1170 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 942/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0131 - mean_absolute_percentage_error: 6.5268 - root_mean_squared_error: 0.1144 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 943/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0140 - mean_absolute_percentage_error: 7.0670 - root_mean_squared_error: 0.1184 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203266.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 944/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0137 - mean_absolute_percentage_error: 6.7005 - root_mean_squared_error: 0.1170 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 945/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0137 - mean_absolute_percentage_error: 6.9024 - root_mean_squared_error: 0.1168 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203266.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 946/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0137 - mean_absolute_percentage_error: 6.8589 - root_mean_squared_error: 0.1170 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203266.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 947/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0142 - mean_absolute_percentage_error: 6.8091 - root_mean_squared_error: 0.1192 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203266.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 948/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step - loss: 0.0135 - mean_absolute_percentage_error: 6.8283 - root_mean_squared_error: 0.1161 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 949/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0139 - mean_absolute_percentage_error: 6.7150 - root_mean_squared_error: 0.1178 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 950/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0134 - mean_absolute_percentage_error: 6.4968 - root_mean_squared_error: 0.1156 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 951/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0137 - mean_absolute_percentage_error: 6.6867 - root_mean_squared_error: 0.1170 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 952/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0137 - mean_absolute_percentage_error: 6.8308 - root_mean_squared_error: 0.1172 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 953/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0138 - mean_absolute_percentage_error: 6.6286 - root_mean_squared_error: 0.1174 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203270.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 954/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0144 - mean_absolute_percentage_error: 7.0526 - root_mean_squared_error: 0.1201 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203266.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 955/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0137 - mean_absolute_percentage_error: 6.7456 - root_mean_squared_error: 0.1169 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203266.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 956/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0137 - mean_absolute_percentage_error: 7.0328 - root_mean_squared_error: 0.1172 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 957/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0133 - mean_absolute_percentage_error: 6.7660 - root_mean_squared_error: 0.1152 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203266.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 958/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0133 - mean_absolute_percentage_error: 7.2093 - root_mean_squared_error: 0.1155 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203266.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 959/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0135 - mean_absolute_percentage_error: 6.9326 - root_mean_squared_error: 0.1162 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203266.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 960/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0135 - mean_absolute_percentage_error: 6.5759 - root_mean_squared_error: 0.1162 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 961/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0137 - mean_absolute_percentage_error: 6.8479 - root_mean_squared_error: 0.1169 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 962/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0132 - mean_absolute_percentage_error: 6.7561 - root_mean_squared_error: 0.1147 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203266.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 963/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0137 - mean_absolute_percentage_error: 7.5921 - root_mean_squared_error: 0.1168 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 964/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0144 - mean_absolute_percentage_error: 7.2267 - root_mean_squared_error: 0.1199 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203262.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 965/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0144 - mean_absolute_percentage_error: 7.3585 - root_mean_squared_error: 0.1198 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203266.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 966/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0136 - mean_absolute_percentage_error: 7.3396 - root_mean_squared_error: 0.1168 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203270.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 967/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0136 - mean_absolute_percentage_error: 7.6019 - root_mean_squared_error: 0.1167 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 968/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0132 - mean_absolute_percentage_error: 7.2906 - root_mean_squared_error: 0.1151 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 969/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0138 - mean_absolute_percentage_error: 7.3930 - root_mean_squared_error: 0.1173 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203266.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 970/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0132 - mean_absolute_percentage_error: 7.0373 - root_mean_squared_error: 0.1150 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 971/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0139 - mean_absolute_percentage_error: 7.1173 - root_mean_squared_error: 0.1181 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 972/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0132 - mean_absolute_percentage_error: 7.1094 - root_mean_squared_error: 0.1150 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203270.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 973/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0137 - mean_absolute_percentage_error: 7.1886 - root_mean_squared_error: 0.1172 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203270.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 974/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0134 - mean_absolute_percentage_error: 7.1845 - root_mean_squared_error: 0.1157 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 975/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0136 - mean_absolute_percentage_error: 6.8833 - root_mean_squared_error: 0.1168 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 976/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0136 - mean_absolute_percentage_error: 7.2295 - root_mean_squared_error: 0.1168 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 977/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0136 - mean_absolute_percentage_error: 7.0768 - root_mean_squared_error: 0.1166 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 978/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0133 - mean_absolute_percentage_error: 6.7039 - root_mean_squared_error: 0.1155 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 979/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step - loss: 0.0138 - mean_absolute_percentage_error: 6.7366 - root_mean_squared_error: 0.1174 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 980/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0138 - mean_absolute_percentage_error: 6.8643 - root_mean_squared_error: 0.1176 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 981/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0139 - mean_absolute_percentage_error: 6.8981 - root_mean_squared_error: 0.1178 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203266.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 982/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0140 - mean_absolute_percentage_error: 7.0082 - root_mean_squared_error: 0.1183 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203270.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 983/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0134 - mean_absolute_percentage_error: 6.6139 - root_mean_squared_error: 0.1157 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 984/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0136 - mean_absolute_percentage_error: 7.2331 - root_mean_squared_error: 0.1165 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 985/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0137 - mean_absolute_percentage_error: 6.8049 - root_mean_squared_error: 0.1171 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 986/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0136 - mean_absolute_percentage_error: 7.6931 - root_mean_squared_error: 0.1167 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203270.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 987/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0133 - mean_absolute_percentage_error: 7.2971 - root_mean_squared_error: 0.1154 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 988/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0138 - mean_absolute_percentage_error: 6.9836 - root_mean_squared_error: 0.1173 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203266.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 989/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0137 - mean_absolute_percentage_error: 6.9128 - root_mean_squared_error: 0.1173 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203270.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 990/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0134 - mean_absolute_percentage_error: 6.8401 - root_mean_squared_error: 0.1156 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 991/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0132 - mean_absolute_percentage_error: 8.0393 - root_mean_squared_error: 0.1151 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203266.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 992/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0135 - mean_absolute_percentage_error: 6.8425 - root_mean_squared_error: 0.1160 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203266.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 993/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0133 - mean_absolute_percentage_error: 7.4445 - root_mean_squared_error: 0.1155 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 994/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0142 - mean_absolute_percentage_error: 7.2089 - root_mean_squared_error: 0.1190 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 995/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0139 - mean_absolute_percentage_error: 7.3107 - root_mean_squared_error: 0.1179 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203270.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 996/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0138 - mean_absolute_percentage_error: 7.1570 - root_mean_squared_error: 0.1173 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 997/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0134 - mean_absolute_percentage_error: 7.4414 - root_mean_squared_error: 0.1158 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 998/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0136 - mean_absolute_percentage_error: 6.9644 - root_mean_squared_error: 0.1168 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203272.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 999/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0137 - mean_absolute_percentage_error: 8.2099 - root_mean_squared_error: 0.1169 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 1000/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0136 - mean_absolute_percentage_error: 7.0005 - root_mean_squared_error: 0.1165 - val_loss: 0.0785 - val_mean_absolute_percentage_error: 23203264.0000 - val_root_mean_squared_error: 0.2801\n"
     ]
    }
   ],
   "source": [
    "#Entrenamiento\n",
    "hist=autoencoder.fit(train_data, train_data, epochs=1000, batch_size=32, shuffle=True, validation_data=(test_data, test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "be1e3e63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt # Import plotting library\n",
    "plt.figure()\n",
    "plt.plot(hist.history[\"mean_absolute_percentage_error\"])\n",
    "plt.plot(hist.history[\"val_mean_absolute_percentage_error\"])\n",
    "plt.title(\"model mean absolute percentage error\")\n",
    "plt.ylabel(\"mape\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.legend([\"train\", \"validation\"], loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8b7eb74e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 375ms/step\n"
     ]
    }
   ],
   "source": [
    "encoder = Model(input_data, encoded)\n",
    "encoded_data = encoder.predict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d052a079",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear DataFrame con los datos codificados\n",
    "encoded_df = pd.DataFrame(encoded_data)\n",
    "\n",
    "# Ver los datos codificados en una tabla\n",
    "encoded_df.head(15)\n",
    "\n",
    "# guardar la base de datos transpuesta en un archivo csv\n",
    "encoded_df.to_csv('encoded_df.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be197922",
   "metadata": {},
   "source": [
    "# librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2d7a30a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gzip\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score, classification_report\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, train_test_split, StratifiedKFold, cross_val_predict,LeaveOneOut, KFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import random\n",
    "from sklearn import tree,svm\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaba4aad",
   "metadata": {},
   "source": [
    "# LogisticRegression con Hiperparametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5d866dd5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "30 fits failed out of a total of 45.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1160, in fit\n",
      "    self._validate_params()\n",
      "  File \"C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'elasticnet', 'none' (deprecated), 'l1', 'l2'} or None. Got 'l3l4' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan 0.46666667        nan        nan 0.46666667        nan\n",
      "        nan 0.55              nan        nan 0.55              nan\n",
      "        nan 0.55              nan]\n",
      "  warnings.warn(\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=3, estimator=LogisticRegression(),\n",
       "             param_grid={&#x27;C&#x27;: [0.01, 0.1, 4, 5, 10],\n",
       "                         &#x27;penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;, &#x27;l3l4&#x27;]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=3, estimator=LogisticRegression(),\n",
       "             param_grid={&#x27;C&#x27;: [0.01, 0.1, 4, 5, 10],\n",
       "                         &#x27;penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;, &#x27;l3l4&#x27;]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=3, estimator=LogisticRegression(),\n",
       "             param_grid={'C': [0.01, 0.1, 4, 5, 10],\n",
       "                         'penalty': ['l1', 'l2', 'l3l4']})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y5 = pd.read_csv(\"target.csv\")\n",
    "X5 = pd.read_csv(\"encoded_df.csv\")\n",
    "\n",
    "# Define los hiperparámetros a ajustar\n",
    "param_grid5 = {'C': [0.01,0.1, 4, 5,10], 'penalty': ['l1', 'l2','l3''l4']}\n",
    "\n",
    "# Crea un modelo de regresión logística\n",
    "model5 = LogisticRegression()\n",
    "\n",
    "# Realiza la búsqueda de hiperparámetros utilizando validación cruzada\n",
    "grid_search5 = GridSearchCV(model5, param_grid5, cv=3)\n",
    "grid_search5.fit(X5, Y5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e57239f9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Obtiene el mejor modelo y sus hiperparámetros\n",
    "best_model5 = grid_search5.best_estimator_\n",
    "best_params5 = grid_search5.best_params_\n",
    "\n",
    "# Calcula la exactitud (accuracy) utilizando validación cruzada\n",
    "accuracy_scores5 = cross_val_score(best_model5, X5, Y5, cv=3)\n",
    "mean_accuracy5 = accuracy_scores5.mean()\n",
    "\n",
    "# Realiza las predicciones con el mejor modelo\n",
    "Y_pred5 = cross_val_predict(best_model5, X5, Y5, cv=3)\n",
    "# Calcula el F1-score\n",
    "f5 = f1_score(Y5, Y_pred5, average=None)\n",
    "f5_macro = f1_score(Y5, Y_pred5, average='macro')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "412ee885",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'C': 4, 'penalty': 'l2'}\n",
      "\n",
      "Accuracy: 54.99999999999999 %\n",
      "F1-score: [ 25. 100.   0. 100.] %\n",
      "F1 Score (Macro): 56.25 %\n"
     ]
    }
   ],
   "source": [
    "# Grafica los resultados\n",
    "plt.title('True Labels vs Predictions')\n",
    "plt.scatter(range(len(Y5)), Y5, color='blue', label='True Labels')\n",
    "plt.scatter(range(len(Y_pred5)), Y_pred5, color='red', label='Predictions')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(\"Best Parameters:\", best_params5)\n",
    "print()\n",
    "print(\"Accuracy:\", mean_accuracy5*100,\"%\")\n",
    "print(\"F1-score:\", f5*100,'%')\n",
    "print(\"F1 Score (Macro):\", f5_macro*100,'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fdf586f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primary human monocytes from patient with metastatic breast cancer:B1, B2, B3, B4\n",
    "# Primary human monocytes from healthy control: H1,H2, H3\n",
    "# Primary human monocytes from patient with gram-negative sepsis: S1,S2, S3\n",
    "# Primary human monocytes from patient with tuberculosis:T1, T2, T3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f54549",
   "metadata": {},
   "source": [
    "# Arbol de decisiones con hiperparametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b3fe694e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor modelo 1: DecisionTreeClassifier(class_weight='balanced', max_depth=4, random_state=20)\n",
      "Mejores hiperparámetros 1: {'criterion': 'gini', 'max_depth': 4, 'min_samples_split': 2}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV, LeaveOneOut, train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Cargar los datos\n",
    "Y3 = pd.read_csv(\"target.csv\")\n",
    "X3 = pd.read_csv(\"encoded_df.csv\")\n",
    "\n",
    "# Definir los hiperparámetros a ajustar\n",
    "param_grid3 = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': [4, 6, 8, 10],\n",
    "    'min_samples_split': [2, 3, 4, 5]\n",
    "}\n",
    "\n",
    "# Realizar la búsqueda de hiperparámetros utilizando validación cruzada Leave-One-Out\n",
    "loo3 = LeaveOneOut()\n",
    "modelo3 = DecisionTreeClassifier(class_weight='balanced', random_state=20)\n",
    "mejor_modelo3 = GridSearchCV(modelo3, param_grid3, cv=loo3)\n",
    "mejor_modelo3.fit(X3, Y3)\n",
    "\n",
    "# Obtener el mejor modelo y sus hiperparámetros\n",
    "modelo_final3 = mejor_modelo3.best_estimator_\n",
    "mejores_parametros3 = mejor_modelo3.best_params_\n",
    "\n",
    "\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "X_train3, X_test3, Y_train3, Y_test3 = train_test_split(X3, Y3, test_size=0.15, random_state=20)\n",
    "\n",
    "# Construir y evaluar el primer modelo\n",
    "modelo3.fit(X_train3, Y_train3)\n",
    "Y_pred3 = modelo3.predict(X_test3)\n",
    "\n",
    "\n",
    "\n",
    "# Construir y evaluar el segundo modelo con los mejores hiperparámetros utilizando validación cruzada Leave-One-Out\n",
    "modelo3a = DecisionTreeClassifier(class_weight='balanced', **mejores_parametros3, random_state=20)\n",
    "modelo3a.fit(X3, Y3)\n",
    "Y_pred3a = modelo3a.predict(X3)\n",
    "\n",
    "# Imprimir el mejor modelo y sus hiperparámetros\n",
    "print(\"Mejor modelo 1:\", modelo_final3)\n",
    "print(\"Mejores hiperparámetros 1:\", mejores_parametros3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "46a2483a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Informe de clasificación - Modelo 1:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         1\n",
      "           2       0.50      1.00      0.67         1\n",
      "\n",
      "    accuracy                           0.50         2\n",
      "   macro avg       0.25      0.50      0.33         2\n",
      "weighted avg       0.25      0.50      0.33         2\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(\"Informe de clasificación - Modelo 1:\")\n",
    "print(classification_report(Y_test3, Y_pred3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b8529fc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Informe de clasificación - Modelo 2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         3\n",
      "           1       1.00      1.00      1.00         3\n",
      "           2       1.00      1.00      1.00         4\n",
      "           3       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00        13\n",
      "   macro avg       1.00      1.00      1.00        13\n",
      "weighted avg       1.00      1.00      1.00        13\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Informe de clasificación - Modelo 2:\")\n",
    "print(classification_report(Y3, Y_pred3a))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df7a9a75",
   "metadata": {},
   "source": [
    "# SVM con hiperparametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "86f3dd00",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:700: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=3.\n",
      "  warnings.warn(\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:700: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=3.\n",
      "  warnings.warn(\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:700: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=3.\n",
      "  warnings.warn(\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "\n",
    "# Cargar los datos\n",
    "Y1 = pd.read_csv(\"target.csv\")\n",
    "X1 = pd.read_csv(\"encoded_df.csv\")\n",
    "\n",
    "# Definir la estrategia de validación cruzada\n",
    "rskf = RepeatedStratifiedKFold(n_splits=3, n_repeats=3, random_state=42)\n",
    "\n",
    "# Creación del modelo SVM\n",
    "model1 = svm.SVC()\n",
    "\n",
    "# Definición de los hiperparámetros a ajustar\n",
    "param_grid1 = {\n",
    "    'C': [0.01, 0.1, 1],\n",
    "    'kernel': ['linear', 'rbf', 'sigmoid']\n",
    "}\n",
    "\n",
    "# Búsqueda de los mejores hiperparámetros utilizando GridSearchCV\n",
    "grid_search1 = GridSearchCV(model1, param_grid1, cv=rskf)\n",
    "X_train1, X_test1, Y_train1, Y_test1 = train_test_split(X1, Y1, test_size=0.25, random_state=30, stratify=Y1)\n",
    "grid_search1.fit(X_train1, Y_train1)\n",
    "\n",
    "# Obtención del mejor modelo\n",
    "best_model1 = grid_search1.best_estimator_\n",
    "\n",
    "# Evaluación del modelo\n",
    "Y_pred1 = best_model1.predict(X_test1)\n",
    "classification_rep1 = classification_report(Y_test1, Y_pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "aebe96bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'C': 0.01, 'kernel': 'linear'}\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         1\n",
      "           1       1.00      1.00      1.00         1\n",
      "           2       0.50      1.00      0.67         1\n",
      "           3       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           0.75         4\n",
      "   macro avg       0.62      0.75      0.67         4\n",
      "weighted avg       0.62      0.75      0.67         4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Imprimir el informe de clasificación\n",
    "print(\"Best Parameters:\", grid_search1.best_params_)\n",
    "print()\n",
    "print(\"Classification Report:\\n\", classification_rep1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9e8381",
   "metadata": {},
   "source": [
    "# Evaluación del Modelo SVM utilizando Leave-One-Out (LOO) y Matriz de Confusión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "976a1c92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "Y6 = pd.read_csv(\"target.csv\")\n",
    "X6 = pd.read_csv(\"encoded_df.csv\")\n",
    "random_state = 42  # Establece un valor fijo para random_state\n",
    "\n",
    "# Crear el esquema de validación cruzada Leave-One-Out (LOO)\n",
    "loo6 = LeaveOneOut()\n",
    "\n",
    "# Paso 3: Creación del modelo SVM\n",
    "model6 = SVC()\n",
    "\n",
    "# Paso 4: Definición de los hiperparámetros a ajustar\n",
    "param_grid6 = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'kernel': ['linear', 'rbf', 'sigmoid']\n",
    "}\n",
    "\n",
    "# Paso 5: Búsqueda de los mejores hiperparámetros utilizando GridSearchCV\n",
    "grid_search6 = GridSearchCV(model6, param_grid6, cv=loo6)\n",
    "grid_search6.fit(X6, Y6)\n",
    "\n",
    "# Paso 6: Obtención del mejor modelo\n",
    "best_model6 = grid_search6.best_estimator_\n",
    "\n",
    "# Paso 7: Evaluación del modelo utilizando LOO\n",
    "accuracy_loo6 = cross_val_score(best_model6, X6, Y6, cv=loo6, scoring='accuracy')\n",
    "# Calcular el F1-score\n",
    "f6 = f1_score(Y6, best_model6.predict(X6), average=None)\n",
    "f6_macro = f1_score(Y6, best_model6.predict(X6), average='macro')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "70c2897e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\57311\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión del modelo (LOO): 69.23076923076923 %\n",
      "Precisión del modelo (datos completos): 100.0 %\n",
      "F1-score: [1. 1. 1. 1.]\n",
      "F1-score (Macro): 1.0\n"
     ]
    }
   ],
   "source": [
    "# Calcular y graficar la matriz de confusión\n",
    "best_model6.fit(X6, Y6)\n",
    "Y_estimado6 = best_model6.predict(X6)\n",
    "confusion_mat6 = confusion_matrix(Y6, Y_estimado6)\n",
    "sns.heatmap(confusion_mat6, annot=True, cmap=\"Blues\")\n",
    "plt.xlabel('Etiqueta Predicha')\n",
    "plt.ylabel('Etiqueta Verdadera')\n",
    "plt.title('Matriz de Confusión')\n",
    "plt.show()\n",
    "\n",
    "# Ajustar el nuevo modelo a los datos completos\n",
    "print(\"Precisión del modelo (LOO):\", accuracy_loo6.mean()*100,'%')\n",
    "\n",
    "accuracy_full_data = accuracy_score(Y6, Y_estimado6)\n",
    "print(\"Precisión del modelo (datos completos):\", accuracy_full_data*100,'%')\n",
    "print(\"F1-score:\", f6)\n",
    "print(\"F1-score (Macro):\", f6_macro)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc6ac07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8285f20e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
